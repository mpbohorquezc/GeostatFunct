[
  {
    "objectID": "vowels.html",
    "href": "vowels.html",
    "title": "Vowels",
    "section": "",
    "text": "El conjunto de datos vowels contiene señales de electroencefalograma (EEG) tomadas de 21 electrodos, durante la actividad mental de imaginar las cinco vocales del idioma español. Este conjunto de datos se desarrolló para ser aplicado en una interfaz cerebro-computadora (BCI, por sus siglas en inglés) destinada al control de una prótesis de mano.\n\n\nUna BCI permite a las personas controlar dispositivos externos, como prótesis, usando únicamente señales cerebrales. En este caso, el conjunto de datos recoge la actividad cerebral relacionada con el pensamiento imaginario de las vocales, lo que se espera que ayude a entrenar modelos para la clasificación y control de una prótesis.\n\n\n\nBrain BCI, Adindva1, CC BY-SA 4.0",
    "crumbs": [
      "Datasets",
      "Vowels"
    ]
  },
  {
    "objectID": "vowels.html#descripción",
    "href": "vowels.html#descripción",
    "title": "Vowels",
    "section": "",
    "text": "El conjunto de datos vowels contiene señales de electroencefalograma (EEG) tomadas de 21 electrodos, durante la actividad mental de imaginar las cinco vocales del idioma español. Este conjunto de datos se desarrolló para ser aplicado en una interfaz cerebro-computadora (BCI, por sus siglas en inglés) destinada al control de una prótesis de mano.\n\n\nUna BCI permite a las personas controlar dispositivos externos, como prótesis, usando únicamente señales cerebrales. En este caso, el conjunto de datos recoge la actividad cerebral relacionada con el pensamiento imaginario de las vocales, lo que se espera que ayude a entrenar modelos para la clasificación y control de una prótesis.\n\n\n\nBrain BCI, Adindva1, CC BY-SA 4.0",
    "crumbs": [
      "Datasets",
      "Vowels"
    ]
  },
  {
    "objectID": "vowels.html#uso",
    "href": "vowels.html#uso",
    "title": "Vowels",
    "section": "Uso",
    "text": "Uso\nPara cargar los datos en R, usa el siguiente comando:\n\ndata(vowels)\n\nWarning in data(vowels): data set 'vowels' not found",
    "crumbs": [
      "Datasets",
      "Vowels"
    ]
  },
  {
    "objectID": "optimal_design.html",
    "href": "optimal_design.html",
    "title": "Diseño Óptimo",
    "section": "",
    "text": "La función FD_optimal_design permite determinar el diseño espacial óptimo para la recolección de datos funcionales o escalares, basado en un modelo de variograma y un conjunto de puntos donde se desea realizar predicciones. Este diseño es crucial para optimizar la información obtenida en estudios espaciales.",
    "crumbs": [
      "Diseño Óptimo",
      "Diseño Óptimo"
    ]
  },
  {
    "objectID": "optimal_design.html#introducción",
    "href": "optimal_design.html#introducción",
    "title": "Diseño Óptimo",
    "section": "",
    "text": "La función FD_optimal_design permite determinar el diseño espacial óptimo para la recolección de datos funcionales o escalares, basado en un modelo de variograma y un conjunto de puntos donde se desea realizar predicciones. Este diseño es crucial para optimizar la información obtenida en estudios espaciales.",
    "crumbs": [
      "Diseño Óptimo",
      "Diseño Óptimo"
    ]
  },
  {
    "objectID": "optimal_design.html#uso",
    "href": "optimal_design.html#uso",
    "title": "Diseño Óptimo",
    "section": "Uso",
    "text": "Uso\nFD_optimal_design(k, s0, model, fixed_stations = NULL,\n                   scalar = FALSE, nharm = NULL,\n                   method = \"lambda\", grid = NULL,\n                   map = NULL, plt = FALSE)",
    "crumbs": [
      "Diseño Óptimo",
      "Diseño Óptimo"
    ]
  },
  {
    "objectID": "optimal_design.html#argumentos",
    "href": "optimal_design.html#argumentos",
    "title": "Diseño Óptimo",
    "section": "Argumentos",
    "text": "Argumentos\n\nk: Número de nuevas estaciones a ubicar.\ns0: Un objeto de tipo matrix, array, data.frame o SpatialPoints que contiene las coordenadas de los puntos donde se desea realizar la predicción óptima.\nmodel: Un objeto VariogramModel del paquete gstat o una lista de modelos si se utilizarán diferentes modelos para cada armónico.\nfixed_stations: Coordenadas de estaciones ya existentes que no se eliminarán. Puede ser de clase matrix, array, data.frame, SpatialPoints o NULL si no hay estaciones fijas.\nscalar: Booleano que indica si la optimización es para datos funcionales (FALSE) o escalares (TRUE). Si es TRUE, nharm se establece en 1.\nnharm: Número de armónicos de los componentes principales funcionales a utilizar en la predicción.\nmethod: Método de kriging funcional que se utilizará, disponible “lambda” y “scores”.\ngrid: Coordenadas donde se pueden ubicar las nuevas estaciones, debe ser de tipo matrix, array, data.frame, SpatialPoints.\nmap: Objeto espacial del paquete sp donde se ubicarán las nuevas estaciones. También se usará para crear la gráfica.\nplt: Booleano que indica si se debe generar una gráfica con ggplot2.",
    "crumbs": [
      "Diseño Óptimo",
      "Diseño Óptimo"
    ]
  },
  {
    "objectID": "optimal_design.html#detalles",
    "href": "optimal_design.html#detalles",
    "title": "Diseño Óptimo",
    "section": "Detalles",
    "text": "Detalles\nLa función utiliza métodos presentados por Bohorquez et al. (2016) para encontrar la mejor combinación de diseño según la varianza del error de predicción de kriging funcional. Se implementan dos métodos de kriging funcional:\n\nMétodo “lambda”: Utiliza FPCA y kriging simple.\nMétodo “scores”: Aplica kriging simple a cada armónico y minimiza la varianza total de las predicciones.",
    "crumbs": [
      "Diseño Óptimo",
      "Diseño Óptimo"
    ]
  },
  {
    "objectID": "optimal_design.html#valor-de-retorno",
    "href": "optimal_design.html#valor-de-retorno",
    "title": "Diseño Óptimo",
    "section": "Valor de Retorno",
    "text": "Valor de Retorno\nLa función devuelve un objeto de clase OptimalSpatialDesign que incluye:\n\nnew_stations: Coordenadas de las nuevas estaciones.\nfixed_stations: Coordenadas de las estaciones fijas.\nplot: Gráfica generada con ggplot2.",
    "crumbs": [
      "Diseño Óptimo",
      "Diseño Óptimo"
    ]
  },
  {
    "objectID": "optimal_design.html#ejemplo",
    "href": "optimal_design.html#ejemplo",
    "title": "Diseño Óptimo",
    "section": "Ejemplo",
    "text": "Ejemplo\nlibrary(gstat)\ns0 &lt;- cbind(2 * runif(100), runif(100))  # coordenadas aleatorias\nfixed_stations &lt;- cbind(2 * runif(4), runif(4))\nx_grid &lt;- seq(0, 2, length = 30)\ny_grid &lt;- seq(0, 1, length = 30)\ngrid &lt;- cbind(rep(x_grid, each = 30), rep(y_grid, 30))\nmodel &lt;- vgm(psill = 5.665312,\n              model = \"Exc\",\n              range = 8000,\n              kappa = 1.62,\n              add.to = vgm(psill = 0.893,\n                           model = \"Nug\",\n                           range = 0,\n                           kappa = 0))\n\nOSD &lt;- FD_optimal_design(k = 10, s0 = s0, model = model,\n                         grid = grid, nharm = 2, plt = TRUE,\n                         fixed_stations = fixed_stations)\n\n# Resultados\nOSD$new_stations\nOSD$fixed_stations\nOSD$plot\nclass(OSD)\n\n\n\n\n\n\nNote\n\n\n\nEl método ‘lambda’ tiende a ser más rápido que el método ‘scores’.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nCuando el método es ‘lambda’, el valor minimizado no es la varianza, sino el negativo de una expresión específica en la referencia mencionada",
    "crumbs": [
      "Diseño Óptimo",
      "Diseño Óptimo"
    ]
  },
  {
    "objectID": "kriging.html",
    "href": "kriging.html",
    "title": "Kriging",
    "section": "",
    "text": "El Kriging es un método de interpolación basado en la teoría de procesos estocástocos que permite estimar los valores que toma una variable en lugares no muestreados a partir de la suposición de que las ubicaciones están correlacionadas espacialmente.",
    "crumbs": [
      "Kriging",
      "Kriging"
    ]
  },
  {
    "objectID": "kriging.html#kriging-ordinario",
    "href": "kriging.html#kriging-ordinario",
    "title": "Kriging",
    "section": "Kriging Ordinario",
    "text": "Kriging Ordinario\nDado un conjunto de observaciones en diferentes localizaciones \\(s_1,s_2,\\cdots,s_n\\) busca predecir el valor de la variable de interés en una nueva ubicación \\(s_0\\)​ como una combinación ponderada de las observaciones:\n\\[\n\\hat{Z}(s_0) = \\sum_{i=1}^n \\lambda_iZ(s_i)\n\\]\nDonde \\(\\lambda_i\\) son los pesos asignados a cada observación, determinados en función de la covarianza espacial entre \\(s_0\\) y \\(s_i\\) determinado por un variograma.",
    "crumbs": [
      "Kriging",
      "Kriging"
    ]
  },
  {
    "objectID": "kriging.html#kriging-funcional",
    "href": "kriging.html#kriging-funcional",
    "title": "Kriging",
    "section": "Kriging Funcional",
    "text": "Kriging Funcional\nEn el contexto funcional, las observaciones en cada ubicación espacial no son valores discretos sino funciones completas. Supongamos que tenemos un conjunto de funciones \\(X(s_1,t),X(s_2,t),\\cdots,X(s_n,t)\\) donde cada \\(X(s_i,t)\\) es una función que describe el comportamiento de la variable de interés a lo largo de un dominio continuo \\(t\\) (como el tiempo).\nEl kriging funcional extiende la idea del kriging clásico al predecir una función en una nueva ubicación \\(s_0\\) utilizando una combinación ponderada de las funciones observadas en las localizaciones \\(s_1,\\cdots,s_n\\). En ese orden de ideas, podemos formular el kriging funcional de la siguiente manera\n\\[\n\\hat{X}(s_0,t)=\\sum_{i=1}^n \\lambda_i(t)X(s_i,t)\n\\]\ndonde \\(\\lambda_i(t)\\) son las funciones de peso que dependen de la localización y del dominio funcional \\(t\\). Estas funciones de peso se determinan resolviendo un sistema de ecuaciones basado en la covariancia entre las funciones observadas y la función a predecir.\nCon el paquete SpatFD podemos crear un objeto SpatFD y definir los modelos de semivariogramas que vamos a emplear en el kriging. En este caso usaremos los datos AirQualityBogota y ajustaremos tres semivariogramas, uno wave, uno Mattern y por último un exponencial, la ubicación que queremos predecir se define en la variable newcoorden.\n\n# Load data and coordinates\ndata(AirQualityBogota)\n\n#s_0 nonsampled location. It could be data.frame or matrix and one or more locations of interest\nnewcoorden=data.frame(X=seq(93000,105000,len=100),Y=seq(97000,112000,len=100))\n\n# Building the SpatFD object\nSFD_PM10 &lt;- SpatFD(PM10, coords = coord[, -1], basis = \"Bsplines\", nbasis = 17,norder=5, lambda = 0.00002, nharm=3)\n\n\n# Semivariogram models for each spatial random field of scores\nmodelos &lt;- list(vgm(psill = 2199288.58, \"Wav\", range = 1484.57, nugget =  0),\n                vgm(psill = 62640.74, \"Mat\", range = 1979.43, nugget = 0,kappa=0.68),\n                vgm(psill =37098.25, \"Exp\", range = 6433.16, nugget =  0))\n\nExisten dos enfoques diferentes para realizar el kriging funcional, el método de scores y el método lambda.\n\nMétodo de Scores\nEn el método de scores, el análisis funcional se basa en una descomposición de las funciones observadas en un conjunto de componentes principales, generalmente a través de una descomposición en funciones base (como la descomposición en funciones ortogonales o en series de Fourier). Este método se descompone en dos etapas:\n\nDescomposición funcional: Se aplica una descomposición funcional de las observaciones para representar cada función como una combinación de componentes principales (bases funcionales) y sus correspondientes coeficientes o “scores”. Si las funciones \\(X(s_i,t)\\) observadas se pueden representar como:\n\n\\[\nX(s_i,t) = \\sum_{k=1}^K \\alpha_{ik}\\phi_k(t)\n\\]\ndonde \\(\\phi_k(t)\\) son las bases funcionales y \\(\\alpha_{ik}\\) son los scores de las componentes principales para cada localización \\(s_i\\). En lugar de predecir la función completa, este método se centra en predecir los scores en la ubicación no observada \\(s_0\\).\nPredicción de una nueva ubicación: El kriging se aplica sobre los scores obtenidos. Se predicen los scores de la nueva ubicación \\(s_0\\) para construir la función predicha \\(\\hat{X}(s_0,t)\\) como una combinación de las bases funcionales ponderadas por los scores predichos:\n\\[\n\\hat{X}(s_0,t) = \\sum_{k=1}^K \\alpha_{0k}\\phi_k(t)\n\\]\nLa función KS_scores_lambdas permite realizar el kriging usando este método al usar “scores” en la opción method\n\nKS_SFD_PM10_sc &lt;- KS_scores_lambdas(SFD_PM10, newcoorden, method = \"scores\", model = modelos)\n\nUsing first variable by default\n\n\nUsing fill.all = TRUE by default\n\n\n[using simple kriging]\n[using simple kriging]\n[using simple kriging]\n\n\nMétodo Lambda\nEste método utiliza una combinación de las funciones observadas, ponderadas por ciertos coeficientes o pesos, para estimar la función en la nueva ubicación, es decir, el kriging se lleva a cabo directamente sobre las funciones. El predictor \\(\\breve{\\chi}_{ s_0}(t)\\)\nestá dado por\n\\[\\breve{\\chi}_{s_0}(t)=\\sum\\limits_{i=1}^{n}\\lambda_i\\chi_{s_i}(t)\\]\nDeben encontrarse los pesos \\(\\lambda_i\\) que minimicen la diferencia entre la verdadera función en la ubicación no observada \\(s_0\\) y el predictor. Eso se expresa matemáticamente como:\n\\[\nmin||\\chi_{s_0}(t)-\\breve{\\chi}_{s_0}(t)||^2\n\\]\ndonde \\(\\chi_{s_0}(t)\\) es la verdadera función en la ubicación \\(s_0\\). La minimización de esta expresión se realiza en el sentido de la norma \\(L^2\\).\nLa función KS_scores_lambdas permite realizar el kriging usando este método al usar “lambda” en la opción method\n\nKS_SFD_PM10_l &lt;- KS_scores_lambdas(SFD_PM10, newcoorden ,method = \"lambda\", model = modelos)\n\nUsing first variable by default\n\n\nUsing fill.all = TRUE by default\n\n\n\nFinalmente, ambos métodos pueden ser aplicados usanto “both” como argumento en method.\n\nKS_SFD_PM10_both &lt;- KS_scores_lambdas(SFD_PM10, newcoorden, method = \"both\", model = modelos)\n\nUsing first variable by default\n\n\nUsing fill.all = TRUE by default\n\n\n[using simple kriging]\n[using simple kriging]\n[using simple kriging]",
    "crumbs": [
      "Kriging",
      "Kriging"
    ]
  },
  {
    "objectID": "kriging.html#gráficamente",
    "href": "kriging.html#gráficamente",
    "title": "Kriging",
    "section": "Gráficamente",
    "text": "Gráficamente\nPodemos graficar las predicciones usando la función ggplot_KS\n\n#ggplot_KS(KS_SFD_PM10_both,show.varpred = FALSE,\n #         main = \"Plot 1 - Using Scores\",\n  #        main2 = \"Plot 2 - Using Lambda\",\n   #       ylab = \"PM10\")\n\nAsí mismo, podemos graficar las predicciones suavizadas en tiempos específicos.\n\n#ggmap_KS(KS_SFD_PM10_both,\n #        map_path = map,\n  #       window_time = c(2108),\n   #      method = \"lambda\",\n    #     zmin = 50,",
    "crumbs": [
      "Kriging",
      "Kriging"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SpatFD",
    "section": "",
    "text": "La geoestadística funcional es una extensión del marco teórico de la geoestadística tradicional, que permite el análisis y modelado de datos funcionales correlacionados espacialmente, tanto univariados como multivariados. Este enfoque incluye herramientas exploratorias, predicción espacial mediante kriging y cokriging, muestreo óptimo, clasificación supervisada y simulación. A través de este enfoque, se modela la estructura de dependencia espacial entre curvas, lo que permite realizar predicciones en ubicaciones no muestreadas utilizando predictores funcionales que minimizan las varianzas del error de predicción. Además, se ofrece la optimización de la configuración de las ubicaciones de muestreo para mejorar la predicción espacial funcional.\nLas herramientas disponibles también permiten la representación gráfica de las curvas predichas en cada ubicación y el mapeo de las superficies en cada punto temporal. La clasificación supervisada integra la correlación espacial, y se extiende a escenarios con medidas funcionales repetidas en cada localización. Finalmente, la simulación de datos funcionales correlacionados espacialmente puede ser tanto condicional como incondicional, y se fundamenta en el supuesto de espacios de Hilbert conjuntos gaussianos.",
    "crumbs": [
      "Estadística Espacial Funcional",
      "Home"
    ]
  },
  {
    "objectID": "index.html#datos-funcionales",
    "href": "index.html#datos-funcionales",
    "title": "SpatFD",
    "section": "Datos Funcionales",
    "text": "Datos Funcionales\nImaginemos que estamos interesados en estudiar cómo varía la temperatura en diferentes ciudades del mundo durante un año completo. Para hacerlo, en lugar de tomar una sola medida de la temperatura, registramos el promedio mensual de la termperatura durante todo un año.\nEn lugar de analizar cada punto de temperatura de manera independiente, podemos ver la temperatura a lo largo del añi como una función continua del tiempo. Esta función nos describe cómo la temperatura cambia en cada instante del día, lo cual permite realizar análisis mucho más precisos.\n\n\n\nPZmaps, CC BY-SA 3.0, via Wikimedia Commons\n\n\nLos datos funcionales son los que en lugar de contemplar cada dato como una observación puntual, se consideran como funciones continuas observadas en un conjunto de puntos. Los datos funcionales permiten capturar mejor la complejidad de fenómenos que además de variar en el espacio, varían en dominios continuos como el tiempo o la altitud, además de facilitar la detección de tendencias o anomalías teniendo en cuenta múltiples dimensiones de variación.",
    "crumbs": [
      "Estadística Espacial Funcional",
      "Home"
    ]
  },
  {
    "objectID": "GeoestadísticaConSgeostat.html",
    "href": "GeoestadísticaConSgeostat.html",
    "title": "Geoestadística con sgeostat",
    "section": "",
    "text": "rm(list=ls())\naquifer=read.table(\"data/aquifer.txt\",head=T,dec=\",\")\nhead(aquifer)\n\n       Este     Norte Profundidad\n1  42.78275 127.62282        1464\n2 -27.39691  90.78732        2553\n3  -1.16289  84.89600        2158\n4 -18.61823  76.45199        2455\n5  96.46549  64.58058        1756\n6 108.56243  82.92325        1702\n\n\n\n\n\n\nlibrary(scatterplot3d)\nlibrary(ggplot2)\nlibrary(cowplot)\nlibrary(sgeostat)\n\n\n\n\n\ng1=ggplot(aquifer, aes(Profundidad, Este)) + \n  geom_point() + \n  geom_line() +\n  xlab(\"Este\") + \n  ylab(\"Profundidad\")\n\ng2=ggplot(aquifer, aes(Profundidad, Norte)) + \n  geom_point() + \n  geom_line() +\n  xlab(\"Norte\") + \n  ylab(\"Profundidad\")\n\ng3=ggplot(aquifer, aes(Profundidad, Este*Norte)) + \n  geom_point() + \n  geom_line() +\n  xlab(\"Interacción este,norte\") + \n  ylab(\"Profundidad\")\n\n\n#plot_grid(g1,g2,g3)\n\n\n#cor(aquifer)\n\n\nscatterplot3d(aquifer, highlight.3d=TRUE, col.axis=\"blue\",\ncol.grid=\"lightblue\", main=\"Tendencia de Profundidad\", pch=20)\n\n\n\n\n\n\n\n\n\nreg1 &lt;- lm(Profundidad ~ Este + Norte, data = aquifer)\nresiduales1  &lt;-  residuals(reg1)\n#summary(reg1)\n\n\nanova(reg1)\n\nAnalysis of Variance Table\n\nResponse: Profundidad\n          Df   Sum Sq  Mean Sq F value    Pr(&gt;F)    \nEste       1 19045642 19045642  460.95 &lt; 2.2e-16 ***\nNorte      1  8960172  8960172  216.86 &lt; 2.2e-16 ***\nResiduals 82  3388069    41318                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nreg2 &lt;- lm(Profundidad ~ Este*Norte, data = aquifer)\nresiduales2  &lt;-  residuals(reg2)\n#summary(reg2)\n\n\nanova(reg2)\n\nAnalysis of Variance Table\n\nResponse: Profundidad\n           Df   Sum Sq  Mean Sq F value    Pr(&gt;F)    \nEste        1 19045642 19045642  517.06 &lt; 2.2e-16 ***\nNorte       1  8960172  8960172  243.25 &lt; 2.2e-16 ***\nEste:Norte  1   404448   404448   10.98  0.001379 ** \nResiduals  81  2983621    36835                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nreg3 &lt;- lm(Profundidad ~ Este*Norte+I(Este^2)*I(Norte^2), data = aquifer)\nresiduales3  &lt;-  residuals(reg3)\n#summary(reg3)\n\n\nanova(reg3)\n\nAnalysis of Variance Table\n\nResponse: Profundidad\n                     Df   Sum Sq  Mean Sq  F value    Pr(&gt;F)    \nEste                  1 19045642 19045642 583.2335 &lt; 2.2e-16 ***\nNorte                 1  8960172  8960172 274.3868 &lt; 2.2e-16 ***\nI(Este^2)             1    55368    55368   1.6955 0.1967061    \nI(Norte^2)            1   152170   152170   4.6599 0.0339500 *  \nEste:Norte            1   451567   451567  13.8283 0.0003755 ***\nI(Este^2):I(Norte^2)  1   181854   181854   5.5689 0.0207829 *  \nResiduals            78  2547110    32655                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\naquifer=data.frame(aquifer,resi=residuales2)\naquifer_points=point(aquifer, x=\"Este\", y=\"Norte\")\naquifer_pair=pair(aquifer_points,num.lags=10)\n\n....................................................................................\n\n\n\nstr(aquifer_pair)\n\nList of 5\n $ from: num [1:3570] 1 1 1 1 1 1 1 1 1 1 ...\n $ to  : num [1:3570] 2 3 4 5 6 7 8 9 10 11 ...\n $ lags: Factor w/ 10 levels \"1\",\"2\",\"3\",\"4\",..: 3 3 3 4 3 4 4 4 4 4 ...\n $ dist: num [1:3570] 79.3 61.3 79.9 82.8 79.5 ...\n $ bins: num [1:10] 13.6 40.7 67.8 94.9 122 ...\n - attr(*, \"type\")= chr \"isotropic\"\n - attr(*, \"class\")= chr \"pair\"\n\n\n\naquifer.v&lt;-est.variogram(aquifer_points,aquifer_pair,'resi')\n\n\ng4=ggplot(aquifer, aes(resi, Este)) + \n  geom_point() + \n  geom_line() +\n  xlab(\"Este\") + \n  ylab(\"residuales2\")\n\ng5=ggplot(aquifer, aes(resi, Norte)) + \n  geom_point() + \n  geom_line() +\n  xlab(\"Norte\") + \n  ylab(\"residuales2\")\n\n#plot_grid(g4,g5)\n\n\naquifer_points=point(aquifer, x=\"Este\", y=\"Norte\")\n#fit.trend(aquifer_points,at=\"Profundidad\", np=2, plot.it=TRUE)\n\n\ng6=ggplot(aquifer.v, aes(resi, Norte)) + \n  geom_point() + \n  geom_line() +\n  xlab(\"Norte\") + \n  ylab(\"residuales2\")\n\ng6=ggplot(aquifer.v, aes(bins, classic)) + \n  geom_point() + \n  geom_line() +\n  xlab(\"Rezago espacial, h\") + \n  ylab(\"Estimador clásico del variograma\")\n\ng7=ggplot(aquifer.v, aes(bins, robust)) + \n  geom_point() + \n  geom_line() +\n  xlab(\"Rezago espacial, h\") + \n  ylab(\"Estimador robusto 1 del variograma\")\n\ng8=ggplot(aquifer.v, aes(bins, med)) + \n  geom_point() + \n  geom_line() +\n  xlab(\"Rezago espacial, h\") + \n  ylab(\"Estimador robusto 2 del variograma\")\n\n#plot_grid(g6,g7,g8,nrow=1,ncol=3)\n\n\n#par(mfrow=c(1,3))\nprint(aquifer.v)\n\n   lags      bins   classic    robust       med   n\n1     1  13.55308  43779.20  44355.34  47948.45 285\n2     2  40.65923  71039.50  71176.29  73188.30 350\n3     3  67.76539  80041.91  85367.59  93223.52 492\n4     4  94.87154  67197.27  68067.40  73056.46 719\n5     5 121.97770  73572.25  68052.99  66133.91 612\n6     6 149.08385  57650.90  58608.95  58819.91 521\n7     7 176.19001  65498.82  62167.57  68112.31 356\n8     8 203.29616 130414.72 107613.55  77805.71 173\n9     9 230.40231 161738.13 134102.60 123952.77  43\n10   10 257.50847  35525.99  45217.14  58333.98  19\n\n\n\nplot(aquifer.v$robust)\n\n\n\n\n\n\n\n\n\nplot(aquifer.v$med)\n\n\n\n\n\n\n\n\n\n#points(aquifer.v$robust,col=\"red\")\n#points(aquifer.v$med,\"blue\")\naquifer.vmodExp&lt;-fit.exponential(aquifer.v,c0=0,ce=40000,ae=20,plot.it=TRUE,iterations=30)\n\nInitial parameter estimates:  0 40000 20 \n\n\n\n\n\n\n\n\n\nIteration: 1 \nGradient vector:  -4432.441 977.0988 -8.943538 \nNew parameter estimates:  1e-06 40977.1 11.05646 \n\nrse.dif =  3232643827 (rse = 3232643827 )  ;  parm.dist =  977.1397 \n\n\n\n\n\n\n\n\n\nIteration: 2 \nGradient vector:  -26700.7 22493.46 -2.800242 \nNew parameter estimates:  1e-06 63470.56 8.256219 \n\nrse.dif =  -17644208 (rse = 3.215e+09 )  ;  parm.dist =  22493.46 \n\n\n\n\n\n\n\n\n\nIteration: 3 \nGradient vector:  -11057.27 -15597.73 2.315183 \nNew parameter estimates:  1e-06 47872.83 10.5714 \n\nrse.dif =  -3772568 (rse = 3211227051 )  ;  parm.dist =  15597.73 \n\n\n\n\n\n\n\n\n\nIteration: 4 \nGradient vector:  -27525.12 16431.58 -1.824505 \nNew parameter estimates:  1e-06 64304.41 8.746897 \n\nrse.dif =  3032851 (rse = 3214259902 )  ;  parm.dist =  16431.58 \n\n\n\n\n\n\n\n\n\nIteration: 5 \nGradient vector:  -20442.22 -7053.019 1.144197 \nNew parameter estimates:  1e-06 57251.39 9.891094 \n\nrse.dif =  -2468665 (rse = 3211791237 )  ;  parm.dist =  7053.019 \n\n\n\n\n\n\n\n\n\nIteration: 6 \nGradient vector:  -27557.41 7097.539 -0.7122805 \nNew parameter estimates:  1e-06 64348.93 9.178813 \n\nrse.dif =  1486180 (rse = 3213277417 )  ;  parm.dist =  7097.539 \n\n\n\n\n\n\n\n\n\nIteration: 7 \nGradient vector:  -24787.06 -2758.919 0.3605893 \nNew parameter estimates:  1e-06 61590.01 9.539403 \n\nrse.dif =  -951749.7 (rse = 3212325667 )  ;  parm.dist =  2758.919 \n\n\n\n\n\n\n\n\n\nIteration: 8 \nGradient vector:  -26691.4 1898.737 -0.1885371 \nNew parameter estimates:  1e-06 63488.75 9.350866 \n\nrse.dif =  471370.4 (rse = 3212797038 )  ;  parm.dist =  1898.737 \n\n\n\n\n\n\n\n\n\nIteration: 9 \nGradient vector:  -25850.35 -838.0686 0.09276125 \nNew parameter estimates:  1e-06 62650.68 9.443627 \n\nrse.dif =  -249219.6 (rse = 3212547818 )  ;  parm.dist =  838.0686 \n\n\n\n\n\n\n\n\n\nIteration: 10 \nGradient vector:  -26302.53 450.7265 -0.04631475 \nNew parameter estimates:  1e-06 63101.41 9.397312 \n\nrse.dif =  121873.4 (rse = 3212669692 )  ;  parm.dist =  450.7265 \n\n\n\n\n\n\n\n\n\nIteration: 11 \nGradient vector:  -26086.54 -215.2624 0.02285916 \nNew parameter estimates:  1e-06 62886.14 9.420171 \n\nrse.dif =  -61031.79 (rse = 3212608660 )  ;  parm.dist =  215.2624 \n\n\n\n\n\n\n\n\n\nIteration: 12 \nGradient vector:  -26195.52 108.6221 -0.01133309 \nNew parameter estimates:  1e-06 62994.77 9.408838 \n\nrse.dif =  30077.83 (rse = 3212638738 )  ;  parm.dist =  108.6221 \n\n\n\n\n\n\n\n\n\nIteration: 13 \nGradient vector:  -26142.08 -53.26613 0.005604603 \nNew parameter estimates:  1e-06 62941.5 9.414443 \n\nrse.dif =  -14922.96 (rse = 3212623815 )  ;  parm.dist =  53.26613 \n\n\n\n\n\n\n\n\n\nIteration: 14 \nGradient vector:  -26168.65 26.48517 -0.002774911 \nNew parameter estimates:  1e-06 62967.99 9.411668 \n\nrse.dif =  7377.216 (rse = 3212631192 )  ;  parm.dist =  26.48517 \n\n\n\n\n\n\n\n\n\nIteration: 15 \nGradient vector:  -26155.53 -13.07801 0.001373075 \nNew parameter estimates:  1e-06 62954.91 9.413041 \n\nrse.dif =  -3653.216 (rse = 3212627539 )  ;  parm.dist =  13.07801 \n\n\n\n\n\n\n\n\n\nIteration: 16 \nGradient vector:  -26162.03 6.479831 -0.0006796194 \nNew parameter estimates:  1e-06 62961.39 9.412361 \n\nrse.dif =  1807.514 (rse = 3212629346 )  ;  parm.dist =  6.479831 \n\n\n\n\n\n\n\n\n\nIteration: 17 \nGradient vector:  -26158.82 -3.20516 0.0003363367 \nNew parameter estimates:  1e-06 62958.18 9.412698 \n\nrse.dif =  -894.6895 (rse = 3212628451 )  ;  parm.dist =  3.20516 \n\n\n\n\n\n\n\n\n\nIteration: 18 \nGradient vector:  -26160.41 1.586717 -0.0001664615 \nNew parameter estimates:  1e-06 62959.77 9.412531 \n\nrse.dif =  442.763 (rse = 3212628894 )  ;  parm.dist =  1.586717 \n\n\n\n\n\n\n\n\n\nIteration: 19 \nGradient vector:  -26159.62 -0.7851797 8.238305e-05 \nNew parameter estimates:  1e-06 62958.98 9.412613 \n\nrse.dif =  -219.1369 (rse = 3212628675 )  ;  parm.dist =  0.7851797 \n\n\n\n\n\n\n\n\n\nIteration: 20 \nGradient vector:  -26160.01 0.3886224 -4.077271e-05 \nNew parameter estimates:  1e-06 62959.37 9.412573 \n\nrse.dif =  108.4519 (rse = 3212628784 )  ;  parm.dist =  0.3886224 \n\n\n\n\n\n\n\n\n\nIteration: 21 \nGradient vector:  -26159.82 -0.192328 2.01789e-05 \nNew parameter estimates:  1e-06 62959.18 9.412593 \n\nrse.dif =  -53.67477 (rse = 3212628730 )  ;  parm.dist =  0.192328 \n\n\n\n\n\n\n\n\n\nIteration: 22 \nGradient vector:  -26159.91 0.09518727 -9.986825e-06 \nNew parameter estimates:  1e-06 62959.28 9.412583 \n\nrse.dif =  26.56425 (rse = 3212628756 )  ;  parm.dist =  0.09518727 \n\n\n\n\n\n\n\n\n\nIteration: 23 \nGradient vector:  -26159.86 -0.04710907 4.94261e-06 \nNew parameter estimates:  1e-06 62959.23 9.412588 \n\nrse.dif =  -13.14703 (rse = 3212628743 )  ;  parm.dist =  0.04710907 \n\n\n\n\n\n\n\n\n\nIteration: 24 \nGradient vector:  -26159.89 0.023315 -2.446165e-06 \nNew parameter estimates:  1e-06 62959.25 9.412585 \n\nrse.dif =  6.506634 (rse = 3212628750 )  ;  parm.dist =  0.023315 \n\n\n\n\n\n\n\n\n\nIteration: 25 \nGradient vector:  -26159.88 -0.01153889 1.21064e-06 \nNew parameter estimates:  1e-06 62959.24 9.412587 \n\nrse.dif =  -3.220222 (rse = 3212628747 )  ;  parm.dist =  0.01153889 \n\n\n\n\n\n\n\n\n\nIteration: 26 \nGradient vector:  -26159.88 0.005710764 -5.991627e-07 \nNew parameter estimates:  1e-06 62959.25 9.412586 \n\nrse.dif =  1.593734 (rse = 3212628748 )  ;  parm.dist =  0.005710764 \n\n\n\n\n\n\n\n\n\nIteration: 27 \nGradient vector:  -26159.88 -0.002826342 2.965346e-07 \nNew parameter estimates:  1e-06 62959.24 9.412586 \n\nrse.dif =  -0.7887611 (rse = 3212628747 )  ;  parm.dist =  0.002826342 \n\n\n\n\n\n\n\n\n\nIteration: 28 \nGradient vector:  -26159.88 0.001398795 -1.467591e-07 \nNew parameter estimates:  1e-06 62959.24 9.412586 \n\nrse.dif =  0.3903689 (rse = 3212628748 )  ;  parm.dist =  0.001398795 \n\n\n\n\n\n\n\n\n\nIteration: 29 \nGradient vector:  -26159.88 -0.0006922812 7.263288e-08 \nNew parameter estimates:  1e-06 62959.24 9.412586 \n\nrse.dif =  -0.1932006 (rse = 3212628748 )  ;  parm.dist =  0.0006922812 \n\n\n\n\n\n\n\n\n\nIteration: 30 \nGradient vector:  -26159.88 0.000342624 -3.594748e-08 \nNew parameter estimates:  1e-06 62959.24 9.412586 \n\nrse.dif =  0.09561825 (rse = 3212628748 )  ;  parm.dist =  0.000342624 \n\n\n\n\n\n\n\n\n\nConvergence not achieved!\n\n\n\naquifer.vmodGau&lt;-fit.gaussian(aquifer.v,c0=0,cg=50000,ag=50,plot.it=TRUE,iterations=30)\n\nInitial parameter estimates:  0 50000 50 \n\n\n\n\n\n\n\n\n\nIteration: 1 \nGradient vector:  19162.34 -33401.14 -11.41191 \nNew parameter estimates:  19162.34 16598.86 38.58809 \n\nrse.dif =  3299750048 (rse = 3299750048 )  ;  parm.dist =  38507.55 \n\n\n\n\n\n\n\n\n\nIteration: 2 \nGradient vector:  -1294.927 2010.017 -18.77473 \nNew parameter estimates:  17867.41 18608.87 19.81336 \n\nrse.dif =  -66430135 (rse = 3233319913 )  ;  parm.dist =  2391.1 \n\n\n\n\n\n\n\n\n\nIteration: 3 \nGradient vector:  3201.043 -2835.169 9.216254 \nNew parameter estimates:  21068.46 15773.71 29.02961 \n\nrse.dif =  -24694350 (rse = 3208625564 )  ;  parm.dist =  4276.09 \n\n\n\n\n\n\n\n\n\nIteration: 4 \nGradient vector:  -4345.272 4292.413 -6.361973 \nNew parameter estimates:  16723.18 20066.12 22.66764 \n\nrse.dif =  4004881 (rse = 3212630445 )  ;  parm.dist =  6107.884 \n\n\n\n\n\n\n\n\n\nIteration: 5 \nGradient vector:  53.88685 -4.270081 2.074271 \nNew parameter estimates:  16777.07 20061.85 24.74191 \n\nrse.dif =  -3703977 (rse = 3208926468 )  ;  parm.dist =  54.09555 \n\n\n\n\n\n\n\n\n\nIteration: 6 \nGradient vector:  -391.4471 384.4526 -0.5571294 \nNew parameter estimates:  16385.62 20446.3 24.18478 \n\nrse.dif =  588163 (rse = 3209514631 )  ;  parm.dist =  548.6666 \n\n\n\n\n\n\n\n\n\nIteration: 7 \nGradient vector:  29.55911 -27.0943 0.07968918 \nNew parameter estimates:  16415.18 20419.21 24.26447 \n\nrse.dif =  -201438.9 (rse = 3209313192 )  ;  parm.dist =  40.09799 \n\n\n\n\n\n\n\n\n\nIteration: 8 \nGradient vector:  -6.581211 6.259206 -0.01207028 \nNew parameter estimates:  16408.6 20425.47 24.2524 \n\nrse.dif =  26607.8 (rse = 3209339800 )  ;  parm.dist =  9.082408 \n\n\n\n\n\n\n\n\n\nIteration: 9 \nGradient vector:  0.9423146 -0.8928955 0.001794561 \nNew parameter estimates:  16409.54 20424.57 24.25419 \n\nrse.dif =  -4077.43 (rse = 3209335722 )  ;  parm.dist =  1.298161 \n\n\n\n\n\n\n\n\n\nIteration: 10 \nGradient vector:  -0.1413215 0.1339887 -0.0002673761 \nNew parameter estimates:  16409.4 20424.71 24.25393 \n\nrse.dif =  605.1536 (rse = 3209336327 )  ;  parm.dist =  0.194743 \n\n\n\n\n\n\n\n\n\nIteration: 11 \nGradient vector:  0.02102884 -0.01993597 3.982407e-05 \nNew parameter estimates:  16409.42 20424.69 24.25397 \n\nrse.dif =  -90.18701 (rse = 3209336237 )  ;  parm.dist =  0.02897682 \n\n\n\n\n\n\n\n\n\nIteration: 12 \nGradient vector:  -0.003132718 0.00296995 -5.931842e-06 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  13.43229 (rse = 3209336251 )  ;  parm.dist =  0.004316777 \n\n\n\n\n\n\n\n\n\nIteration: 13 \nGradient vector:  0.0004666088 -0.0004423641 8.835486e-07 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  -2.000767 (rse = 3209336249 )  ;  parm.dist =  0.0006429701 \n\n\n\n\n\n\n\n\n\nIteration: 14 \nGradient vector:  -6.950171e-05 6.589045e-05 -1.316048e-07 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  0.2980142 (rse = 3209336249 )  ;  parm.dist =  9.577086e-05 \n\n\n\n\n\n\n\n\n\nIteration: 15 \nGradient vector:  1.035229e-05 -9.814388e-06 1.960254e-08 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  -0.04438925 (rse = 3209336249 )  ;  parm.dist =  1.426508e-05 \n\n\n\n\n\n\n\n\n\nIteration: 16 \nGradient vector:  -1.542e-06 1.46188e-06 -2.919839e-09 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  0.006612301 (rse = 3209336249 )  ;  parm.dist =  2.124821e-06 \n\n\n\n\n\n\n\n\n\nIteration: 17 \nGradient vector:  2.296994e-07 -2.177628e-07 4.349363e-10 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  -0.0009851456 (rse = 3209336249 )  ;  parm.dist =  3.165152e-07 \n\n\n\n\n\n\n\n\n\nIteration: 18 \nGradient vector:  -3.420782e-08 3.242781e-08 -6.477718e-11 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  0.0001473427 (rse = 3209336249 )  ;  parm.dist =  4.713621e-08 \n\n\n\n\n\n\n\n\n\nIteration: 19 \nGradient vector:  5.086605e-09 -4.821087e-09 9.637383e-12 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  -2.193451e-05 (rse = 3209336249 )  ;  parm.dist =  7.007276e-09 \n\n\n\n\n\n\n\n\n\nIteration: 20 \nGradient vector:  -7.583935e-10 7.161523e-10 -1.439258e-12 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  2.861023e-06 (rse = 3209336249 )  ;  parm.dist =  1.042223e-09 \n\n\n\n\n\n\n\n\n\nIteration: 21 \nGradient vector:  1.019258e-10 -9.775917e-11 1.99309e-13 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  -4.768372e-07 (rse = 3209336249 )  ;  parm.dist =  1.415077e-10 \n\nConvergence achieved by sums of squares.\n\n\n\n\n\n\n\n\n\nFinal parameter estimates:  16409.42 20424.69 24.25396 \n\n\n\naquifer.vmodWave&lt;-fit.wave(aquifer.v,c0=0,cw=40000,aw=10,plot.it=TRUE,iterations=30,weighted=T)\n\nInitial parameter estimates:  0 40000 10 \n\n\n\n\n\n\n\n\n\nIteration: 1 \nGradient vector:  18650.32 -21981.27 -0.7942028 \nNew parameter estimates:  18650.32 18018.73 9.205797 \n\nrse.dif =  3409704989 (rse = 3409704989 )  ;  parm.dist =  28827.26 \n\n\n\n\n\n\n\n\n\nIteration: 2 \nGradient vector:  812.9227 -1109.399 -1.187299 \nNew parameter estimates:  19463.25 16909.33 8.018498 \n\nrse.dif =  -289093760 (rse = 3120611230 )  ;  parm.dist =  1375.358 \n\n\n\n\n\n\n\n\n\nIteration: 3 \nGradient vector:  -6990.158 6973.566 0.9858099 \nNew parameter estimates:  12473.09 23882.9 9.004308 \n\nrse.dif =  24044562 (rse = 3144655792 )  ;  parm.dist =  9873.851 \n\n\n\n\n\n\n\n\n\nIteration: 4 \nGradient vector:  7025.438 -6960.473 -1.260353 \nNew parameter estimates:  19498.53 16922.43 7.743955 \n\nrse.dif =  -56767551 (rse = 3087888241 )  ;  parm.dist =  9889.639 \n\n\n\n\n\n\n\n\n\nIteration: 5 \nGradient vector:  -9210.154 9213.61 1.066674 \nNew parameter estimates:  10288.37 26136.04 8.810629 \n\nrse.dif =  175986924 (rse = 3263875165 )  ;  parm.dist =  13027.57 \n\n\n\n\n\n\n\n\n\nIteration: 6 \nGradient vector:  11994.7 -11983.26 -2.255679 \nNew parameter estimates:  22283.07 14152.77 6.55495 \n\nrse.dif =  -196728543 (rse = 3067146622 )  ;  parm.dist =  16954.98 \n\n\n\n\n\n\n\n\n\nIteration: 7 \nGradient vector:  -14060.45 14195.04 -1.578095 \nNew parameter estimates:  8222.625 28347.81 4.976855 \n\nrse.dif =  147278852 (rse = 3214425474 )  ;  parm.dist =  19979.87 \n\n\n\n\n\n\n\n\n\nIteration: 8 \nGradient vector:  -15826.64 16212.91 0.3854677 \nNew parameter estimates:  1e-06 44560.72 5.362323 \n\nrse.dif =  -46983778 (rse = 3167441696 )  ;  parm.dist =  18178.84 \n\n\n\n\n\n\n\n\n\nIteration: 9 \nGradient vector:  13145.08 -21444.98 -0.8756698 \nNew parameter estimates:  13145.08 23115.75 4.486653 \n\nrse.dif =  -757940879 (rse = 2409500817 )  ;  parm.dist =  25153.13 \n\n\n\n\n\n\n\n\n\nIteration: 10 \nGradient vector:  -9434763 9682459 25.73116 \nNew parameter estimates:  1e-06 9705575 30.21781 \n\nrse.dif =  1636307005 (rse = 4045807822 )  ;  parm.dist =  9682468 \n\n\n\n\n\n\n\n\n\nIteration: 11 \nGradient vector:  20962.2 -9688482 0.02156687 \nNew parameter estimates:  20962.2 17093.21 30.23938 \n\nrse.dif =  83628062 (rse = 4129435883 )  ;  parm.dist =  9688504 \n\n\n\n\n\n\n\n\n\nIteration: 12 \nGradient vector:  7173.136 -8587.116 1.22582 \nNew parameter estimates:  28135.34 8506.099 31.4652 \n\nrse.dif =  -628497356 (rse = 3500938527 )  ;  parm.dist =  11188.94 \n\n\n\n\n\n\n\n\n\nIteration: 13 \nGradient vector:  2974.651 -2890.861 -4.19572 \nNew parameter estimates:  31109.99 5615.237 27.26947 \n\nrse.dif =  -192443200 (rse = 3308495327 )  ;  parm.dist =  4147.969 \n\n\n\n\n\n\n\n\n\nIteration: 14 \nGradient vector:  -2399.351 1443.698 15.69929 \nNew parameter estimates:  28710.64 7058.936 42.96876 \n\nrse.dif =  147479203 (rse = 3455974530 )  ;  parm.dist =  2800.25 \n\n\n\n\n\n\n\n\n\nIteration: 15 \nGradient vector:  4786.661 2165.107 -43.14322 \nNew parameter estimates:  33497.3 9224.042 1e-06 \n\nrse.dif =  -686128323 (rse = 2769846206 )  ;  parm.dist =  5253.728 \n\n\nIteration: 16 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\n\n\n\n\n\n\n\nGradient vector:  -7188.309 -5.926894e-07 0 \nNew parameter estimates:  26308.99 9224.042 1e-06 \n\nrse.dif =  686457465 (rse = 3456303671 )  ;  parm.dist =  7188.309 \n\n\nIteration: 17 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\n\n\n\n\n\n\n\nGradient vector:  -5.339328e-06 -5.926894e-07 0 \nNew parameter estimates:  26308.99 9224.042 1e-06 \n\nrse.dif =  0.4889331 (rse = 3456303672 )  ;  parm.dist =  5.372122e-06 \n\n\nIteration: 18 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\n\n\n\n\n\n\n\nGradient vector:  5.926852e-07 -5.926894e-07 0 \nNew parameter estimates:  26308.99 9224.042 1e-06 \n\nrse.dif =  1.907349e-06 (rse = 3456303672 )  ;  parm.dist =  8.381857e-07 \n\n\nIteration: 19 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\n\n\n\n\n\n\n\nGradient vector:  5.926931e-07 -5.926894e-07 0 \nNew parameter estimates:  26308.99 9224.042 1e-06 \n\nrse.dif =  -9.536743e-07 (rse = 3456303672 )  ;  parm.dist =  8.381908e-07 \n\nConvergence achieved by sums of squares.\n\n\n\n\n\n\n\n\n\nFinal parameter estimates:  26308.99 9224.042 1e-06 \n\n\n\ncurve(65000*(1-(14/x)*sin(x/14)),0,300,ylim=c(0,200000))\npoints(aquifer.v$bins,aquifer.v$classic,col=3)\ntext(aquifer.v$bins,aquifer.v$classic,aquifer.v$n,col=2)\n\n\n\n\n\n\n\n\n\ncurve(200000*(1-exp(-x/170)),0,300)\npoints(aquifer.v$bins,aquifer.v$classic,col=2)\n\n\n\n\n\n\n\n\n\ncurve(65000*(1-(14/x)*sin(x/14)),0,300,ylim=c(0,200000))\npoints(aquifer.v$bins,aquifer.v$classic,col=3)\ntext(aquifer.v$bins,aquifer.v$classic,aquifer.v$n,col=2)\n\n\n\n\n\n\n\n\n\naquifer.vmodExp&lt;-fit.exponential(aquifer.v,c0=0,ce=200000,ae=170,plot.it=TRUE,iterations=30,weighted=T)\n\nInitial parameter estimates:  0 2e+05 170 \n\n\n\n\n\n\n\n\n\nIteration: 1 \nGradient vector:  16365.66 -238859.4 -103.7436 \nNew parameter estimates:  16365.66 1e-06 66.25643 \n\nrse.dif =  3826411368 (rse = 3826411368 )  ;  parm.dist =  200668.5 \n\n\n\n\n\n\n\n\n\nIteration: 2 \nGradient vector:  7737.246 16547.95 166070861252 \nNew parameter estimates:  24102.91 16547.95 166070861318 \n\nrse.dif =  -767474321 (rse = 3058937047 )  ;  parm.dist =  166070861252 \n\n\nIteration: 3 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\n\n\n\n\n\n\n\nGradient vector:  3355.03 1.242479e+13 0 \nNew parameter estimates:  27457.94 1.242479e+13 166070861318 \n\nrse.dif =  -120011141 (rse = 2938925906 )  ;  parm.dist =  1.242479e+13 \n\n\nIteration: 4 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\n\n\n\n\n\n\n\nGradient vector:  423.3165 -663474885968 0 \nNew parameter estimates:  27881.25 1.176131e+13 166070861318 \n\nrse.dif =  11801483 (rse = 2950727388 )  ;  parm.dist =  663474885968 \n\n\nIteration: 5 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\n\n\n\n\n\n\n\nGradient vector:  3.873181 -6320523090 0 \nNew parameter estimates:  27885.12 1.175499e+13 166070861318 \n\nrse.dif =  128956.4 (rse = 2950856345 )  ;  parm.dist =  6320523090 \n\n\nIteration: 6 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\n\n\n\n\n\n\n\nGradient vector:  0.02266712 -36921321 0 \nNew parameter estimates:  27885.15 1.175495e+13 166070861318 \n\nrse.dif =  752.3639 (rse = 2950857097 )  ;  parm.dist =  36921321 \n\n\nIteration: 7 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\n\n\n\n\n\n\n\nGradient vector:  0.0001316946 -214507.3 0 \nNew parameter estimates:  27885.15 1.175495e+13 166070861318 \n\nrse.dif =  4.371067 (rse = 2950857102 )  ;  parm.dist =  214507.3 \n\n\nIteration: 8 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\n\n\n\n\n\n\n\nGradient vector:  7.650992e-07 -1246.212 0 \nNew parameter estimates:  27885.15 1.175495e+13 166070861318 \n\nrse.dif =  0.02539396 (rse = 2950857102 )  ;  parm.dist =  1246.213 \n\n\nIteration: 9 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\n\n\n\n\n\n\n\nGradient vector:  4.447233e-09 -7.24441 0 \nNew parameter estimates:  27885.15 1.175495e+13 166070861318 \n\nrse.dif =  0.0001473427 (rse = 2950857102 )  ;  parm.dist =  7.244141 \n\n\nIteration: 10 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\n\n\n\n\n\n\n\nGradient vector:  2.31966e-11 -0.03646515 0 \nNew parameter estimates:  27885.15 1.175495e+13 166070861318 \n\nrse.dif =  9.536743e-07 (rse = 2950857102 )  ;  parm.dist =  0.03710938 \n\nConvergence achieved by sums of squares.\n\n\n\n\n\n\n\n\n\nFinal parameter estimates:  27885.15 1.175495e+13 166070861318 \n\n\n\naquifer.vmodwave&lt;-fit.wave(aquifer.v,c0=4000,cw=30000,aw=15,plot.it=TRUE,iterations=0,weighted=T)\n\n\n\n\n\n\n\n\nConvergence not achieved!\n\n\n\naquifer.vmodExp_0&lt;-fit.exponential(aquifer.v,c0=0,ce=200000,ae=170,plot.it=TRUE,iterations=0,weighted=T)\n\n\n\n\n\n\n\n\nConvergence not achieved!\n\n\n\naquifer.vmodwave_0&lt;-fit.wave(aquifer.v,c0=4000,cw=30000,aw=15,plot.it=TRUE,iterations=0,weighted=T)\n\n\n\n\n\n\n\n\nConvergence not achieved!\n\n\n\naquifer.spherical&lt;-fit.spherical(aquifer.v,c0=0,cs=35000,as=70,plot.it=TRUE,iterations=0,weighted=T)\n\n\n\n\n\n\n\n\nConvergence not achieved!\n\n\n\n#ggplot(aquifer.v, aes(bins, classic)) + \n#  geom_point() + \n#  geom_line() +\n#  xlab(\"Rezago espacial, h\") + \n#  ylab(\"Estimador clásico del variograma\")+\n#  xlim(0, 300) +\n#  geom_function(aes(color = \"Exponencial\"),\n#    fun =~4000+150000*(1-exp(-.x/100)) \n#    ) +\n#  geom_function(aes(color = \"Seno cardinal\"),\n#    fun =~4000+30000*(1-((15/.x)*sin(.x/15)))             \n#    ) + xlab(\"Rezago espacial\") + ylab(\"Modelos teóricos de #semivariogramas\") \n\n\nKriging_aquifer &lt;- point(data.frame(list(x=10,y=80)))\nKriging_aquifer &lt;- krige(Kriging_aquifer, aquifer_points, 'resi', aquifer.vmodExp_0)\n\n\nUsing all points.\n  Preparing the kriging system matrix...\n  Inverting the matrix...\n  Predicting.\n\n\n\nKriging_aquifer\n\n\nPoint object: x \n\n   Locations: 1\n\n   Attributes:\n      x\n      y\n      do\n      zhat\n      sigma2hat\n\n\n\n#Kriging_aquifer$sigma2hat\n\n\nKriging_aquifer &lt;- point(data.frame(list(x=10,y=80)))\nKriging_aquifer &lt;- krige(Kriging_aquifer, aquifer_points, 'resi', aquifer.vmodwave_0)\n\n\nUsing all points.\n  Preparing the kriging system matrix...\n  Inverting the matrix...\n  Predicting.\n\n\n\nKriging_aquifer\n\n\nPoint object: x \n\n   Locations: 1\n\n   Attributes:\n      x\n      y\n      do\n      zhat\n      sigma2hat\n\n\n\n#Kriging_aquifer$zhat\n\n\n#Kriging_aquifer$sigma2hat\n\n\ngrid &lt;- list(x=seq(min(aquifer$Este),max(aquifer$Este),by=20),y=seq(min(aquifer$Norte),max(aquifer$Norte),by=10))\ngrid$xr &lt;- range(grid$x)\ngrid$xs &lt;- grid$xr[2] - grid$xr[1]\ngrid$yr &lt;- range(grid$y)\ngrid$ys &lt;- grid$yr[2] - grid$yr[1]\ngrid$max &lt;- max(grid$xs, grid$ys)\ngrid$xy &lt;- data.frame(cbind(c(matrix(grid$x, length(grid$x), length(grid$y))),\nc(matrix(grid$y, length(grid$x), length(grid$y), byrow=TRUE))))\ncolnames(grid$xy) &lt;- c(\"x\", \"y\")\ngrid$point &lt;- point(grid$xy)\ngrid$krige &lt;- krige(grid$point,aquifer_points,'resi',aquifer.vmodwave_0,maxdist=180,extrap=FALSE)\n\n\nUsing points within 180 units of prediction points.\n  Predicting..........................................................................................................................................................................................................................................\n\n\n\nop &lt;- par(no.readonly = TRUE)\npar(pty=\"s\")\nplot(grid$xy, type=\"n\", xlim=c(grid$xr[1], grid$xr[1]+grid$max),ylim=c(grid$yr[1], grid$yr[1]+grid$max))\nimage(grid$x,grid$y,matrix(grid$krige$zhat,length(grid$x),length(grid$y)),add=TRUE)\ncontour(grid$x,grid$y,matrix(grid$krige$zhat,length(grid$x),length(grid$y)),add=TRUE)\n\n\n\n\n\n\n\n\n\nx11()\nop &lt;- par(no.readonly = TRUE)\npar(pty=\"s\")\nplot(grid$xy, type=\"n\", xlim=c(grid$xr[1], grid$xr[1]+grid$max),ylim=c(grid$yr[1], grid$yr[1]+grid$max))\nimage(grid$x,grid$y,matrix(grid$krige$sigma2hat,length(grid$x),length(grid$y)), add=TRUE)\ncontour(grid$x,grid$y,matrix(grid$krige$sigma2hat,length(grid$x),length(grid$y)),add=TRUE)",
    "crumbs": [
      "Geoestadística",
      "Geoestadística con Sgeostat"
    ]
  },
  {
    "objectID": "GeoestadísticaConSgeostat.html#data-load",
    "href": "GeoestadísticaConSgeostat.html#data-load",
    "title": "Geoestadística con sgeostat",
    "section": "",
    "text": "rm(list=ls())\naquifer=read.table(\"data/aquifer.txt\",head=T,dec=\",\")\nhead(aquifer)\n\n       Este     Norte Profundidad\n1  42.78275 127.62282        1464\n2 -27.39691  90.78732        2553\n3  -1.16289  84.89600        2158\n4 -18.61823  76.45199        2455\n5  96.46549  64.58058        1756\n6 108.56243  82.92325        1702",
    "crumbs": [
      "Geoestadística",
      "Geoestadística con Sgeostat"
    ]
  },
  {
    "objectID": "GeoestadísticaConSgeostat.html#libraries",
    "href": "GeoestadísticaConSgeostat.html#libraries",
    "title": "Geoestadística con sgeostat",
    "section": "",
    "text": "library(scatterplot3d)\nlibrary(ggplot2)\nlibrary(cowplot)\nlibrary(sgeostat)",
    "crumbs": [
      "Geoestadística",
      "Geoestadística con Sgeostat"
    ]
  },
  {
    "objectID": "GeoestadísticaConSgeostat.html#including-plots",
    "href": "GeoestadísticaConSgeostat.html#including-plots",
    "title": "Geoestadística con sgeostat",
    "section": "",
    "text": "g1=ggplot(aquifer, aes(Profundidad, Este)) + \n  geom_point() + \n  geom_line() +\n  xlab(\"Este\") + \n  ylab(\"Profundidad\")\n\ng2=ggplot(aquifer, aes(Profundidad, Norte)) + \n  geom_point() + \n  geom_line() +\n  xlab(\"Norte\") + \n  ylab(\"Profundidad\")\n\ng3=ggplot(aquifer, aes(Profundidad, Este*Norte)) + \n  geom_point() + \n  geom_line() +\n  xlab(\"Interacción este,norte\") + \n  ylab(\"Profundidad\")\n\n\n#plot_grid(g1,g2,g3)\n\n\n#cor(aquifer)\n\n\nscatterplot3d(aquifer, highlight.3d=TRUE, col.axis=\"blue\",\ncol.grid=\"lightblue\", main=\"Tendencia de Profundidad\", pch=20)\n\n\n\n\n\n\n\n\n\nreg1 &lt;- lm(Profundidad ~ Este + Norte, data = aquifer)\nresiduales1  &lt;-  residuals(reg1)\n#summary(reg1)\n\n\nanova(reg1)\n\nAnalysis of Variance Table\n\nResponse: Profundidad\n          Df   Sum Sq  Mean Sq F value    Pr(&gt;F)    \nEste       1 19045642 19045642  460.95 &lt; 2.2e-16 ***\nNorte      1  8960172  8960172  216.86 &lt; 2.2e-16 ***\nResiduals 82  3388069    41318                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nreg2 &lt;- lm(Profundidad ~ Este*Norte, data = aquifer)\nresiduales2  &lt;-  residuals(reg2)\n#summary(reg2)\n\n\nanova(reg2)\n\nAnalysis of Variance Table\n\nResponse: Profundidad\n           Df   Sum Sq  Mean Sq F value    Pr(&gt;F)    \nEste        1 19045642 19045642  517.06 &lt; 2.2e-16 ***\nNorte       1  8960172  8960172  243.25 &lt; 2.2e-16 ***\nEste:Norte  1   404448   404448   10.98  0.001379 ** \nResiduals  81  2983621    36835                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nreg3 &lt;- lm(Profundidad ~ Este*Norte+I(Este^2)*I(Norte^2), data = aquifer)\nresiduales3  &lt;-  residuals(reg3)\n#summary(reg3)\n\n\nanova(reg3)\n\nAnalysis of Variance Table\n\nResponse: Profundidad\n                     Df   Sum Sq  Mean Sq  F value    Pr(&gt;F)    \nEste                  1 19045642 19045642 583.2335 &lt; 2.2e-16 ***\nNorte                 1  8960172  8960172 274.3868 &lt; 2.2e-16 ***\nI(Este^2)             1    55368    55368   1.6955 0.1967061    \nI(Norte^2)            1   152170   152170   4.6599 0.0339500 *  \nEste:Norte            1   451567   451567  13.8283 0.0003755 ***\nI(Este^2):I(Norte^2)  1   181854   181854   5.5689 0.0207829 *  \nResiduals            78  2547110    32655                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\naquifer=data.frame(aquifer,resi=residuales2)\naquifer_points=point(aquifer, x=\"Este\", y=\"Norte\")\naquifer_pair=pair(aquifer_points,num.lags=10)\n\n....................................................................................\n\n\n\nstr(aquifer_pair)\n\nList of 5\n $ from: num [1:3570] 1 1 1 1 1 1 1 1 1 1 ...\n $ to  : num [1:3570] 2 3 4 5 6 7 8 9 10 11 ...\n $ lags: Factor w/ 10 levels \"1\",\"2\",\"3\",\"4\",..: 3 3 3 4 3 4 4 4 4 4 ...\n $ dist: num [1:3570] 79.3 61.3 79.9 82.8 79.5 ...\n $ bins: num [1:10] 13.6 40.7 67.8 94.9 122 ...\n - attr(*, \"type\")= chr \"isotropic\"\n - attr(*, \"class\")= chr \"pair\"\n\n\n\naquifer.v&lt;-est.variogram(aquifer_points,aquifer_pair,'resi')\n\n\ng4=ggplot(aquifer, aes(resi, Este)) + \n  geom_point() + \n  geom_line() +\n  xlab(\"Este\") + \n  ylab(\"residuales2\")\n\ng5=ggplot(aquifer, aes(resi, Norte)) + \n  geom_point() + \n  geom_line() +\n  xlab(\"Norte\") + \n  ylab(\"residuales2\")\n\n#plot_grid(g4,g5)\n\n\naquifer_points=point(aquifer, x=\"Este\", y=\"Norte\")\n#fit.trend(aquifer_points,at=\"Profundidad\", np=2, plot.it=TRUE)\n\n\ng6=ggplot(aquifer.v, aes(resi, Norte)) + \n  geom_point() + \n  geom_line() +\n  xlab(\"Norte\") + \n  ylab(\"residuales2\")\n\ng6=ggplot(aquifer.v, aes(bins, classic)) + \n  geom_point() + \n  geom_line() +\n  xlab(\"Rezago espacial, h\") + \n  ylab(\"Estimador clásico del variograma\")\n\ng7=ggplot(aquifer.v, aes(bins, robust)) + \n  geom_point() + \n  geom_line() +\n  xlab(\"Rezago espacial, h\") + \n  ylab(\"Estimador robusto 1 del variograma\")\n\ng8=ggplot(aquifer.v, aes(bins, med)) + \n  geom_point() + \n  geom_line() +\n  xlab(\"Rezago espacial, h\") + \n  ylab(\"Estimador robusto 2 del variograma\")\n\n#plot_grid(g6,g7,g8,nrow=1,ncol=3)\n\n\n#par(mfrow=c(1,3))\nprint(aquifer.v)\n\n   lags      bins   classic    robust       med   n\n1     1  13.55308  43779.20  44355.34  47948.45 285\n2     2  40.65923  71039.50  71176.29  73188.30 350\n3     3  67.76539  80041.91  85367.59  93223.52 492\n4     4  94.87154  67197.27  68067.40  73056.46 719\n5     5 121.97770  73572.25  68052.99  66133.91 612\n6     6 149.08385  57650.90  58608.95  58819.91 521\n7     7 176.19001  65498.82  62167.57  68112.31 356\n8     8 203.29616 130414.72 107613.55  77805.71 173\n9     9 230.40231 161738.13 134102.60 123952.77  43\n10   10 257.50847  35525.99  45217.14  58333.98  19\n\n\n\nplot(aquifer.v$robust)\n\n\n\n\n\n\n\n\n\nplot(aquifer.v$med)\n\n\n\n\n\n\n\n\n\n#points(aquifer.v$robust,col=\"red\")\n#points(aquifer.v$med,\"blue\")\naquifer.vmodExp&lt;-fit.exponential(aquifer.v,c0=0,ce=40000,ae=20,plot.it=TRUE,iterations=30)\n\nInitial parameter estimates:  0 40000 20 \n\n\n\n\n\n\n\n\n\nIteration: 1 \nGradient vector:  -4432.441 977.0988 -8.943538 \nNew parameter estimates:  1e-06 40977.1 11.05646 \n\nrse.dif =  3232643827 (rse = 3232643827 )  ;  parm.dist =  977.1397 \n\n\n\n\n\n\n\n\n\nIteration: 2 \nGradient vector:  -26700.7 22493.46 -2.800242 \nNew parameter estimates:  1e-06 63470.56 8.256219 \n\nrse.dif =  -17644208 (rse = 3.215e+09 )  ;  parm.dist =  22493.46 \n\n\n\n\n\n\n\n\n\nIteration: 3 \nGradient vector:  -11057.27 -15597.73 2.315183 \nNew parameter estimates:  1e-06 47872.83 10.5714 \n\nrse.dif =  -3772568 (rse = 3211227051 )  ;  parm.dist =  15597.73 \n\n\n\n\n\n\n\n\n\nIteration: 4 \nGradient vector:  -27525.12 16431.58 -1.824505 \nNew parameter estimates:  1e-06 64304.41 8.746897 \n\nrse.dif =  3032851 (rse = 3214259902 )  ;  parm.dist =  16431.58 \n\n\n\n\n\n\n\n\n\nIteration: 5 \nGradient vector:  -20442.22 -7053.019 1.144197 \nNew parameter estimates:  1e-06 57251.39 9.891094 \n\nrse.dif =  -2468665 (rse = 3211791237 )  ;  parm.dist =  7053.019 \n\n\n\n\n\n\n\n\n\nIteration: 6 \nGradient vector:  -27557.41 7097.539 -0.7122805 \nNew parameter estimates:  1e-06 64348.93 9.178813 \n\nrse.dif =  1486180 (rse = 3213277417 )  ;  parm.dist =  7097.539 \n\n\n\n\n\n\n\n\n\nIteration: 7 \nGradient vector:  -24787.06 -2758.919 0.3605893 \nNew parameter estimates:  1e-06 61590.01 9.539403 \n\nrse.dif =  -951749.7 (rse = 3212325667 )  ;  parm.dist =  2758.919 \n\n\n\n\n\n\n\n\n\nIteration: 8 \nGradient vector:  -26691.4 1898.737 -0.1885371 \nNew parameter estimates:  1e-06 63488.75 9.350866 \n\nrse.dif =  471370.4 (rse = 3212797038 )  ;  parm.dist =  1898.737 \n\n\n\n\n\n\n\n\n\nIteration: 9 \nGradient vector:  -25850.35 -838.0686 0.09276125 \nNew parameter estimates:  1e-06 62650.68 9.443627 \n\nrse.dif =  -249219.6 (rse = 3212547818 )  ;  parm.dist =  838.0686 \n\n\n\n\n\n\n\n\n\nIteration: 10 \nGradient vector:  -26302.53 450.7265 -0.04631475 \nNew parameter estimates:  1e-06 63101.41 9.397312 \n\nrse.dif =  121873.4 (rse = 3212669692 )  ;  parm.dist =  450.7265 \n\n\n\n\n\n\n\n\n\nIteration: 11 \nGradient vector:  -26086.54 -215.2624 0.02285916 \nNew parameter estimates:  1e-06 62886.14 9.420171 \n\nrse.dif =  -61031.79 (rse = 3212608660 )  ;  parm.dist =  215.2624 \n\n\n\n\n\n\n\n\n\nIteration: 12 \nGradient vector:  -26195.52 108.6221 -0.01133309 \nNew parameter estimates:  1e-06 62994.77 9.408838 \n\nrse.dif =  30077.83 (rse = 3212638738 )  ;  parm.dist =  108.6221 \n\n\n\n\n\n\n\n\n\nIteration: 13 \nGradient vector:  -26142.08 -53.26613 0.005604603 \nNew parameter estimates:  1e-06 62941.5 9.414443 \n\nrse.dif =  -14922.96 (rse = 3212623815 )  ;  parm.dist =  53.26613 \n\n\n\n\n\n\n\n\n\nIteration: 14 \nGradient vector:  -26168.65 26.48517 -0.002774911 \nNew parameter estimates:  1e-06 62967.99 9.411668 \n\nrse.dif =  7377.216 (rse = 3212631192 )  ;  parm.dist =  26.48517 \n\n\n\n\n\n\n\n\n\nIteration: 15 \nGradient vector:  -26155.53 -13.07801 0.001373075 \nNew parameter estimates:  1e-06 62954.91 9.413041 \n\nrse.dif =  -3653.216 (rse = 3212627539 )  ;  parm.dist =  13.07801 \n\n\n\n\n\n\n\n\n\nIteration: 16 \nGradient vector:  -26162.03 6.479831 -0.0006796194 \nNew parameter estimates:  1e-06 62961.39 9.412361 \n\nrse.dif =  1807.514 (rse = 3212629346 )  ;  parm.dist =  6.479831 \n\n\n\n\n\n\n\n\n\nIteration: 17 \nGradient vector:  -26158.82 -3.20516 0.0003363367 \nNew parameter estimates:  1e-06 62958.18 9.412698 \n\nrse.dif =  -894.6895 (rse = 3212628451 )  ;  parm.dist =  3.20516 \n\n\n\n\n\n\n\n\n\nIteration: 18 \nGradient vector:  -26160.41 1.586717 -0.0001664615 \nNew parameter estimates:  1e-06 62959.77 9.412531 \n\nrse.dif =  442.763 (rse = 3212628894 )  ;  parm.dist =  1.586717 \n\n\n\n\n\n\n\n\n\nIteration: 19 \nGradient vector:  -26159.62 -0.7851797 8.238305e-05 \nNew parameter estimates:  1e-06 62958.98 9.412613 \n\nrse.dif =  -219.1369 (rse = 3212628675 )  ;  parm.dist =  0.7851797 \n\n\n\n\n\n\n\n\n\nIteration: 20 \nGradient vector:  -26160.01 0.3886224 -4.077271e-05 \nNew parameter estimates:  1e-06 62959.37 9.412573 \n\nrse.dif =  108.4519 (rse = 3212628784 )  ;  parm.dist =  0.3886224 \n\n\n\n\n\n\n\n\n\nIteration: 21 \nGradient vector:  -26159.82 -0.192328 2.01789e-05 \nNew parameter estimates:  1e-06 62959.18 9.412593 \n\nrse.dif =  -53.67477 (rse = 3212628730 )  ;  parm.dist =  0.192328 \n\n\n\n\n\n\n\n\n\nIteration: 22 \nGradient vector:  -26159.91 0.09518727 -9.986825e-06 \nNew parameter estimates:  1e-06 62959.28 9.412583 \n\nrse.dif =  26.56425 (rse = 3212628756 )  ;  parm.dist =  0.09518727 \n\n\n\n\n\n\n\n\n\nIteration: 23 \nGradient vector:  -26159.86 -0.04710907 4.94261e-06 \nNew parameter estimates:  1e-06 62959.23 9.412588 \n\nrse.dif =  -13.14703 (rse = 3212628743 )  ;  parm.dist =  0.04710907 \n\n\n\n\n\n\n\n\n\nIteration: 24 \nGradient vector:  -26159.89 0.023315 -2.446165e-06 \nNew parameter estimates:  1e-06 62959.25 9.412585 \n\nrse.dif =  6.506634 (rse = 3212628750 )  ;  parm.dist =  0.023315 \n\n\n\n\n\n\n\n\n\nIteration: 25 \nGradient vector:  -26159.88 -0.01153889 1.21064e-06 \nNew parameter estimates:  1e-06 62959.24 9.412587 \n\nrse.dif =  -3.220222 (rse = 3212628747 )  ;  parm.dist =  0.01153889 \n\n\n\n\n\n\n\n\n\nIteration: 26 \nGradient vector:  -26159.88 0.005710764 -5.991627e-07 \nNew parameter estimates:  1e-06 62959.25 9.412586 \n\nrse.dif =  1.593734 (rse = 3212628748 )  ;  parm.dist =  0.005710764 \n\n\n\n\n\n\n\n\n\nIteration: 27 \nGradient vector:  -26159.88 -0.002826342 2.965346e-07 \nNew parameter estimates:  1e-06 62959.24 9.412586 \n\nrse.dif =  -0.7887611 (rse = 3212628747 )  ;  parm.dist =  0.002826342 \n\n\n\n\n\n\n\n\n\nIteration: 28 \nGradient vector:  -26159.88 0.001398795 -1.467591e-07 \nNew parameter estimates:  1e-06 62959.24 9.412586 \n\nrse.dif =  0.3903689 (rse = 3212628748 )  ;  parm.dist =  0.001398795 \n\n\n\n\n\n\n\n\n\nIteration: 29 \nGradient vector:  -26159.88 -0.0006922812 7.263288e-08 \nNew parameter estimates:  1e-06 62959.24 9.412586 \n\nrse.dif =  -0.1932006 (rse = 3212628748 )  ;  parm.dist =  0.0006922812 \n\n\n\n\n\n\n\n\n\nIteration: 30 \nGradient vector:  -26159.88 0.000342624 -3.594748e-08 \nNew parameter estimates:  1e-06 62959.24 9.412586 \n\nrse.dif =  0.09561825 (rse = 3212628748 )  ;  parm.dist =  0.000342624 \n\n\n\n\n\n\n\n\n\nConvergence not achieved!\n\n\n\naquifer.vmodGau&lt;-fit.gaussian(aquifer.v,c0=0,cg=50000,ag=50,plot.it=TRUE,iterations=30)\n\nInitial parameter estimates:  0 50000 50 \n\n\n\n\n\n\n\n\n\nIteration: 1 \nGradient vector:  19162.34 -33401.14 -11.41191 \nNew parameter estimates:  19162.34 16598.86 38.58809 \n\nrse.dif =  3299750048 (rse = 3299750048 )  ;  parm.dist =  38507.55 \n\n\n\n\n\n\n\n\n\nIteration: 2 \nGradient vector:  -1294.927 2010.017 -18.77473 \nNew parameter estimates:  17867.41 18608.87 19.81336 \n\nrse.dif =  -66430135 (rse = 3233319913 )  ;  parm.dist =  2391.1 \n\n\n\n\n\n\n\n\n\nIteration: 3 \nGradient vector:  3201.043 -2835.169 9.216254 \nNew parameter estimates:  21068.46 15773.71 29.02961 \n\nrse.dif =  -24694350 (rse = 3208625564 )  ;  parm.dist =  4276.09 \n\n\n\n\n\n\n\n\n\nIteration: 4 \nGradient vector:  -4345.272 4292.413 -6.361973 \nNew parameter estimates:  16723.18 20066.12 22.66764 \n\nrse.dif =  4004881 (rse = 3212630445 )  ;  parm.dist =  6107.884 \n\n\n\n\n\n\n\n\n\nIteration: 5 \nGradient vector:  53.88685 -4.270081 2.074271 \nNew parameter estimates:  16777.07 20061.85 24.74191 \n\nrse.dif =  -3703977 (rse = 3208926468 )  ;  parm.dist =  54.09555 \n\n\n\n\n\n\n\n\n\nIteration: 6 \nGradient vector:  -391.4471 384.4526 -0.5571294 \nNew parameter estimates:  16385.62 20446.3 24.18478 \n\nrse.dif =  588163 (rse = 3209514631 )  ;  parm.dist =  548.6666 \n\n\n\n\n\n\n\n\n\nIteration: 7 \nGradient vector:  29.55911 -27.0943 0.07968918 \nNew parameter estimates:  16415.18 20419.21 24.26447 \n\nrse.dif =  -201438.9 (rse = 3209313192 )  ;  parm.dist =  40.09799 \n\n\n\n\n\n\n\n\n\nIteration: 8 \nGradient vector:  -6.581211 6.259206 -0.01207028 \nNew parameter estimates:  16408.6 20425.47 24.2524 \n\nrse.dif =  26607.8 (rse = 3209339800 )  ;  parm.dist =  9.082408 \n\n\n\n\n\n\n\n\n\nIteration: 9 \nGradient vector:  0.9423146 -0.8928955 0.001794561 \nNew parameter estimates:  16409.54 20424.57 24.25419 \n\nrse.dif =  -4077.43 (rse = 3209335722 )  ;  parm.dist =  1.298161 \n\n\n\n\n\n\n\n\n\nIteration: 10 \nGradient vector:  -0.1413215 0.1339887 -0.0002673761 \nNew parameter estimates:  16409.4 20424.71 24.25393 \n\nrse.dif =  605.1536 (rse = 3209336327 )  ;  parm.dist =  0.194743 \n\n\n\n\n\n\n\n\n\nIteration: 11 \nGradient vector:  0.02102884 -0.01993597 3.982407e-05 \nNew parameter estimates:  16409.42 20424.69 24.25397 \n\nrse.dif =  -90.18701 (rse = 3209336237 )  ;  parm.dist =  0.02897682 \n\n\n\n\n\n\n\n\n\nIteration: 12 \nGradient vector:  -0.003132718 0.00296995 -5.931842e-06 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  13.43229 (rse = 3209336251 )  ;  parm.dist =  0.004316777 \n\n\n\n\n\n\n\n\n\nIteration: 13 \nGradient vector:  0.0004666088 -0.0004423641 8.835486e-07 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  -2.000767 (rse = 3209336249 )  ;  parm.dist =  0.0006429701 \n\n\n\n\n\n\n\n\n\nIteration: 14 \nGradient vector:  -6.950171e-05 6.589045e-05 -1.316048e-07 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  0.2980142 (rse = 3209336249 )  ;  parm.dist =  9.577086e-05 \n\n\n\n\n\n\n\n\n\nIteration: 15 \nGradient vector:  1.035229e-05 -9.814388e-06 1.960254e-08 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  -0.04438925 (rse = 3209336249 )  ;  parm.dist =  1.426508e-05 \n\n\n\n\n\n\n\n\n\nIteration: 16 \nGradient vector:  -1.542e-06 1.46188e-06 -2.919839e-09 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  0.006612301 (rse = 3209336249 )  ;  parm.dist =  2.124821e-06 \n\n\n\n\n\n\n\n\n\nIteration: 17 \nGradient vector:  2.296994e-07 -2.177628e-07 4.349363e-10 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  -0.0009851456 (rse = 3209336249 )  ;  parm.dist =  3.165152e-07 \n\n\n\n\n\n\n\n\n\nIteration: 18 \nGradient vector:  -3.420782e-08 3.242781e-08 -6.477718e-11 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  0.0001473427 (rse = 3209336249 )  ;  parm.dist =  4.713621e-08 \n\n\n\n\n\n\n\n\n\nIteration: 19 \nGradient vector:  5.086605e-09 -4.821087e-09 9.637383e-12 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  -2.193451e-05 (rse = 3209336249 )  ;  parm.dist =  7.007276e-09 \n\n\n\n\n\n\n\n\n\nIteration: 20 \nGradient vector:  -7.583935e-10 7.161523e-10 -1.439258e-12 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  2.861023e-06 (rse = 3209336249 )  ;  parm.dist =  1.042223e-09 \n\n\n\n\n\n\n\n\n\nIteration: 21 \nGradient vector:  1.019258e-10 -9.775917e-11 1.99309e-13 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  -4.768372e-07 (rse = 3209336249 )  ;  parm.dist =  1.415077e-10 \n\nConvergence achieved by sums of squares.\n\n\n\n\n\n\n\n\n\nFinal parameter estimates:  16409.42 20424.69 24.25396 \n\n\n\naquifer.vmodWave&lt;-fit.wave(aquifer.v,c0=0,cw=40000,aw=10,plot.it=TRUE,iterations=30,weighted=T)\n\nInitial parameter estimates:  0 40000 10 \n\n\n\n\n\n\n\n\n\nIteration: 1 \nGradient vector:  18650.32 -21981.27 -0.7942028 \nNew parameter estimates:  18650.32 18018.73 9.205797 \n\nrse.dif =  3409704989 (rse = 3409704989 )  ;  parm.dist =  28827.26 \n\n\n\n\n\n\n\n\n\nIteration: 2 \nGradient vector:  812.9227 -1109.399 -1.187299 \nNew parameter estimates:  19463.25 16909.33 8.018498 \n\nrse.dif =  -289093760 (rse = 3120611230 )  ;  parm.dist =  1375.358 \n\n\n\n\n\n\n\n\n\nIteration: 3 \nGradient vector:  -6990.158 6973.566 0.9858099 \nNew parameter estimates:  12473.09 23882.9 9.004308 \n\nrse.dif =  24044562 (rse = 3144655792 )  ;  parm.dist =  9873.851 \n\n\n\n\n\n\n\n\n\nIteration: 4 \nGradient vector:  7025.438 -6960.473 -1.260353 \nNew parameter estimates:  19498.53 16922.43 7.743955 \n\nrse.dif =  -56767551 (rse = 3087888241 )  ;  parm.dist =  9889.639 \n\n\n\n\n\n\n\n\n\nIteration: 5 \nGradient vector:  -9210.154 9213.61 1.066674 \nNew parameter estimates:  10288.37 26136.04 8.810629 \n\nrse.dif =  175986924 (rse = 3263875165 )  ;  parm.dist =  13027.57 \n\n\n\n\n\n\n\n\n\nIteration: 6 \nGradient vector:  11994.7 -11983.26 -2.255679 \nNew parameter estimates:  22283.07 14152.77 6.55495 \n\nrse.dif =  -196728543 (rse = 3067146622 )  ;  parm.dist =  16954.98 \n\n\n\n\n\n\n\n\n\nIteration: 7 \nGradient vector:  -14060.45 14195.04 -1.578095 \nNew parameter estimates:  8222.625 28347.81 4.976855 \n\nrse.dif =  147278852 (rse = 3214425474 )  ;  parm.dist =  19979.87 \n\n\n\n\n\n\n\n\n\nIteration: 8 \nGradient vector:  -15826.64 16212.91 0.3854677 \nNew parameter estimates:  1e-06 44560.72 5.362323 \n\nrse.dif =  -46983778 (rse = 3167441696 )  ;  parm.dist =  18178.84 \n\n\n\n\n\n\n\n\n\nIteration: 9 \nGradient vector:  13145.08 -21444.98 -0.8756698 \nNew parameter estimates:  13145.08 23115.75 4.486653 \n\nrse.dif =  -757940879 (rse = 2409500817 )  ;  parm.dist =  25153.13 \n\n\n\n\n\n\n\n\n\nIteration: 10 \nGradient vector:  -9434763 9682459 25.73116 \nNew parameter estimates:  1e-06 9705575 30.21781 \n\nrse.dif =  1636307005 (rse = 4045807822 )  ;  parm.dist =  9682468 \n\n\n\n\n\n\n\n\n\nIteration: 11 \nGradient vector:  20962.2 -9688482 0.02156687 \nNew parameter estimates:  20962.2 17093.21 30.23938 \n\nrse.dif =  83628062 (rse = 4129435883 )  ;  parm.dist =  9688504 \n\n\n\n\n\n\n\n\n\nIteration: 12 \nGradient vector:  7173.136 -8587.116 1.22582 \nNew parameter estimates:  28135.34 8506.099 31.4652 \n\nrse.dif =  -628497356 (rse = 3500938527 )  ;  parm.dist =  11188.94 \n\n\n\n\n\n\n\n\n\nIteration: 13 \nGradient vector:  2974.651 -2890.861 -4.19572 \nNew parameter estimates:  31109.99 5615.237 27.26947 \n\nrse.dif =  -192443200 (rse = 3308495327 )  ;  parm.dist =  4147.969 \n\n\n\n\n\n\n\n\n\nIteration: 14 \nGradient vector:  -2399.351 1443.698 15.69929 \nNew parameter estimates:  28710.64 7058.936 42.96876 \n\nrse.dif =  147479203 (rse = 3455974530 )  ;  parm.dist =  2800.25 \n\n\n\n\n\n\n\n\n\nIteration: 15 \nGradient vector:  4786.661 2165.107 -43.14322 \nNew parameter estimates:  33497.3 9224.042 1e-06 \n\nrse.dif =  -686128323 (rse = 2769846206 )  ;  parm.dist =  5253.728 \n\n\nIteration: 16 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\n\n\n\n\n\n\n\nGradient vector:  -7188.309 -5.926894e-07 0 \nNew parameter estimates:  26308.99 9224.042 1e-06 \n\nrse.dif =  686457465 (rse = 3456303671 )  ;  parm.dist =  7188.309 \n\n\nIteration: 17 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\n\n\n\n\n\n\n\nGradient vector:  -5.339328e-06 -5.926894e-07 0 \nNew parameter estimates:  26308.99 9224.042 1e-06 \n\nrse.dif =  0.4889331 (rse = 3456303672 )  ;  parm.dist =  5.372122e-06 \n\n\nIteration: 18 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\n\n\n\n\n\n\n\nGradient vector:  5.926852e-07 -5.926894e-07 0 \nNew parameter estimates:  26308.99 9224.042 1e-06 \n\nrse.dif =  1.907349e-06 (rse = 3456303672 )  ;  parm.dist =  8.381857e-07 \n\n\nIteration: 19 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\n\n\n\n\n\n\n\nGradient vector:  5.926931e-07 -5.926894e-07 0 \nNew parameter estimates:  26308.99 9224.042 1e-06 \n\nrse.dif =  -9.536743e-07 (rse = 3456303672 )  ;  parm.dist =  8.381908e-07 \n\nConvergence achieved by sums of squares.\n\n\n\n\n\n\n\n\n\nFinal parameter estimates:  26308.99 9224.042 1e-06 \n\n\n\ncurve(65000*(1-(14/x)*sin(x/14)),0,300,ylim=c(0,200000))\npoints(aquifer.v$bins,aquifer.v$classic,col=3)\ntext(aquifer.v$bins,aquifer.v$classic,aquifer.v$n,col=2)\n\n\n\n\n\n\n\n\n\ncurve(200000*(1-exp(-x/170)),0,300)\npoints(aquifer.v$bins,aquifer.v$classic,col=2)\n\n\n\n\n\n\n\n\n\ncurve(65000*(1-(14/x)*sin(x/14)),0,300,ylim=c(0,200000))\npoints(aquifer.v$bins,aquifer.v$classic,col=3)\ntext(aquifer.v$bins,aquifer.v$classic,aquifer.v$n,col=2)\n\n\n\n\n\n\n\n\n\naquifer.vmodExp&lt;-fit.exponential(aquifer.v,c0=0,ce=200000,ae=170,plot.it=TRUE,iterations=30,weighted=T)\n\nInitial parameter estimates:  0 2e+05 170 \n\n\n\n\n\n\n\n\n\nIteration: 1 \nGradient vector:  16365.66 -238859.4 -103.7436 \nNew parameter estimates:  16365.66 1e-06 66.25643 \n\nrse.dif =  3826411368 (rse = 3826411368 )  ;  parm.dist =  200668.5 \n\n\n\n\n\n\n\n\n\nIteration: 2 \nGradient vector:  7737.246 16547.95 166070861252 \nNew parameter estimates:  24102.91 16547.95 166070861318 \n\nrse.dif =  -767474321 (rse = 3058937047 )  ;  parm.dist =  166070861252 \n\n\nIteration: 3 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\n\n\n\n\n\n\n\nGradient vector:  3355.03 1.242479e+13 0 \nNew parameter estimates:  27457.94 1.242479e+13 166070861318 \n\nrse.dif =  -120011141 (rse = 2938925906 )  ;  parm.dist =  1.242479e+13 \n\n\nIteration: 4 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\n\n\n\n\n\n\n\nGradient vector:  423.3165 -663474885968 0 \nNew parameter estimates:  27881.25 1.176131e+13 166070861318 \n\nrse.dif =  11801483 (rse = 2950727388 )  ;  parm.dist =  663474885968 \n\n\nIteration: 5 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\n\n\n\n\n\n\n\nGradient vector:  3.873181 -6320523090 0 \nNew parameter estimates:  27885.12 1.175499e+13 166070861318 \n\nrse.dif =  128956.4 (rse = 2950856345 )  ;  parm.dist =  6320523090 \n\n\nIteration: 6 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\n\n\n\n\n\n\n\nGradient vector:  0.02266712 -36921321 0 \nNew parameter estimates:  27885.15 1.175495e+13 166070861318 \n\nrse.dif =  752.3639 (rse = 2950857097 )  ;  parm.dist =  36921321 \n\n\nIteration: 7 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\n\n\n\n\n\n\n\nGradient vector:  0.0001316946 -214507.3 0 \nNew parameter estimates:  27885.15 1.175495e+13 166070861318 \n\nrse.dif =  4.371067 (rse = 2950857102 )  ;  parm.dist =  214507.3 \n\n\nIteration: 8 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\n\n\n\n\n\n\n\nGradient vector:  7.650992e-07 -1246.212 0 \nNew parameter estimates:  27885.15 1.175495e+13 166070861318 \n\nrse.dif =  0.02539396 (rse = 2950857102 )  ;  parm.dist =  1246.213 \n\n\nIteration: 9 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\n\n\n\n\n\n\n\nGradient vector:  4.447233e-09 -7.24441 0 \nNew parameter estimates:  27885.15 1.175495e+13 166070861318 \n\nrse.dif =  0.0001473427 (rse = 2950857102 )  ;  parm.dist =  7.244141 \n\n\nIteration: 10 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\n\n\n\n\n\n\n\nGradient vector:  2.31966e-11 -0.03646515 0 \nNew parameter estimates:  27885.15 1.175495e+13 166070861318 \n\nrse.dif =  9.536743e-07 (rse = 2950857102 )  ;  parm.dist =  0.03710938 \n\nConvergence achieved by sums of squares.\n\n\n\n\n\n\n\n\n\nFinal parameter estimates:  27885.15 1.175495e+13 166070861318 \n\n\n\naquifer.vmodwave&lt;-fit.wave(aquifer.v,c0=4000,cw=30000,aw=15,plot.it=TRUE,iterations=0,weighted=T)\n\n\n\n\n\n\n\n\nConvergence not achieved!\n\n\n\naquifer.vmodExp_0&lt;-fit.exponential(aquifer.v,c0=0,ce=200000,ae=170,plot.it=TRUE,iterations=0,weighted=T)\n\n\n\n\n\n\n\n\nConvergence not achieved!\n\n\n\naquifer.vmodwave_0&lt;-fit.wave(aquifer.v,c0=4000,cw=30000,aw=15,plot.it=TRUE,iterations=0,weighted=T)\n\n\n\n\n\n\n\n\nConvergence not achieved!\n\n\n\naquifer.spherical&lt;-fit.spherical(aquifer.v,c0=0,cs=35000,as=70,plot.it=TRUE,iterations=0,weighted=T)\n\n\n\n\n\n\n\n\nConvergence not achieved!\n\n\n\n#ggplot(aquifer.v, aes(bins, classic)) + \n#  geom_point() + \n#  geom_line() +\n#  xlab(\"Rezago espacial, h\") + \n#  ylab(\"Estimador clásico del variograma\")+\n#  xlim(0, 300) +\n#  geom_function(aes(color = \"Exponencial\"),\n#    fun =~4000+150000*(1-exp(-.x/100)) \n#    ) +\n#  geom_function(aes(color = \"Seno cardinal\"),\n#    fun =~4000+30000*(1-((15/.x)*sin(.x/15)))             \n#    ) + xlab(\"Rezago espacial\") + ylab(\"Modelos teóricos de #semivariogramas\") \n\n\nKriging_aquifer &lt;- point(data.frame(list(x=10,y=80)))\nKriging_aquifer &lt;- krige(Kriging_aquifer, aquifer_points, 'resi', aquifer.vmodExp_0)\n\n\nUsing all points.\n  Preparing the kriging system matrix...\n  Inverting the matrix...\n  Predicting.\n\n\n\nKriging_aquifer\n\n\nPoint object: x \n\n   Locations: 1\n\n   Attributes:\n      x\n      y\n      do\n      zhat\n      sigma2hat\n\n\n\n#Kriging_aquifer$sigma2hat\n\n\nKriging_aquifer &lt;- point(data.frame(list(x=10,y=80)))\nKriging_aquifer &lt;- krige(Kriging_aquifer, aquifer_points, 'resi', aquifer.vmodwave_0)\n\n\nUsing all points.\n  Preparing the kriging system matrix...\n  Inverting the matrix...\n  Predicting.\n\n\n\nKriging_aquifer\n\n\nPoint object: x \n\n   Locations: 1\n\n   Attributes:\n      x\n      y\n      do\n      zhat\n      sigma2hat\n\n\n\n#Kriging_aquifer$zhat\n\n\n#Kriging_aquifer$sigma2hat\n\n\ngrid &lt;- list(x=seq(min(aquifer$Este),max(aquifer$Este),by=20),y=seq(min(aquifer$Norte),max(aquifer$Norte),by=10))\ngrid$xr &lt;- range(grid$x)\ngrid$xs &lt;- grid$xr[2] - grid$xr[1]\ngrid$yr &lt;- range(grid$y)\ngrid$ys &lt;- grid$yr[2] - grid$yr[1]\ngrid$max &lt;- max(grid$xs, grid$ys)\ngrid$xy &lt;- data.frame(cbind(c(matrix(grid$x, length(grid$x), length(grid$y))),\nc(matrix(grid$y, length(grid$x), length(grid$y), byrow=TRUE))))\ncolnames(grid$xy) &lt;- c(\"x\", \"y\")\ngrid$point &lt;- point(grid$xy)\ngrid$krige &lt;- krige(grid$point,aquifer_points,'resi',aquifer.vmodwave_0,maxdist=180,extrap=FALSE)\n\n\nUsing points within 180 units of prediction points.\n  Predicting..........................................................................................................................................................................................................................................\n\n\n\nop &lt;- par(no.readonly = TRUE)\npar(pty=\"s\")\nplot(grid$xy, type=\"n\", xlim=c(grid$xr[1], grid$xr[1]+grid$max),ylim=c(grid$yr[1], grid$yr[1]+grid$max))\nimage(grid$x,grid$y,matrix(grid$krige$zhat,length(grid$x),length(grid$y)),add=TRUE)\ncontour(grid$x,grid$y,matrix(grid$krige$zhat,length(grid$x),length(grid$y)),add=TRUE)\n\n\n\n\n\n\n\n\n\nx11()\nop &lt;- par(no.readonly = TRUE)\npar(pty=\"s\")\nplot(grid$xy, type=\"n\", xlim=c(grid$xr[1], grid$xr[1]+grid$max),ylim=c(grid$yr[1], grid$yr[1]+grid$max))\nimage(grid$x,grid$y,matrix(grid$krige$sigma2hat,length(grid$x),length(grid$y)), add=TRUE)\ncontour(grid$x,grid$y,matrix(grid$krige$sigma2hat,length(grid$x),length(grid$y)),add=TRUE)",
    "crumbs": [
      "Geoestadística",
      "Geoestadística con Sgeostat"
    ]
  },
  {
    "objectID": "cross_validation.html",
    "href": "cross_validation.html",
    "title": "Validación Cruzada",
    "section": "",
    "text": "Esta función realiza la validación cruzada leave-one-out para kriging funcional y cokriging. Deja sistemáticamente una observación fuera del conjunto de datos, ajusta el modelo a los datos restantes y luego realiza una predicción para la observación que se ha dejado fuera. Se utiliza para evaluar el rendimiento predictivo del modelo de kriging funcional.",
    "crumbs": [
      "Kriging",
      "Validación cruzada"
    ]
  },
  {
    "objectID": "cross_validation.html#descripción",
    "href": "cross_validation.html#descripción",
    "title": "Validación Cruzada",
    "section": "",
    "text": "Esta función realiza la validación cruzada leave-one-out para kriging funcional y cokriging. Deja sistemáticamente una observación fuera del conjunto de datos, ajusta el modelo a los datos restantes y luego realiza una predicción para la observación que se ha dejado fuera. Se utiliza para evaluar el rendimiento predictivo del modelo de kriging funcional.",
    "crumbs": [
      "Kriging",
      "Validación cruzada"
    ]
  },
  {
    "objectID": "cross_validation.html#uso",
    "href": "cross_validation.html#uso",
    "title": "Validación Cruzada",
    "section": "Uso",
    "text": "Uso\ncrossval_loo(object, plot_show)",
    "crumbs": [
      "Kriging",
      "Validación cruzada"
    ]
  },
  {
    "objectID": "cross_validation.html#argumentos",
    "href": "cross_validation.html#argumentos",
    "title": "Validación Cruzada",
    "section": "Argumentos",
    "text": "Argumentos\n\nobject: Un objeto de clase KS_pred obtenido con la función KS_scores_lambdas.\nplot_show: Un valor lógico. Si es TRUE, la función generará y mostrará un gráfico de los resultados de la validación cruzada. Si es FALSE, no se mostrará ningún gráfico. El valor predeterminado es TRUE.",
    "crumbs": [
      "Kriging",
      "Validación cruzada"
    ]
  },
  {
    "objectID": "cross_validation.html#valor",
    "href": "cross_validation.html#valor",
    "title": "Validación Cruzada",
    "section": "Valor",
    "text": "Valor\nLa función devuelve un objeto que contiene los resultados de la validación cruzada leave-one-out. Incluye:\n\nperformance_metrics: Estadísticas resumidas que describen el rendimiento predictivo general, como el error cuadrático medio.\nplots: Generación de gráficos que muestran los resultados de la validación cruzada, controlados por el parámetro plot_show. Si plot_show es TRUE, esto contendrá los gráficos; de lo contrario, estará vacío.",
    "crumbs": [
      "Kriging",
      "Validación cruzada"
    ]
  },
  {
    "objectID": "cross_validation.html#ejemplos",
    "href": "cross_validation.html#ejemplos",
    "title": "Validación Cruzada",
    "section": "Ejemplos",
    "text": "Ejemplos\n# Código de ejemplo que demuestra cómo usar la función crossval_loo\nlibrary(SpatFD)\nlibrary(gstat)\n\n# Cargar datos y coordenadas\ndata(AirQualityBogota)\n\n# s_0 ubicación no muestreada. Puede ser un data.frame o matriz con una o más ubicaciones de interés\nnewcoorden = data.frame(X = seq(93000, 105000, len = 100), Y = seq(97000, 112000, len = 100))\n# newcoorden = data.frame(X=110000,Y=126000)\n# newcoorden = matrix(c(110000.23, 109000, 109500, 130000.81, 129000, 131000), nrow = 3, ncol = 2, byrow = TRUE)\n\n# Construir el objeto SpatFD\nSFD_PM10 &lt;- SpatFD(PM10, coords = coord[, -1], basis = \"Bsplines\", \n                   nbasis = 17, norder = 5, lambda = 0.00002, nharm = 3)\n\n# Modelos de semivariograma para cada campo aleatorio espacial de puntuaciones\nmodelos &lt;- list(vgm(psill = 2199288.58, \"Wav\", range = 1484.57, nugget = 0),\n                vgm(psill = 62640.74, \"Mat\", range = 1979.43, nugget = 0, kappa = 0.68),\n                vgm(psill = 37098.25, \"Exp\", range = 6433.16, nugget = 0))\n\n# Kriging funcional. Predicción espacial funcional en cada ubicación de interés\n# method = \"lambda\"\n# Cálculo de lambda_i\nKS_SFD_PM10_l &lt;- KS_scores_lambdas(SFD_PM10, newcoorden, method = \"lambda\", \n                                    model = modelos)\n# method = \"scores\"\n# Kriging simple de puntuaciones\nKS_SFD_PM10_sc &lt;- KS_scores_lambdas(SFD_PM10, newcoorden, method = \"scores\", model = modelos)\n# method = \"both\"\nKS_SFD_PM10_both &lt;- KS_scores_lambdas(SFD_PM10, newcoorden, method = \"both\", model = modelos)\n\n# Validación Cruzada \ncrossval_loo(KS_SFD_PM10_l)\ncrossval_loo(KS_SFD_PM10_sc)\ncrossval_loo(KS_SFD_PM10_both)",
    "crumbs": [
      "Kriging",
      "Validación cruzada"
    ]
  },
  {
    "objectID": "cokmexico.html",
    "href": "cokmexico.html",
    "title": "Mex PM10",
    "section": "",
    "text": "El conjunto de datos COKMexico contiene información sobre la calidad del aire en 13 ubicaciones de México. Específicamente, incluye mediciones de material particulado 10 (PM10) y N02 recolectadas en 13 estaciones de monitoreo distribuidas por el país. Al cargar los datos encontrará en el ambiente.",
    "crumbs": [
      "Datasets",
      "CokMexico"
    ]
  },
  {
    "objectID": "cokmexico.html#uso",
    "href": "cokmexico.html#uso",
    "title": "Mex PM10",
    "section": "Uso",
    "text": "Uso\nPara cargar los datos en R, usa el siguiente comando:\n\n\nLinking to GEOS 3.11.2, GDAL 3.8.2, PROJ 9.3.1; sf_use_s2() is TRUE\n\n\n\ndata(COKMexico)\n\n\nstr(coord_NO2)\n\n'data.frame':   18 obs. of  2 variables:\n $ X: num  509226 473346 482180 469366 479189 ...\n $ Y: num  2171149 2164689 2152665 2141275 2180751 ...\n\n\n\nstr(coord_PM10)\n\n'data.frame':   13 obs. of  2 variables:\n $ X: num  509226 479189 474444 484020 487445 ...\n $ Y: num  2171149 2180751 2154232 2146380 2147815 ...\n\n\n\nstr(Mex_PM10)\n\n int [1:4344, 1:13] 84 110 140 131 151 181 147 139 118 74 ...\n - attr(*, \"dimnames\")=List of 2\n  ..$ : chr [1:4344] \"1\" \"2\" \"3\" \"4\" ...\n  ..$ : chr [1:13] \"ACO\" \"CUT\" \"FAC\" \"HGM\" ...\n\n\n\nstr(Mex_PM10)\n\n int [1:4344, 1:13] 84 110 140 131 151 181 147 139 118 74 ...\n - attr(*, \"dimnames\")=List of 2\n  ..$ : chr [1:4344] \"1\" \"2\" \"3\" \"4\" ...\n  ..$ : chr [1:13] \"ACO\" \"CUT\" \"FAC\" \"HGM\" ...\n\n\n\nstr(NO2)\n\n int [1:4292, 1:18] 21 21 21 18 16 12 12 10 9 10 ...\n - attr(*, \"dimnames\")=List of 2\n  ..$ : chr [1:4292] \"1\" \"2\" \"3\" \"4\" ...\n  ..$ : chr [1:18] \"ACO\" \"ATI\" \"CAM\" \"CUA\" ...\n\n\n\nplot(map_mex)",
    "crumbs": [
      "Datasets",
      "CokMexico"
    ]
  },
  {
    "objectID": "airqualitybogota.html",
    "href": "airqualitybogota.html",
    "title": "AirQualityBogota",
    "section": "",
    "text": "El conjunto de datos AirQualityBogota contiene información sobre la calidad del aire en Bogotá, Colombia. Específicamente, incluye mediciones de material particulado 10 (PM10) recolectadas en 10 estaciones de monitoreo distribuidas por la ciudad. Al cargar los datos encontrará en el ambiente\n\ncoord: Un DataFrame con los nombres y coordenadas de cada una de las estaciones de monitoreo.\nmap: Un objeto del tipo sf que contiene el mapa de Bogotá.\nPM10: Contiene las observaciones de PM10 de cada estación.\n\n\n\nEl PM10 se refiere a partículas de materia en el aire con un diámetro de 10 micrómetros o menos. Estas partículas son lo suficientemente pequeñas como para ser inhaladas y pueden tener efectos negativos en la salud humana, especialmente en los sistemas respiratorio y cardiovascular.",
    "crumbs": [
      "Datasets",
      "AirQualityBogota"
    ]
  },
  {
    "objectID": "airqualitybogota.html#descripción",
    "href": "airqualitybogota.html#descripción",
    "title": "AirQualityBogota",
    "section": "",
    "text": "El conjunto de datos AirQualityBogota contiene información sobre la calidad del aire en Bogotá, Colombia. Específicamente, incluye mediciones de material particulado 10 (PM10) recolectadas en 10 estaciones de monitoreo distribuidas por la ciudad. Al cargar los datos encontrará en el ambiente\n\ncoord: Un DataFrame con los nombres y coordenadas de cada una de las estaciones de monitoreo.\nmap: Un objeto del tipo sf que contiene el mapa de Bogotá.\nPM10: Contiene las observaciones de PM10 de cada estación.\n\n\n\nEl PM10 se refiere a partículas de materia en el aire con un diámetro de 10 micrómetros o menos. Estas partículas son lo suficientemente pequeñas como para ser inhaladas y pueden tener efectos negativos en la salud humana, especialmente en los sistemas respiratorio y cardiovascular.",
    "crumbs": [
      "Datasets",
      "AirQualityBogota"
    ]
  },
  {
    "objectID": "airqualitybogota.html#uso",
    "href": "airqualitybogota.html#uso",
    "title": "AirQualityBogota",
    "section": "Uso",
    "text": "Uso\nPara cargar los datos en R, usa el siguiente comando:\n\n\nLinking to GEOS 3.11.2, GDAL 3.8.2, PROJ 9.3.1; sf_use_s2() is TRUE\n\n\n\ndata(AirQualityBogota)\n\n\nstr(coord)\n\n'data.frame':   10 obs. of  3 variables:\n $ ESTACION: chr  \"Bsq\" \"IDRD\" \"Sony\" \"EscIng\" ...\n $ X       : num  105076 99661 92104 103675 98239 ...\n $ Y       : num  112526 106572 99968 120780 118365 ...\n\n\n\nstr(PM10)\n\n'data.frame':   8761 obs. of  10 variables:\n $ Bosque       : int  29 32 32 24 29 31 24 26 25 36 ...\n $ IDRD         : int  53 48 25 36 17 7 9 12 12 13 ...\n $ Carvajal_Sony: int  72 69 61 30 42 44 30 39 53 49 ...\n $ Guaymaral    : int  74 55 58 51 41 39 46 60 54 41 ...\n $ Suba_Corpas  : int  53 52 45 45 38 40 44 67 51 41 ...\n $ Fontibon     : int  65 49 35 40 26 23 21 29 32 30 ...\n $ PteAranda    : int  91 70 45 43 33 11 15 28 24 31 ...\n $ MAVDT        : int  31 32 32 29 21 21 25 29 26 32 ...\n $ Kennedy      : int  135 94 68 53 47 45 49 59 62 71 ...\n $ Tunal        : int  38 29 18 17 24 24 19 15 20 35 ...\n\n\n\nplot(map$geometry)",
    "crumbs": [
      "Datasets",
      "AirQualityBogota"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "SpatFD es un paquete en R diseñado para facilitar el análisis de datos espaciales con componentes funcionales. Proporciona herramientas para manejar datos funcionales espaciales, permitiendo a investigadores y analistas explorar, modelar y visualizar de manera eficiente la variabilidad y dependencias espaciales en conjuntos de datos complejos.\nNuestro paquete está pensado para soportar una amplia gama de aplicaciones, desde estudios ambientales hasta econometría, ofreciendo métodos adaptables a diversos dominios. Ya sea que estés trabajando con tendencias geoespaciales, dinámicas temporales o relaciones funcionales, SpatFD te brinda la flexibilidad y las herramientas necesarias para extraer conclusiones significativas.\nSpatFD ha sido desarrollado con un enfoque en la usabilidad y el rendimiento, asegurando que tanto usuarios novatos como experimentados de R puedan aprovechar sus capacidades para realizar investigaciones avanzadas en estadística espacial. Únete a nuestra creciente comunidad de usuarios y explora el potencial de los datos funcionales espaciales con SpatFD.",
    "crumbs": [
      "Estadística Espacial Funcional",
      "About"
    ]
  },
  {
    "objectID": "about.html#referencias",
    "href": "about.html#referencias",
    "title": "About",
    "section": "Referencias",
    "text": "Referencias\n\nBohorquez, M., Giraldo, R., & Mateu, J. (2016). Optimal sampling for spatial prediction of functional data. Statistical Methods & Applications, 25(1), 39-54.\nBohorquez, M., Giraldo, R., & Mateu, J. (2016). Multivariate functional random fields: prediction and optimal sampling. Stochastic Environmental Research and Risk Assessment, 31, pages53–70 (2017).\nBohorquez M., Giraldo R. and Mateu J. (2021). Spatial prediction and optimal sampling of functional data in Geostatistical Functional Data Analysis: Theory and Methods. John Wiley Sons, Chichester, UK. ISBN: 978-1-119-38784-8. https://www.wiley.com/en-us/Geostatistical+Functional+Data+Analysis-p-9781119387848.",
    "crumbs": [
      "Estadística Espacial Funcional",
      "About"
    ]
  },
  {
    "objectID": "classification.html",
    "href": "classification.html",
    "title": "Clasificación",
    "section": "",
    "text": "Esta función clasifica nuevos datos funcionales basándose en los resultados del PCA de los datos de entrenamiento.",
    "crumbs": [
      "Clasificación",
      "Clasificación"
    ]
  },
  {
    "objectID": "classification.html#descripción",
    "href": "classification.html#descripción",
    "title": "Clasificación",
    "section": "",
    "text": "Esta función clasifica nuevos datos funcionales basándose en los resultados del PCA de los datos de entrenamiento.",
    "crumbs": [
      "Clasificación",
      "Clasificación"
    ]
  },
  {
    "objectID": "classification.html#uso",
    "href": "classification.html#uso",
    "title": "Clasificación",
    "section": "Uso",
    "text": "Uso\nclassification(data.train.pca, new.basis, k, distance, mcov = NULL)",
    "crumbs": [
      "Clasificación",
      "Clasificación"
    ]
  },
  {
    "objectID": "classification.html#argumentos",
    "href": "classification.html#argumentos",
    "title": "Clasificación",
    "section": "Argumentos",
    "text": "Argumentos\n\ndata.train.pca: Una lista de resultados de PCA a partir de los datos de entrenamiento.\nnew.basis: Objeto de base a partir de los datos de prueba.\nk: Número de vecinos más cercanos a considerar para la clasificación.\ndistance: Tipo de distancia a utilizar (por ejemplo, “euclidiana”, “mahalanobis”).\nmcov: Matrices de covarianza opcionales para la distancia de Mahalanobis.",
    "crumbs": [
      "Clasificación",
      "Clasificación"
    ]
  },
  {
    "objectID": "classification.html#valor",
    "href": "classification.html#valor",
    "title": "Clasificación",
    "section": "Valor",
    "text": "Valor\nLa función devuelve la clase predicha para los nuevos datos.",
    "crumbs": [
      "Clasificación",
      "Clasificación"
    ]
  },
  {
    "objectID": "classification.html#detalles",
    "href": "classification.html#detalles",
    "title": "Clasificación",
    "section": "Detalles",
    "text": "Detalles\nEl proceso de clasificación utiliza los resultados del PCA sobre los datos de entrenamiento para clasificar nuevos puntos de datos. Emplea un algoritmo de k vecinos más cercanos, donde la métrica de distancia puede ser especificada por el usuario.",
    "crumbs": [
      "Clasificación",
      "Clasificación"
    ]
  },
  {
    "objectID": "classification.html#ejemplos",
    "href": "classification.html#ejemplos",
    "title": "Clasificación",
    "section": "Ejemplos",
    "text": "Ejemplos\ndata(vowels)\n#### Crear parámetros y nombres para los datos.\np = 228 ; nelec = 21 ; nvow = 5\nnames_vowels = c(\"a\",\"e\",\"i\",\"o\",\"u\")\nn.basis &lt;- c(14, 13, 12, 13, 11)\ns4.gfdata = gfdata(data = vowels, p = p, names = names_vowels, coords = vowels_coords, nbasis = n.basis)\n\n# Crear datos de entrenamiento y prueba\ns4.sep = gfd_clasif_data(s4.gfdata, 0.8, seed = 2910)\ns4.train = s4.sep$train\ns4.test = s4.sep$test\n\n# Clasificación\ncla &lt;- classification(data.train.pca = s4.train,\n                      new.basis = s4.test[[1]]$data_fd[[1]],\n                      k = 4,\n                      distance = 'euclidean',\n                      mcov = mcov)",
    "crumbs": [
      "Clasificación",
      "Clasificación"
    ]
  },
  {
    "objectID": "cokriging.html",
    "href": "cokriging.html",
    "title": "Cokriging",
    "section": "",
    "text": "El cokriging es una extensión del kriging que permite predecir una variable en una ubicación no muestreada utilizando no solo datos de esa misma variable, sino también información de otras variables relacionadas o covariables. Este método aprovecha la correlación espacial entre varias variables para mejorar la precisión de las predicciones.\nSupongamos que queremos hacer la predicción tomando en cuenta \\(p\\) variables de forma simultánea. Considerando \\(Z(s_i) = (Z_1(s_i),Z_2(s_i),\\cdots,Z_p(s_i))'\\) , el predictor para \\(Z_l(s_0), 1\\leq l\\leq p\\) basado en p, basado en las \\(p\\) variables tiene la forma\n\\[\nZ^*_l(s_0) = \\sum_{i=1}^n \\sum_{q=1}^p \\lambda_{qi}Z_q(s_i)\n\\]\nEl mejor predictor lineal insesgado de una variable en la ubicación \\(s_0\\) está dado por la minimización de\n\\[\nmax_{1\\leq l \\leq n}\\{Var[Z_l(s_0)-Z^*_l(s_0)]\\}\n\\]\nPor eficiencia computacional, puede decidirse minimizar\n\\[\n\\sum_{i=1}^nVar[Z_l(s_0)-Z^*_l(s_0)]\n\\]\nEn el paquete SpatFD se realiza cokriging sobre los scores elegidos para todas las variables funcionales involucradas. Las predicciones de scores se utilizan para construir el predictor funcional del cokriging.\n\ndata(COKMexico)\n# Definimos nuestro objeto SpatFD\nSFD_PM10_NO2 &lt;- SpatFD(Mex_PM10, coords = coord_PM10, basis = \"Fourier\", \nnbasis = 21, lambda = 0.000001, nharm = 2)\n# Agregamos las observaciones de NO2 al objeto que creamos antes por medio del argumento add\nSFD_PM10_NO2 &lt;- SpatFD(NO2, coords = coord_NO2, basis = \"Fourier\", \nnbasis = 27, lambda = 0.000001, nharm = 2,\n                      add = SFD_PM10_NO2)\n# Definimos los modelos de varianza de cada una de las variables\nmodel1 &lt;- gstat::vgm(647677.1,\"Gau\",23317.05)\nmodel1 &lt;- gstat::vgm(127633,\"Wav\",9408.63, add.to = model1)\n\n# Especificamos la ubicación no muestreada\nnewcoords &lt;- data.frame(x = 509926, y = 2179149)\n\nLa función COKS_scores_lambdas nos permite hacer el cokriging funcional\n\ncokrig = COKS_scores_lambdas(SFD_PM10_NO2, newcoords, model1)\n\nUsing fill.all = TRUE by default\n\n\nUsing method = 'lambda' by default\n\n\n\n\n\n\n\n\n\nLinear Model of Coregionalization found. Good.\n[using ordinary cokriging]\n\n\n\n#cokrig$modelfit",
    "crumbs": [
      "Kriging",
      "Cokriging"
    ]
  },
  {
    "objectID": "GeoestadisticaUnivariadaConGeoR.html",
    "href": "GeoestadisticaUnivariadaConGeoR.html",
    "title": "Geoestadística univariada con geoR",
    "section": "",
    "text": "Lista de librerías con link a la documentación.\n\nfields\ngeoR\nakima Usado para gráficos descriptivos\n\n\nrm(list=ls())\nlibrary(fields)\n\nCargando paquete requerido: spam\n\n\nSpam version 2.11-0 (2024-10-03) is loaded.\nType 'help( Spam)' or 'demo( spam)' for a short introduction \nand overview of this package.\nHelp for individual functions is also obtained by adding the\nsuffix '.spam' to the function name, e.g. 'help( chol.spam)'.\n\n\n\nAdjuntando el paquete: 'spam'\n\n\nThe following objects are masked from 'package:base':\n\n    backsolve, forwardsolve\n\n\nCargando paquete requerido: viridisLite\n\n\n\nTry help(fields) to get started.\n\nlibrary(geoR)\n\n--------------------------------------------------------------\n Analysis of Geostatistical Data\n For an Introduction to geoR go to http://www.leg.ufpr.br/geoR\n geoR version 1.9-4 (built on 2024-02-14) is now loaded\n--------------------------------------------------------------\n\nlibrary(akima)\n\n\n\n\n\naquifer &lt;- read.table(\"data/aquifer.txt\", head = TRUE, dec = \",\")\n\nEncabezado de datos aquifer.txt\n\nhead(aquifer)\n\n       Este     Norte Profundidad\n1  42.78275 127.62282        1464\n2 -27.39691  90.78732        2553\n3  -1.16289  84.89600        2158\n4 -18.61823  76.45199        2455\n5  96.46549  64.58058        1756\n6 108.56243  82.92325        1702\n\n\nSummary de los datos aquifer.txt\n\n#summary(aquifer)\n\n\n\n\n\n\n\n\nDocumentación as.geodata\n\n\naquiferg &lt;- as.geodata(aquifer)\n#summary(aquiferg)\n\n\n\n\n\nDocumentación plotgeodata\n\nGráfico del objeto geodata\n\nplot(aquiferg, qt.col = c(\"purple\",\n                         \"pink\",\n                         \"green\",\n                         \"yellow\"))\n\n\n\n\n\n\n\n\nGráfico con el parametro 3d\n\nplot(aquiferg, scatter3d = T)\n\n\n\n\n\n\n\n\nGráfico removiendo la tendencia (trend )\n\nplot(aquiferg, trend = \"1st\")\n\n\n\n\n\n\n\n\n\n\n\n\nDocumentación Interpolación inderp\nDocumentación persp\nDocumentación drape.plot\n\n\npar(mfrow = c(2, 2),\n    mar = c(3, 3, 1, 1),\n    mgp = c(2, 1, 0))\n# Esta función agrupa los siguientes gráficos en\n# una matrix 2x2\n\ngrillas &lt;- interp(aquifer$Este,\n                  aquifer$Norte,\n                  aquifer$Profundidad)\n\npersp(grillas$x,\n      grillas$y,\n      grillas$z,\n      xlab = \"Este\",\n      ylab = \"Norte\",\n      zlab = \"Nivel freatico\",\n      phi = 30,\n      theta = 20,\n      col = \"lightblue\",\n      expand = .5,\n      ticktype = \"detailed\")\n\ndrape.plot(grillas$x,\n           grillas$y,\n           grillas$z,\n           xlab = \"Este\",\n           ylab = \"Norte\",\n           zlab = \"z\",\n           theta = 45,\n           col = topo.colors(64),\n           expand = .5,\n           ticktype = \"detailed\")\n\n\ndrape.plot(grillas$x,\n           grillas$y,\n           grillas$z,\n           xlab = \"Este\",\n           ylab = \"Norte\",\n           zlab = \"z\",\n           theta = -10,\n           col = topo.colors(64),\n           expand = .5,\n           ticktype = \"detailed\")\n\n\ndrape.plot(grillas$x,\n           grillas$y,\n           grillas$z,\n           xlab = \"Este\",\n           ylab = \"Norte\",\n           zlab = \"z\",\n           theta = 60,\n           col = topo.colors(64),\n           expand = .5,\n           ticktype = \"detailed\")\n\n\n\n\n\n\n\n\n\n\n\n\nDocumentación contour\nDocumentación filled.contour\n\n\npar(mfrow = c(2, 1),\n    mar = c(1,1,1,1))\n\ncontour(grillas, nlevels = 10, main = \"Contorno\")\nimage(grillas$z, main =  \"Grilla\")\n\n\n\n\n\n\n\n\n\nfilled.contour(grillas, levels = seq(1000,\n                                     5000,\n                                     len = 10),\n               col = heat.colors(10),\n                main = \"grilla niveles\")\n\n\n\n\n\n\n\n\n\n\n\n\nh &lt;- seq(0, 1, len = 50)\nu &lt;- seq(0, 1, len = 50)\n\nejemplo1CH  &lt;- function(h, u, sigma, a, b, c, d, delta) {\n    (sigma^2/((a^2*u^2+c)^(d/2)))*exp(-(b^2*h^2)/(a^2*u^2+c))*exp(-delta*u^2)\n    }\nh &lt;- seq(0, 1, len = 20)\nu &lt;- seq(1, 10, len = 20)\nf &lt;- outer(h, u, ejemplo1CH, sigma=3, a=1, b=3, c=1, d=2, delta=0)\n\npar(mfrow = c(2, 2),\n    mar = c(3, 3, 1, 1),\n    mgp = c(2, 1, 0))\n\ndrape.plot(h,\n           u,\n           f,\n           main = \"Cressie-Huang; 1 (25,1,0.6)\",\n           xlab = \"h\",\n           ylab = \"u\",\n           zlab = \"Covarianza\",\n           ltheta = 75,\n           col = terrain.colors(64))\n\ndrape.plot(h,\n           u,\n           f,\n           main = \"Cressie-Huang; 1 (25,1,0.6)\",\n           xlab = \"h\",\n           ylab = \"u\",\n           zlab = \"Covarianza\",\n           theta = -150,\n           col = terrain.colors(64))\npersp(h,\n      u,\n      f,\n      main = \"Cressie-Huang; 1 (25,1,0.6)\",\n      xlab = \"h\",\n      ylab = \"u\",\n      zlab = \"Covarianza\",\n      ltheta = 75)\n\ncontour(h,\n        u,\n        f,\n        col = topo.colors(10),\n        xlim = c(0,0.6))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nreg1 &lt;- lm(Profundidad ~ Este + Norte, data = aquifer)\nresiduales1  &lt;-  residuals(reg1)\n#summary(reg1)\nanova(reg1)\n\nAnalysis of Variance Table\n\nResponse: Profundidad\n          Df   Sum Sq  Mean Sq F value    Pr(&gt;F)    \nEste       1 19045642 19045642  460.95 &lt; 2.2e-16 ***\nNorte      1  8960172  8960172  216.86 &lt; 2.2e-16 ***\nResiduals 82  3388069    41318                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\nreg2 &lt;- lm(Profundidad ~ Este + Norte +\n           I(Este^2) + I(Norte^2) +\n           I(Este * Norte),\n           data = aquifer)\nresiduales2  &lt;-  residuals(reg2)\n#summary(reg2)\nanova(reg2)\n\nAnalysis of Variance Table\n\nResponse: Profundidad\n                Df   Sum Sq  Mean Sq  F value    Pr(&gt;F)    \nEste             1 19045642 19045642 551.3469 &lt; 2.2e-16 ***\nNorte            1  8960172  8960172 259.3855 &lt; 2.2e-16 ***\nI(Este^2)        1    55368    55368   1.6028 0.2092235    \nI(Norte^2)       1   152170   152170   4.4051 0.0390253 *  \nI(Este * Norte)  1   451567   451567  13.0723 0.0005259 ***\nResiduals       79  2728964    34544                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\nreg3 &lt;- lm(Profundidad ~ Este * Norte,\n           data = aquifer)\nresiduales3  &lt;-  residuals(reg3)\n#summary(reg3)\nanova(reg3)\n\nAnalysis of Variance Table\n\nResponse: Profundidad\n           Df   Sum Sq  Mean Sq F value    Pr(&gt;F)    \nEste        1 19045642 19045642  517.06 &lt; 2.2e-16 ***\nNorte       1  8960172  8960172  243.25 &lt; 2.2e-16 ***\nEste:Norte  1   404448   404448   10.98  0.001379 ** \nResiduals  81  2983621    36835                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\nDocumentación variog\n\n\nvari2 &lt;- variog(aquiferg, trend = \"1st\")\n\nvariog: computing omnidirectional variogram\n\nvari2Cloud &lt;- variog(aquiferg, op = \"cloud\", trend = \"1st\")\n\nvariog: computing omnidirectional variogram\n\nvari2BinCloud &lt;- variog(aquiferg,\n                       max.dist = 200,\n                       op = \"cloud\",\n                       bin.cloud = TRUE)\n\nvariog: computing omnidirectional variogram\n\nvari2Sm &lt;- variog(aquiferg,\n                  trend = \"1st\",\n                  op = \"sm\",\n                  band=11)\n\nvariog: computing omnidirectional variogram\n\n\n\npar(mfrow = c(2, 2), mar = c(3, 3, 1, 1), mgp = c(2, 1, 0))\n     plot(vari2$u, vari2$v, main = \"binned variogram\") # jocastroc: vari2 solo no da el plot se dejo vari2$u,vari2$v\n     plot(vari2Cloud$u, vari2Cloud$v, main = \"variogram cloud\")\n     plot(vari2BinCloud$u, vari2BinCloud$v, main = \"clouds for binned variogram\")\n     plot(vari2Sm$u, vari2Sm$v, main = \"smoothed variogram\")\n\n\n\n\n\n\n\n\n\n\n\nvari1 &lt;- variog(aquiferg)\n\nvariog: computing omnidirectional variogram\n\nvari2 &lt;- variog(aquiferg, trend = \"1st\")\n\nvariog: computing omnidirectional variogram\n\nvari3 &lt;- variog(aquiferg, trend = \"2nd\")\n\nvariog: computing omnidirectional variogram\n\n\n\nplot(vari1$u,vari1$v, main = \"Sin remover tendencia\")\n\n\n\n\n\n\n\nplot(vari2$u,vari2$v, main  = \"Trend 1 \")\n\n\n\n\n\n\n\nplot(vari3$u,vari3$v, main  = \"Trend 2 \")\n\n\n\n\n\n\n\n\n\n\n\n\nvari1 &lt;- variog(aquiferg, estimator.type = \"modulus\")\n\nvariog: computing omnidirectional variogram\n\nvari2 &lt;- variog(aquiferg, trend = \"1st\", estimator.type = \"modulus\")\n\nvariog: computing omnidirectional variogram\n\nvari3 &lt;- variog(aquiferg, trend = \"2nd\", estimator.type = \"modulus\")\n\nvariog: computing omnidirectional variogram\n\n\n\nplot(vari1$u,vari1$v, main = \"Sin remover tendencia\")\n\n\n\n\n\n\n\nplot(vari2$u,vari2$v, main  = \"Trend 1 \")\n\n\n\n\n\n\n\nplot(vari3$u,vari3$v, main  = \"Trend 2 \")\n\n\n\n\n\n\n\n\n\n\n\n\nvari_0 &lt;- variog(aquiferg,\n                 trend = \"1st\",\n                 max.dist = 200,\n                 dir = 0)\n\nvariog: computing variogram for direction = 0 degrees (0 radians)\n        tolerance angle = 22.5 degrees (0.393 radians)\n\nvari_45 &lt;- variog(aquiferg,\n                  trend = \"1st\",\n                  max.dist = 200,\n                  dir = pi / 4)\n\nvariog: computing variogram for direction = 45 degrees (0.785 radians)\n        tolerance angle = 22.5 degrees (0.393 radians)\n\nvari_90 &lt;- variog(aquiferg,\n                  trend = \"1st\",\n                  max.dist = 200,\n                  dir = pi / 2)\n\nvariog: computing variogram for direction = 90 degrees (1.571 radians)\n        tolerance angle = 22.5 degrees (0.393 radians)\n\nvari_135 &lt;- variog(aquiferg,\n                   trend = \"1st\",\n                   max.dist = 200,\n                   dir = 3 * pi / 4)\n\nvariog: computing variogram for direction = 135 degrees (2.356 radians)\n        tolerance angle = 22.5 degrees (0.393 radians)\n\npar(mfrow = c(2, 2),\n    mar = c(3, 3, 1, 1),\n    mgp = c(2, 1, 0))\n\nplot(vari_0$u,vari_0$v, main = \"vari 0\")\nplot(vari_45$u,vari_45$v, main = \"vari 45\")\nplot(vari_90$u,vari_90$v, main = \"vari 90\")\nplot(vari_135$u,vari_135$v, main = \"vari 195\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nDocumentación eyefit\nDocumentación variofit\nDocumentación likfit\n\n\nvar1 &lt;- variog(aquiferg,trend=\"1st\",max.dist=200)\n\nvariog: computing omnidirectional variogram\n\n#ini1 &lt;- eyefit(var1)\n#cov.model  sigmasq phi   tausq kappa kappa2   practicalRange\n#1      wave 30805.52  13 8984.94  &lt;NA&gt;   &lt;NA&gt; 38.8889336320589\nini1 &lt;- c(30805.52, 13)\nfitvar1 &lt;- variofit(var1,\n                    cov.model = \"wave\",\n                    ini1,\n                    fix.nugget = TRUE,\n                    nugget = 8984.94,\n                    wei = \"equal\")\n\nvariofit: covariance model used is wave \nvariofit: weights used: equal \nvariofit: minimisation function used: optim \n\nfitvar2 &lt;- variofit(var1,\n                    cov.model = \"wave\",\n                    ini1,\n                    fix.nugget = TRUE,\n                    nugget = 8984.94,\n                    wei = \"npairs\")\n\nvariofit: covariance model used is wave \nvariofit: weights used: npairs \nvariofit: minimisation function used: optim \n\nfitvar3 &lt;- variofit(var1,\n                    ini1,\n                    fix.nugget = TRUE,\n                    nugget = 8984.94,\n                    wei = \"cressie\")\n\nvariofit: covariance model used is matern \nvariofit: weights used: cressie \nvariofit: minimisation function used: optim \n\nfitvar4 &lt;- likfit(aquiferg,\n                  coords = aquiferg$coords,\n                  data = aquiferg$data,\n                  trend = \"1st\",\n                  ini.cov.pars = ini1,\n                  fix.nugget = T,\n                  nugget = 8984.94,\n                  cov.model = \"wave\",\n                  lik.method = \"ML\")\n\nkappa not used for the wave correlation function\n---------------------------------------------------------------\nlikfit: likelihood maximisation using the function optim.\nlikfit: Use control() to pass additional\n         arguments for the maximisation function.\n        For further details see documentation for optim.\nlikfit: It is highly advisable to run this function several\n        times with different initial values for the parameters.\nlikfit: WARNING: This step can be time demanding!\n---------------------------------------------------------------\nlikfit: end of numerical maximisation.\n\nfitvar5 &lt;- likfit(aquiferg,\n                  coords = aquiferg$coords,\n                  data = aquiferg$data,\n                  trend = \"1st\",\n                  ini.cov.pars = ini1,\n                  fix.nugget = T,\n                  nugget = 8984.94,\n                  cov.model = \"wave\",\n                  lik.method = \"REML\")\n\nkappa not used for the wave correlation function\n---------------------------------------------------------------\nlikfit: likelihood maximisation using the function optim.\nlikfit: Use control() to pass additional\n         arguments for the maximisation function.\n        For further details see documentation for optim.\nlikfit: It is highly advisable to run this function several\n        times with different initial values for the parameters.\nlikfit: WARNING: This step can be time demanding!\n---------------------------------------------------------------\nlikfit: end of numerical maximisation.\n\n\n\nplot(var1$u,var1$v,\n     xlab = \"h\",\n     ylab = \"semivarianza\",\n     cex.lab = 1.3,\n     cex.axis = 1.2,\n     main = \"Estimación teórica del modelo de semivariograma\",\n     col.main = 4, cex.main =1.3)\nlines(fitvar1, col = 1)\nlines(fitvar2, col = 2)\nlines(fitvar3, col = 3)\nlines(fitvar4, col = 4)\nlines(fitvar5, col = 5)\nlegend(130, 18000,\n       c(\"MCO\", \"MCPnpairs\", \"MCPcressie\", \"ML\", \"REML\"),\n       lwd = 2,\n       lty = 2:7,\n       col = 2:7,\n       box.col = 9,\n       text.col = 2:7)\n\n\n\n\n\n\n\n\n\n\n\n\n#summary(fitvar1)\n#summary(fitvar2)\n#summary(fitvar3)\n#summary(fitvar4)\n#summary(fitvar5)\n\n\n\n\nEsta es una alternativa al modelamiento de la media cuando los modelos de regresión polinómicos usuales no logran el objetivo de eliminar la tendencia ya sea porque el tipo de tendencia corresponde mas a unas ventanas móviles o porque hay presentes datos atípicos.\n\n\nLista de librerías con link a la documentación.\n\nrm(list=ls())\nlibrary(gstat)\nlibrary(sp)\nlibrary(mvtnorm)\n\n\nAdjuntando el paquete: 'mvtnorm'\n\n\nThe following objects are masked from 'package:spam':\n\n    rmvnorm, rmvt\n\n\n\ngstat\nsp\n\n\n\n\n\nn_x &lt;- 4\nn_y &lt;- 6\nx &lt;- seq(0, 1, len = n_x)\ny &lt;- seq(0, 1, len = n_y)\ncoordenadas &lt;- as.data.frame(expand.grid(x, y))\nnames(coordenadas) &lt;- c(\"X\", \"Y\")\n\nEncabezado coordenadas\n\n\n\nX\nY\n\n\n\n\n0.0000000\n0.0\n\n\n0.3333333\n0.0\n\n\n0.6666667\n0.0\n\n\n1.0000000\n0.0\n\n\n0.0000000\n0.2\n\n\n0.3333333\n0.2\n\n\n\n\n\n\nEsto define un objeto vgm que es el tipo de objeto que usa el paquete gstat para los modelos teóricos de variograma. Con este objeto se pueden definir modelos anidados.\n\nvgm\n\n\nvario &lt;- vgm(10, # Punto de silla\n             \"Exp\", # Modelo, ver documentación\n             0.5)  # Rango\nprint(vario)\n\n  model psill range\n1   Exp    10   0.5\n\n\n\n\n\n\nvgmArea\ncoordinates\n\n\ncoordinates(coordenadas) &lt;- ~X + Y\n#class(coordenadas) # Cambio de objedto dataframe a sp\n\n\ncov_mat &lt;- vgmArea(coordenadas, # Matriz de ubiaciones SP\n        vgm = vario) # VGM object\n\nprint(dim(cov_mat))\n\n[1] 24 24\n\n\n\n\n\nSimulación dada la media y la matriz de varianza\n\nmu  &lt;- rep(0, n_x * n_y) # Media del proceso\nsimu &lt;- rmvnorm(1,\n                mean = mu,\n                sigma = cov_mat)\nprint(simu[1:5])\n\n[1] -0.1754460 -1.0791818 -2.6804808 -0.5803572 -0.7986549\n\n\n\n\n\nUnir las coordenadas con la columna de simulación\n\ndata &lt;- as.data.frame(cbind(coordenadas@coords,\n                            Simula = t(simu)))\nnames(data) &lt;- c(\"X\", \"Y\", \"Var\")\nprint(head(data))\n\n          X   Y        Var\n1 0.0000000 0.0 -0.1754460\n2 0.3333333 0.0 -1.0791818\n3 0.6666667 0.0 -2.6804808\n4 1.0000000 0.0 -0.5803572\n5 0.0000000 0.2 -0.7986549\n6 0.3333333 0.2  2.1251560\n\n\nReshape para matriz, esto transforma la tabla de datos en matriz\n\ntabla &lt;- reshape2::dcast(data,\n                         X ~ Y,\n                         value.var = \"Var\")\nrownames(tabla) &lt;- tabla[, 1]\ntabla &lt;- tabla[, c(-1)]\nprint(tabla)\n\n                           0        0.2       0.4         0.6        0.8\n0                 -0.1754460 -0.7986549  5.034347  0.02068872  0.6737984\n0.333333333333333 -1.0791818  2.1251560  1.320088 -2.71596165 -2.6710621\n0.666666666666667 -2.6804808  0.8508661 -1.648666 -3.61460060 -4.2433416\n1                 -0.5803572 -4.3177146 -2.240096 -2.89269507 -1.6432483\n                           1\n0                  4.3284278\n0.333333333333333 -0.5319672\n0.666666666666667  2.9161060\n1                  3.3113610\n\n\nPulimiento de medianas de la tabla\n\nmed &lt;- medpolish(tabla)\n\n1: 30.92069\n2: 29.92268\nFinal: 29.92268\n\n\n\ngeo_data &lt;- reshape2::melt(med$residuals)\nprint(med)\n\n\nMedian Polish Results (Dataset: \"tabla\")\n\nOverall: -0.8339295\n\nRow Effects:\n                0 0.333333333333333 0.666666666666667                 1 \n       1.93302399        0.03220131       -1.21776765       -0.03220131 \n\nColumn Effects:\n         0        0.2        0.4        0.6        0.8          1 \n-0.4531186  0.5024070  1.2624238 -1.7385684 -1.3232257  3.7034126 \n\nResiduals:\n                         0     0.2      0.4      0.6      0.8        1\n0                 -0.82142 -2.4002  2.67283  0.66016  0.89793 -0.47408\n0.333333333333333  0.17567  2.4245  0.85939 -0.17567 -0.54611 -3.43365\n0.666666666666667 -0.17567  2.4002 -0.85939  0.17567 -0.86842  1.26439\n1                  0.73889 -3.9540 -2.63639 -0.28800  0.54611  0.47408\n\n\nReshape de los datos, con efecto de la fila y la columna\n\ntabla_residuales &lt;- as.data.frame(med$residuals)\nnames(tabla_residuales) &lt;- med$col\nrownames(tabla_residuales) &lt;- med$row\ngeo_data &lt;- reshape2::melt(as.matrix(tabla_residuales))\n\ngeo_data &lt;- cbind(data,\n                  geo_data,\n                  med$overall)\nnames(geo_data) &lt;- c(\"X\",\n                     \"Y\",\n                     \"Var\",\n                     \"Efecto fila\",\n                     \"Efecto columa\",\n                     \"Residual\",\n                     \"Efecto Global\")\nprint(geo_data)\n\n           X   Y         Var Efecto fila Efecto columa   Residual Efecto Global\n1  0.0000000 0.0 -0.17544600  1.93302399    -0.4531186 -0.8214219    -0.8339295\n2  0.3333333 0.0 -1.07918181  0.03220131    -0.4531186  0.1756650    -0.8339295\n3  0.6666667 0.0 -2.68048078 -1.21776765    -0.4531186 -0.1756650    -0.8339295\n4  1.0000000 0.0 -0.58035718 -0.03220131    -0.4531186  0.7388923    -0.8339295\n5  0.0000000 0.2 -0.79865485  1.93302399     0.5024070 -2.4001563    -0.8339295\n6  0.3333333 0.2  2.12515597  0.03220131     0.5024070  2.4244772    -0.8339295\n7  0.6666667 0.2  0.85086614 -1.21776765     0.5024070  2.4001563    -0.8339295\n8  1.0000000 0.2 -4.31771460 -0.03220131     0.5024070 -3.9539908    -0.8339295\n9  0.0000000 0.4  5.03434662  1.93302399     1.2624238  2.6728284    -0.8339295\n10 0.3333333 0.4  1.32008790  0.03220131     1.2624238  0.8593923    -0.8339295\n11 0.6666667 0.4 -1.64866572 -1.21776765     1.2624238 -0.8593923    -0.8339295\n12 1.0000000 0.4 -2.24009637 -0.03220131     1.2624238 -2.6363893    -0.8339295\n13 0.0000000 0.6  0.02068872  1.93302399    -1.7385684  0.6601627    -0.8339295\n14 0.3333333 0.6 -2.71596165  0.03220131    -1.7385684 -0.1756650    -0.8339295\n15 0.6666667 0.6 -3.61460060 -1.21776765    -1.7385684  0.1756650    -0.8339295\n16 1.0000000 0.6 -2.89269507 -0.03220131    -1.7385684 -0.2879958    -0.8339295\n17 0.0000000 0.8  0.67379836  1.93302399    -1.3232257  0.8979296    -0.8339295\n18 0.3333333 0.8 -2.67106214  0.03220131    -1.3232257 -0.5461082    -0.8339295\n19 0.6666667 0.8 -4.24334155 -1.21776765    -1.3232257 -0.8684187    -0.8339295\n20 1.0000000 0.8 -1.64324827 -0.03220131    -1.3232257  0.5461082    -0.8339295\n21 0.0000000 1.0  4.32842781  1.93302399     3.7034126 -0.4740792    -0.8339295\n22 0.3333333 1.0 -0.53196718  0.03220131     3.7034126 -3.4336516    -0.8339295\n23 0.6666667 1.0  2.91610598 -1.21776765     3.7034126  1.2643906    -0.8339295\n24 1.0000000 1.0  3.31136101 -0.03220131     3.7034126  0.4740792    -0.8339295\n\n\nValidación de la descomposición\n\nvalida &lt;- cbind(geo_data$Var,\n                geo_data[[\"Efecto fila\"]] +\n                geo_data[[\"Efecto columa\"]] +\n                geo_data[[\"Residual\"]] +\n                geo_data[[\"Efecto Global\"]])\nvalida &lt;- as.data.frame(valida)\nnames(valida) &lt;- c(\"datos\", \"suma\")\nprint(valida)\n\n         datos        suma\n1  -0.17544600 -0.17544600\n2  -1.07918181 -1.07918181\n3  -2.68048078 -2.68048078\n4  -0.58035718 -0.58035718\n5  -0.79865485 -0.79865485\n6   2.12515597  2.12515597\n7   0.85086614  0.85086614\n8  -4.31771460 -4.31771460\n9   5.03434662  5.03434662\n10  1.32008790  1.32008790\n11 -1.64866572 -1.64866572\n12 -2.24009637 -2.24009637\n13  0.02068872  0.02068872\n14 -2.71596165 -2.71596165\n15 -3.61460060 -3.61460060\n16 -2.89269507 -2.89269507\n17  0.67379836  0.67379836\n18 -2.67106214 -2.67106214\n19 -4.24334155 -4.24334155\n20 -1.64324827 -1.64324827\n21  4.32842781  4.32842781\n22 -0.53196718 -0.53196718\n23  2.91610598  2.91610598\n24  3.31136101  3.31136101",
    "crumbs": [
      "Geoestadística",
      "Geoestadística Univariada con GeoR"
    ]
  },
  {
    "objectID": "GeoestadisticaUnivariadaConGeoR.html#parte-descriptiva",
    "href": "GeoestadisticaUnivariadaConGeoR.html#parte-descriptiva",
    "title": "Geoestadística univariada con geoR",
    "section": "",
    "text": "Lista de librerías con link a la documentación.\n\nfields\ngeoR\nakima Usado para gráficos descriptivos\n\n\nrm(list=ls())\nlibrary(fields)\n\nCargando paquete requerido: spam\n\n\nSpam version 2.11-0 (2024-10-03) is loaded.\nType 'help( Spam)' or 'demo( spam)' for a short introduction \nand overview of this package.\nHelp for individual functions is also obtained by adding the\nsuffix '.spam' to the function name, e.g. 'help( chol.spam)'.\n\n\n\nAdjuntando el paquete: 'spam'\n\n\nThe following objects are masked from 'package:base':\n\n    backsolve, forwardsolve\n\n\nCargando paquete requerido: viridisLite\n\n\n\nTry help(fields) to get started.\n\nlibrary(geoR)\n\n--------------------------------------------------------------\n Analysis of Geostatistical Data\n For an Introduction to geoR go to http://www.leg.ufpr.br/geoR\n geoR version 1.9-4 (built on 2024-02-14) is now loaded\n--------------------------------------------------------------\n\nlibrary(akima)\n\n\n\n\n\naquifer &lt;- read.table(\"data/aquifer.txt\", head = TRUE, dec = \",\")\n\nEncabezado de datos aquifer.txt\n\nhead(aquifer)\n\n       Este     Norte Profundidad\n1  42.78275 127.62282        1464\n2 -27.39691  90.78732        2553\n3  -1.16289  84.89600        2158\n4 -18.61823  76.45199        2455\n5  96.46549  64.58058        1756\n6 108.56243  82.92325        1702\n\n\nSummary de los datos aquifer.txt\n\n#summary(aquifer)",
    "crumbs": [
      "Geoestadística",
      "Geoestadística Univariada con GeoR"
    ]
  },
  {
    "objectID": "GeoestadisticaUnivariadaConGeoR.html#geo_data",
    "href": "GeoestadisticaUnivariadaConGeoR.html#geo_data",
    "title": "Geoestadística univariada con geoR",
    "section": "",
    "text": "Documentación as.geodata\n\n\naquiferg &lt;- as.geodata(aquifer)\n#summary(aquiferg)\n\n\n\n\n\nDocumentación plotgeodata\n\nGráfico del objeto geodata\n\nplot(aquiferg, qt.col = c(\"purple\",\n                         \"pink\",\n                         \"green\",\n                         \"yellow\"))\n\n\n\n\n\n\n\n\nGráfico con el parametro 3d\n\nplot(aquiferg, scatter3d = T)\n\n\n\n\n\n\n\n\nGráfico removiendo la tendencia (trend )\n\nplot(aquiferg, trend = \"1st\")\n\n\n\n\n\n\n\n\n\n\n\n\nDocumentación Interpolación inderp\nDocumentación persp\nDocumentación drape.plot\n\n\npar(mfrow = c(2, 2),\n    mar = c(3, 3, 1, 1),\n    mgp = c(2, 1, 0))\n# Esta función agrupa los siguientes gráficos en\n# una matrix 2x2\n\ngrillas &lt;- interp(aquifer$Este,\n                  aquifer$Norte,\n                  aquifer$Profundidad)\n\npersp(grillas$x,\n      grillas$y,\n      grillas$z,\n      xlab = \"Este\",\n      ylab = \"Norte\",\n      zlab = \"Nivel freatico\",\n      phi = 30,\n      theta = 20,\n      col = \"lightblue\",\n      expand = .5,\n      ticktype = \"detailed\")\n\ndrape.plot(grillas$x,\n           grillas$y,\n           grillas$z,\n           xlab = \"Este\",\n           ylab = \"Norte\",\n           zlab = \"z\",\n           theta = 45,\n           col = topo.colors(64),\n           expand = .5,\n           ticktype = \"detailed\")\n\n\ndrape.plot(grillas$x,\n           grillas$y,\n           grillas$z,\n           xlab = \"Este\",\n           ylab = \"Norte\",\n           zlab = \"z\",\n           theta = -10,\n           col = topo.colors(64),\n           expand = .5,\n           ticktype = \"detailed\")\n\n\ndrape.plot(grillas$x,\n           grillas$y,\n           grillas$z,\n           xlab = \"Este\",\n           ylab = \"Norte\",\n           zlab = \"z\",\n           theta = 60,\n           col = topo.colors(64),\n           expand = .5,\n           ticktype = \"detailed\")\n\n\n\n\n\n\n\n\n\n\n\n\nDocumentación contour\nDocumentación filled.contour\n\n\npar(mfrow = c(2, 1),\n    mar = c(1,1,1,1))\n\ncontour(grillas, nlevels = 10, main = \"Contorno\")\nimage(grillas$z, main =  \"Grilla\")\n\n\n\n\n\n\n\n\n\nfilled.contour(grillas, levels = seq(1000,\n                                     5000,\n                                     len = 10),\n               col = heat.colors(10),\n                main = \"grilla niveles\")\n\n\n\n\n\n\n\n\n\n\n\n\nh &lt;- seq(0, 1, len = 50)\nu &lt;- seq(0, 1, len = 50)\n\nejemplo1CH  &lt;- function(h, u, sigma, a, b, c, d, delta) {\n    (sigma^2/((a^2*u^2+c)^(d/2)))*exp(-(b^2*h^2)/(a^2*u^2+c))*exp(-delta*u^2)\n    }\nh &lt;- seq(0, 1, len = 20)\nu &lt;- seq(1, 10, len = 20)\nf &lt;- outer(h, u, ejemplo1CH, sigma=3, a=1, b=3, c=1, d=2, delta=0)\n\npar(mfrow = c(2, 2),\n    mar = c(3, 3, 1, 1),\n    mgp = c(2, 1, 0))\n\ndrape.plot(h,\n           u,\n           f,\n           main = \"Cressie-Huang; 1 (25,1,0.6)\",\n           xlab = \"h\",\n           ylab = \"u\",\n           zlab = \"Covarianza\",\n           ltheta = 75,\n           col = terrain.colors(64))\n\ndrape.plot(h,\n           u,\n           f,\n           main = \"Cressie-Huang; 1 (25,1,0.6)\",\n           xlab = \"h\",\n           ylab = \"u\",\n           zlab = \"Covarianza\",\n           theta = -150,\n           col = terrain.colors(64))\npersp(h,\n      u,\n      f,\n      main = \"Cressie-Huang; 1 (25,1,0.6)\",\n      xlab = \"h\",\n      ylab = \"u\",\n      zlab = \"Covarianza\",\n      ltheta = 75)\n\ncontour(h,\n        u,\n        f,\n        col = topo.colors(10),\n        xlim = c(0,0.6))",
    "crumbs": [
      "Geoestadística",
      "Geoestadística Univariada con GeoR"
    ]
  },
  {
    "objectID": "GeoestadisticaUnivariadaConGeoR.html#modelando-la-media-con-regresión-polinomial",
    "href": "GeoestadisticaUnivariadaConGeoR.html#modelando-la-media-con-regresión-polinomial",
    "title": "Geoestadística univariada con geoR",
    "section": "",
    "text": "reg1 &lt;- lm(Profundidad ~ Este + Norte, data = aquifer)\nresiduales1  &lt;-  residuals(reg1)\n#summary(reg1)\nanova(reg1)\n\nAnalysis of Variance Table\n\nResponse: Profundidad\n          Df   Sum Sq  Mean Sq F value    Pr(&gt;F)    \nEste       1 19045642 19045642  460.95 &lt; 2.2e-16 ***\nNorte      1  8960172  8960172  216.86 &lt; 2.2e-16 ***\nResiduals 82  3388069    41318                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\nreg2 &lt;- lm(Profundidad ~ Este + Norte +\n           I(Este^2) + I(Norte^2) +\n           I(Este * Norte),\n           data = aquifer)\nresiduales2  &lt;-  residuals(reg2)\n#summary(reg2)\nanova(reg2)\n\nAnalysis of Variance Table\n\nResponse: Profundidad\n                Df   Sum Sq  Mean Sq  F value    Pr(&gt;F)    \nEste             1 19045642 19045642 551.3469 &lt; 2.2e-16 ***\nNorte            1  8960172  8960172 259.3855 &lt; 2.2e-16 ***\nI(Este^2)        1    55368    55368   1.6028 0.2092235    \nI(Norte^2)       1   152170   152170   4.4051 0.0390253 *  \nI(Este * Norte)  1   451567   451567  13.0723 0.0005259 ***\nResiduals       79  2728964    34544                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\nreg3 &lt;- lm(Profundidad ~ Este * Norte,\n           data = aquifer)\nresiduales3  &lt;-  residuals(reg3)\n#summary(reg3)\nanova(reg3)\n\nAnalysis of Variance Table\n\nResponse: Profundidad\n           Df   Sum Sq  Mean Sq F value    Pr(&gt;F)    \nEste        1 19045642 19045642  517.06 &lt; 2.2e-16 ***\nNorte       1  8960172  8960172  243.25 &lt; 2.2e-16 ***\nEste:Norte  1   404448   404448   10.98  0.001379 ** \nResiduals  81  2983621    36835                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1",
    "crumbs": [
      "Geoestadística",
      "Geoestadística Univariada con GeoR"
    ]
  },
  {
    "objectID": "GeoestadisticaUnivariadaConGeoR.html#estimación-del-semivariograma-empírico",
    "href": "GeoestadisticaUnivariadaConGeoR.html#estimación-del-semivariograma-empírico",
    "title": "Geoestadística univariada con geoR",
    "section": "",
    "text": "Documentación variog\n\n\nvari2 &lt;- variog(aquiferg, trend = \"1st\")\n\nvariog: computing omnidirectional variogram\n\nvari2Cloud &lt;- variog(aquiferg, op = \"cloud\", trend = \"1st\")\n\nvariog: computing omnidirectional variogram\n\nvari2BinCloud &lt;- variog(aquiferg,\n                       max.dist = 200,\n                       op = \"cloud\",\n                       bin.cloud = TRUE)\n\nvariog: computing omnidirectional variogram\n\nvari2Sm &lt;- variog(aquiferg,\n                  trend = \"1st\",\n                  op = \"sm\",\n                  band=11)\n\nvariog: computing omnidirectional variogram\n\n\n\npar(mfrow = c(2, 2), mar = c(3, 3, 1, 1), mgp = c(2, 1, 0))\n     plot(vari2$u, vari2$v, main = \"binned variogram\") # jocastroc: vari2 solo no da el plot se dejo vari2$u,vari2$v\n     plot(vari2Cloud$u, vari2Cloud$v, main = \"variogram cloud\")\n     plot(vari2BinCloud$u, vari2BinCloud$v, main = \"clouds for binned variogram\")\n     plot(vari2Sm$u, vari2Sm$v, main = \"smoothed variogram\")\n\n\n\n\n\n\n\n\n\n\n\nvari1 &lt;- variog(aquiferg)\n\nvariog: computing omnidirectional variogram\n\nvari2 &lt;- variog(aquiferg, trend = \"1st\")\n\nvariog: computing omnidirectional variogram\n\nvari3 &lt;- variog(aquiferg, trend = \"2nd\")\n\nvariog: computing omnidirectional variogram\n\n\n\nplot(vari1$u,vari1$v, main = \"Sin remover tendencia\")\n\n\n\n\n\n\n\nplot(vari2$u,vari2$v, main  = \"Trend 1 \")\n\n\n\n\n\n\n\nplot(vari3$u,vari3$v, main  = \"Trend 2 \")\n\n\n\n\n\n\n\n\n\n\n\n\nvari1 &lt;- variog(aquiferg, estimator.type = \"modulus\")\n\nvariog: computing omnidirectional variogram\n\nvari2 &lt;- variog(aquiferg, trend = \"1st\", estimator.type = \"modulus\")\n\nvariog: computing omnidirectional variogram\n\nvari3 &lt;- variog(aquiferg, trend = \"2nd\", estimator.type = \"modulus\")\n\nvariog: computing omnidirectional variogram\n\n\n\nplot(vari1$u,vari1$v, main = \"Sin remover tendencia\")\n\n\n\n\n\n\n\nplot(vari2$u,vari2$v, main  = \"Trend 1 \")\n\n\n\n\n\n\n\nplot(vari3$u,vari3$v, main  = \"Trend 2 \")\n\n\n\n\n\n\n\n\n\n\n\n\nvari_0 &lt;- variog(aquiferg,\n                 trend = \"1st\",\n                 max.dist = 200,\n                 dir = 0)\n\nvariog: computing variogram for direction = 0 degrees (0 radians)\n        tolerance angle = 22.5 degrees (0.393 radians)\n\nvari_45 &lt;- variog(aquiferg,\n                  trend = \"1st\",\n                  max.dist = 200,\n                  dir = pi / 4)\n\nvariog: computing variogram for direction = 45 degrees (0.785 radians)\n        tolerance angle = 22.5 degrees (0.393 radians)\n\nvari_90 &lt;- variog(aquiferg,\n                  trend = \"1st\",\n                  max.dist = 200,\n                  dir = pi / 2)\n\nvariog: computing variogram for direction = 90 degrees (1.571 radians)\n        tolerance angle = 22.5 degrees (0.393 radians)\n\nvari_135 &lt;- variog(aquiferg,\n                   trend = \"1st\",\n                   max.dist = 200,\n                   dir = 3 * pi / 4)\n\nvariog: computing variogram for direction = 135 degrees (2.356 radians)\n        tolerance angle = 22.5 degrees (0.393 radians)\n\npar(mfrow = c(2, 2),\n    mar = c(3, 3, 1, 1),\n    mgp = c(2, 1, 0))\n\nplot(vari_0$u,vari_0$v, main = \"vari 0\")\nplot(vari_45$u,vari_45$v, main = \"vari 45\")\nplot(vari_90$u,vari_90$v, main = \"vari 90\")\nplot(vari_135$u,vari_135$v, main = \"vari 195\")",
    "crumbs": [
      "Geoestadística",
      "Geoestadística Univariada con GeoR"
    ]
  },
  {
    "objectID": "GeoestadisticaUnivariadaConGeoR.html#estimación-teórica-del-semivariograma",
    "href": "GeoestadisticaUnivariadaConGeoR.html#estimación-teórica-del-semivariograma",
    "title": "Geoestadística univariada con geoR",
    "section": "",
    "text": "Documentación eyefit\nDocumentación variofit\nDocumentación likfit\n\n\nvar1 &lt;- variog(aquiferg,trend=\"1st\",max.dist=200)\n\nvariog: computing omnidirectional variogram\n\n#ini1 &lt;- eyefit(var1)\n#cov.model  sigmasq phi   tausq kappa kappa2   practicalRange\n#1      wave 30805.52  13 8984.94  &lt;NA&gt;   &lt;NA&gt; 38.8889336320589\nini1 &lt;- c(30805.52, 13)\nfitvar1 &lt;- variofit(var1,\n                    cov.model = \"wave\",\n                    ini1,\n                    fix.nugget = TRUE,\n                    nugget = 8984.94,\n                    wei = \"equal\")\n\nvariofit: covariance model used is wave \nvariofit: weights used: equal \nvariofit: minimisation function used: optim \n\nfitvar2 &lt;- variofit(var1,\n                    cov.model = \"wave\",\n                    ini1,\n                    fix.nugget = TRUE,\n                    nugget = 8984.94,\n                    wei = \"npairs\")\n\nvariofit: covariance model used is wave \nvariofit: weights used: npairs \nvariofit: minimisation function used: optim \n\nfitvar3 &lt;- variofit(var1,\n                    ini1,\n                    fix.nugget = TRUE,\n                    nugget = 8984.94,\n                    wei = \"cressie\")\n\nvariofit: covariance model used is matern \nvariofit: weights used: cressie \nvariofit: minimisation function used: optim \n\nfitvar4 &lt;- likfit(aquiferg,\n                  coords = aquiferg$coords,\n                  data = aquiferg$data,\n                  trend = \"1st\",\n                  ini.cov.pars = ini1,\n                  fix.nugget = T,\n                  nugget = 8984.94,\n                  cov.model = \"wave\",\n                  lik.method = \"ML\")\n\nkappa not used for the wave correlation function\n---------------------------------------------------------------\nlikfit: likelihood maximisation using the function optim.\nlikfit: Use control() to pass additional\n         arguments for the maximisation function.\n        For further details see documentation for optim.\nlikfit: It is highly advisable to run this function several\n        times with different initial values for the parameters.\nlikfit: WARNING: This step can be time demanding!\n---------------------------------------------------------------\nlikfit: end of numerical maximisation.\n\nfitvar5 &lt;- likfit(aquiferg,\n                  coords = aquiferg$coords,\n                  data = aquiferg$data,\n                  trend = \"1st\",\n                  ini.cov.pars = ini1,\n                  fix.nugget = T,\n                  nugget = 8984.94,\n                  cov.model = \"wave\",\n                  lik.method = \"REML\")\n\nkappa not used for the wave correlation function\n---------------------------------------------------------------\nlikfit: likelihood maximisation using the function optim.\nlikfit: Use control() to pass additional\n         arguments for the maximisation function.\n        For further details see documentation for optim.\nlikfit: It is highly advisable to run this function several\n        times with different initial values for the parameters.\nlikfit: WARNING: This step can be time demanding!\n---------------------------------------------------------------\nlikfit: end of numerical maximisation.\n\n\n\nplot(var1$u,var1$v,\n     xlab = \"h\",\n     ylab = \"semivarianza\",\n     cex.lab = 1.3,\n     cex.axis = 1.2,\n     main = \"Estimación teórica del modelo de semivariograma\",\n     col.main = 4, cex.main =1.3)\nlines(fitvar1, col = 1)\nlines(fitvar2, col = 2)\nlines(fitvar3, col = 3)\nlines(fitvar4, col = 4)\nlines(fitvar5, col = 5)\nlegend(130, 18000,\n       c(\"MCO\", \"MCPnpairs\", \"MCPcressie\", \"ML\", \"REML\"),\n       lwd = 2,\n       lty = 2:7,\n       col = 2:7,\n       box.col = 9,\n       text.col = 2:7)",
    "crumbs": [
      "Geoestadística",
      "Geoestadística Univariada con GeoR"
    ]
  },
  {
    "objectID": "GeoestadisticaUnivariadaConGeoR.html#resultados",
    "href": "GeoestadisticaUnivariadaConGeoR.html#resultados",
    "title": "Geoestadística univariada con geoR",
    "section": "",
    "text": "#summary(fitvar1)\n#summary(fitvar2)\n#summary(fitvar3)\n#summary(fitvar4)\n#summary(fitvar5)",
    "crumbs": [
      "Geoestadística",
      "Geoestadística Univariada con GeoR"
    ]
  },
  {
    "objectID": "GeoestadisticaUnivariadaConGeoR.html#pulimiento-de-medianas",
    "href": "GeoestadisticaUnivariadaConGeoR.html#pulimiento-de-medianas",
    "title": "Geoestadística univariada con geoR",
    "section": "",
    "text": "Esta es una alternativa al modelamiento de la media cuando los modelos de regresión polinómicos usuales no logran el objetivo de eliminar la tendencia ya sea porque el tipo de tendencia corresponde mas a unas ventanas móviles o porque hay presentes datos atípicos.\n\n\nLista de librerías con link a la documentación.\n\nrm(list=ls())\nlibrary(gstat)\nlibrary(sp)\nlibrary(mvtnorm)\n\n\nAdjuntando el paquete: 'mvtnorm'\n\n\nThe following objects are masked from 'package:spam':\n\n    rmvnorm, rmvt\n\n\n\ngstat\nsp\n\n\n\n\n\nn_x &lt;- 4\nn_y &lt;- 6\nx &lt;- seq(0, 1, len = n_x)\ny &lt;- seq(0, 1, len = n_y)\ncoordenadas &lt;- as.data.frame(expand.grid(x, y))\nnames(coordenadas) &lt;- c(\"X\", \"Y\")\n\nEncabezado coordenadas\n\n\n\nX\nY\n\n\n\n\n0.0000000\n0.0\n\n\n0.3333333\n0.0\n\n\n0.6666667\n0.0\n\n\n1.0000000\n0.0\n\n\n0.0000000\n0.2\n\n\n0.3333333\n0.2\n\n\n\n\n\n\nEsto define un objeto vgm que es el tipo de objeto que usa el paquete gstat para los modelos teóricos de variograma. Con este objeto se pueden definir modelos anidados.\n\nvgm\n\n\nvario &lt;- vgm(10, # Punto de silla\n             \"Exp\", # Modelo, ver documentación\n             0.5)  # Rango\nprint(vario)\n\n  model psill range\n1   Exp    10   0.5\n\n\n\n\n\n\nvgmArea\ncoordinates\n\n\ncoordinates(coordenadas) &lt;- ~X + Y\n#class(coordenadas) # Cambio de objedto dataframe a sp\n\n\ncov_mat &lt;- vgmArea(coordenadas, # Matriz de ubiaciones SP\n        vgm = vario) # VGM object\n\nprint(dim(cov_mat))\n\n[1] 24 24\n\n\n\n\n\nSimulación dada la media y la matriz de varianza\n\nmu  &lt;- rep(0, n_x * n_y) # Media del proceso\nsimu &lt;- rmvnorm(1,\n                mean = mu,\n                sigma = cov_mat)\nprint(simu[1:5])\n\n[1] -0.1754460 -1.0791818 -2.6804808 -0.5803572 -0.7986549\n\n\n\n\n\nUnir las coordenadas con la columna de simulación\n\ndata &lt;- as.data.frame(cbind(coordenadas@coords,\n                            Simula = t(simu)))\nnames(data) &lt;- c(\"X\", \"Y\", \"Var\")\nprint(head(data))\n\n          X   Y        Var\n1 0.0000000 0.0 -0.1754460\n2 0.3333333 0.0 -1.0791818\n3 0.6666667 0.0 -2.6804808\n4 1.0000000 0.0 -0.5803572\n5 0.0000000 0.2 -0.7986549\n6 0.3333333 0.2  2.1251560\n\n\nReshape para matriz, esto transforma la tabla de datos en matriz\n\ntabla &lt;- reshape2::dcast(data,\n                         X ~ Y,\n                         value.var = \"Var\")\nrownames(tabla) &lt;- tabla[, 1]\ntabla &lt;- tabla[, c(-1)]\nprint(tabla)\n\n                           0        0.2       0.4         0.6        0.8\n0                 -0.1754460 -0.7986549  5.034347  0.02068872  0.6737984\n0.333333333333333 -1.0791818  2.1251560  1.320088 -2.71596165 -2.6710621\n0.666666666666667 -2.6804808  0.8508661 -1.648666 -3.61460060 -4.2433416\n1                 -0.5803572 -4.3177146 -2.240096 -2.89269507 -1.6432483\n                           1\n0                  4.3284278\n0.333333333333333 -0.5319672\n0.666666666666667  2.9161060\n1                  3.3113610\n\n\nPulimiento de medianas de la tabla\n\nmed &lt;- medpolish(tabla)\n\n1: 30.92069\n2: 29.92268\nFinal: 29.92268\n\n\n\ngeo_data &lt;- reshape2::melt(med$residuals)\nprint(med)\n\n\nMedian Polish Results (Dataset: \"tabla\")\n\nOverall: -0.8339295\n\nRow Effects:\n                0 0.333333333333333 0.666666666666667                 1 \n       1.93302399        0.03220131       -1.21776765       -0.03220131 \n\nColumn Effects:\n         0        0.2        0.4        0.6        0.8          1 \n-0.4531186  0.5024070  1.2624238 -1.7385684 -1.3232257  3.7034126 \n\nResiduals:\n                         0     0.2      0.4      0.6      0.8        1\n0                 -0.82142 -2.4002  2.67283  0.66016  0.89793 -0.47408\n0.333333333333333  0.17567  2.4245  0.85939 -0.17567 -0.54611 -3.43365\n0.666666666666667 -0.17567  2.4002 -0.85939  0.17567 -0.86842  1.26439\n1                  0.73889 -3.9540 -2.63639 -0.28800  0.54611  0.47408\n\n\nReshape de los datos, con efecto de la fila y la columna\n\ntabla_residuales &lt;- as.data.frame(med$residuals)\nnames(tabla_residuales) &lt;- med$col\nrownames(tabla_residuales) &lt;- med$row\ngeo_data &lt;- reshape2::melt(as.matrix(tabla_residuales))\n\ngeo_data &lt;- cbind(data,\n                  geo_data,\n                  med$overall)\nnames(geo_data) &lt;- c(\"X\",\n                     \"Y\",\n                     \"Var\",\n                     \"Efecto fila\",\n                     \"Efecto columa\",\n                     \"Residual\",\n                     \"Efecto Global\")\nprint(geo_data)\n\n           X   Y         Var Efecto fila Efecto columa   Residual Efecto Global\n1  0.0000000 0.0 -0.17544600  1.93302399    -0.4531186 -0.8214219    -0.8339295\n2  0.3333333 0.0 -1.07918181  0.03220131    -0.4531186  0.1756650    -0.8339295\n3  0.6666667 0.0 -2.68048078 -1.21776765    -0.4531186 -0.1756650    -0.8339295\n4  1.0000000 0.0 -0.58035718 -0.03220131    -0.4531186  0.7388923    -0.8339295\n5  0.0000000 0.2 -0.79865485  1.93302399     0.5024070 -2.4001563    -0.8339295\n6  0.3333333 0.2  2.12515597  0.03220131     0.5024070  2.4244772    -0.8339295\n7  0.6666667 0.2  0.85086614 -1.21776765     0.5024070  2.4001563    -0.8339295\n8  1.0000000 0.2 -4.31771460 -0.03220131     0.5024070 -3.9539908    -0.8339295\n9  0.0000000 0.4  5.03434662  1.93302399     1.2624238  2.6728284    -0.8339295\n10 0.3333333 0.4  1.32008790  0.03220131     1.2624238  0.8593923    -0.8339295\n11 0.6666667 0.4 -1.64866572 -1.21776765     1.2624238 -0.8593923    -0.8339295\n12 1.0000000 0.4 -2.24009637 -0.03220131     1.2624238 -2.6363893    -0.8339295\n13 0.0000000 0.6  0.02068872  1.93302399    -1.7385684  0.6601627    -0.8339295\n14 0.3333333 0.6 -2.71596165  0.03220131    -1.7385684 -0.1756650    -0.8339295\n15 0.6666667 0.6 -3.61460060 -1.21776765    -1.7385684  0.1756650    -0.8339295\n16 1.0000000 0.6 -2.89269507 -0.03220131    -1.7385684 -0.2879958    -0.8339295\n17 0.0000000 0.8  0.67379836  1.93302399    -1.3232257  0.8979296    -0.8339295\n18 0.3333333 0.8 -2.67106214  0.03220131    -1.3232257 -0.5461082    -0.8339295\n19 0.6666667 0.8 -4.24334155 -1.21776765    -1.3232257 -0.8684187    -0.8339295\n20 1.0000000 0.8 -1.64324827 -0.03220131    -1.3232257  0.5461082    -0.8339295\n21 0.0000000 1.0  4.32842781  1.93302399     3.7034126 -0.4740792    -0.8339295\n22 0.3333333 1.0 -0.53196718  0.03220131     3.7034126 -3.4336516    -0.8339295\n23 0.6666667 1.0  2.91610598 -1.21776765     3.7034126  1.2643906    -0.8339295\n24 1.0000000 1.0  3.31136101 -0.03220131     3.7034126  0.4740792    -0.8339295\n\n\nValidación de la descomposición\n\nvalida &lt;- cbind(geo_data$Var,\n                geo_data[[\"Efecto fila\"]] +\n                geo_data[[\"Efecto columa\"]] +\n                geo_data[[\"Residual\"]] +\n                geo_data[[\"Efecto Global\"]])\nvalida &lt;- as.data.frame(valida)\nnames(valida) &lt;- c(\"datos\", \"suma\")\nprint(valida)\n\n         datos        suma\n1  -0.17544600 -0.17544600\n2  -1.07918181 -1.07918181\n3  -2.68048078 -2.68048078\n4  -0.58035718 -0.58035718\n5  -0.79865485 -0.79865485\n6   2.12515597  2.12515597\n7   0.85086614  0.85086614\n8  -4.31771460 -4.31771460\n9   5.03434662  5.03434662\n10  1.32008790  1.32008790\n11 -1.64866572 -1.64866572\n12 -2.24009637 -2.24009637\n13  0.02068872  0.02068872\n14 -2.71596165 -2.71596165\n15 -3.61460060 -3.61460060\n16 -2.89269507 -2.89269507\n17  0.67379836  0.67379836\n18 -2.67106214 -2.67106214\n19 -4.24334155 -4.24334155\n20 -1.64324827 -1.64324827\n21  4.32842781  4.32842781\n22 -0.53196718 -0.53196718\n23  2.91610598  2.91610598\n24  3.31136101  3.31136101",
    "crumbs": [
      "Geoestadística",
      "Geoestadística Univariada con GeoR"
    ]
  },
  {
    "objectID": "gfdata.html",
    "href": "gfdata.html",
    "title": "gfdata",
    "section": "",
    "text": "Los objetos de clase gfdata son una extensión de los objetos SpatFD para mediciones repetidas, combinan coordenadas espaciales con funciones o series temporales observadas en cada ubicación espacial. Aunque el término “serie temporal” es genérico, las observaciones también pueden estar distribuidas según la frecuencia, profundidad u otra dimensión espacial, en lugar de tiempo.",
    "crumbs": [
      "Objetos",
      "gfdata"
    ]
  },
  {
    "objectID": "gfdata.html#descripción",
    "href": "gfdata.html#descripción",
    "title": "gfdata",
    "section": "",
    "text": "Los objetos de clase gfdata son una extensión de los objetos SpatFD para mediciones repetidas, combinan coordenadas espaciales con funciones o series temporales observadas en cada ubicación espacial. Aunque el término “serie temporal” es genérico, las observaciones también pueden estar distribuidas según la frecuencia, profundidad u otra dimensión espacial, en lugar de tiempo.",
    "crumbs": [
      "Objetos",
      "gfdata"
    ]
  },
  {
    "objectID": "gfdata.html#argumentos",
    "href": "gfdata.html#argumentos",
    "title": "gfdata",
    "section": "Argumentos",
    "text": "Argumentos\n\ndata: Matriz que contiene los datos, donde cada columna corresponde a un sujeto, y las filas representan una secuencia de puntos de datos (ordenados según el tiempo, frecuencia, profundidad, etc.). La última columna debe incluir las clases para clasificación.\np: Número de repeticiones para cada clase.\nbasis: Tipo de funciones base a utilizar. Puede ser “Fourier” o “Bsplines” (predeterminado es “Bsplines”).\ncoords: Matriz con las coordenadas espaciales (x, y).\nnbasis: Número de funciones base.\nnames: Nombres de las clases de datos.\nlambda: Valor del parámetro de suavizado.",
    "crumbs": [
      "Objetos",
      "gfdata"
    ]
  },
  {
    "objectID": "gfdata.html#detalles",
    "href": "gfdata.html#detalles",
    "title": "gfdata",
    "section": "Detalles",
    "text": "Detalles\nLos objetos de clase gfdata almacenan los datos funcionales, sus parámetros, los resultados del análisis de componentes principales funcionales (PCA funcional), y las coordenadas espaciales para cada variable. Cada variable tiene su propio conjunto de datos funcionales, data.frame o matriz, y su correspondiente archivo de coordenadas espaciales.\n\ndata(vowels)\n\n# Definir parámetros y nombres para los datos\np = 228\nnelec = 21\nnvow = 5\nnames_vowels = c(\"a\", \"e\", \"i\", \"o\", \"u\")\nn.basis = c(14, 13, 12, 13, 11)\n\n# Crear el objeto gfdata\ns4.gfdata = gfdata(data = vowels, p = p, names = names_vowels, coords = vowels_coords, nbasis = n.basis)",
    "crumbs": [
      "Objetos",
      "gfdata"
    ]
  },
  {
    "objectID": "gfdata.html#summary",
    "href": "gfdata.html#summary",
    "title": "gfdata",
    "section": "Summary",
    "text": "Summary\nPara cada variable incluida en el objeto gfdata, esta función devuelve:\n\nHead of data: Muestra las primeras filas de los datos funcionales.\nCoordinates: Muestra las coordenadas espaciales asociadas a las observaciones.\nEigenvalues: Valores propios obtenidos del análisis de componentes principales.\nMean coefficients: Coeficientes medios de las funciones base.\nProportion of explained variance by each component: Proporción de la varianza explicada por cada componente principal.\n\n\n#summary.gfdata(s4.gfdata)",
    "crumbs": [
      "Objetos",
      "gfdata"
    ]
  },
  {
    "objectID": "intro_spatial.html",
    "href": "intro_spatial.html",
    "title": "Cudernos de Estadística Espacial",
    "section": "",
    "text": "En los siguientes cuadernos encontrará ejemplos con código sobre estadística espacial. Para poder correr todos los ejemplos clone el repositorio de la siguiente forma. Debe tener instalado previamente git en su computador.\ngit clone https://github.com/mpbohorquezc/Clases-EE-UN.git\nSi esta corriendo sobre Ubuntu o Mint es importante tener algunos compiladores previamente instalados para poder instanciar algunas de las librerías. En general con los siguientes comandos podría correr cualquiera de los cuadernos sin problema\nsudo apt-get install r-base-dev\nsudo apt install liblapack-dev libopenblas-dev\nSi alguna dependencia hace falta algunos repositorios los puede descargar e instalar a manera de archivo .tar.gz o se encuentran simplemente en los repositorios del CRAN.\n\n\n\n1. Introducción\n2. Geoestadística con sgeostat\n3. Geoestadística Univariada con geoR\n4. Otros Tipos de Kriging",
    "crumbs": [
      "Cuadernos de Estadística Espacial"
    ]
  },
  {
    "objectID": "intro_spatial.html#indice",
    "href": "intro_spatial.html#indice",
    "title": "Cudernos de Estadística Espacial",
    "section": "",
    "text": "1. Introducción\n2. Geoestadística con sgeostat\n3. Geoestadística Univariada con geoR\n4. Otros Tipos de Kriging",
    "crumbs": [
      "Cuadernos de Estadística Espacial"
    ]
  },
  {
    "objectID": "Kriging_puntual.html",
    "href": "Kriging_puntual.html",
    "title": "Kriging_Puntual",
    "section": "",
    "text": "Kriging es una técnica de interpolación espacial que permite estimar valores desconocidos en una superficie a partir de los valores conocidos en ubicaciones cercanas. Es especialmente útil para datos de alta densidad y para datos con estructuras espaciales complejas. En este cuaderno, vamos a explorar los diferentes tipos de Kriging y cómo implementarlos en R.\nAntes de comenzar, asegúrate de tener instalados los siguientes paquetes de R: “gstat”, “sp”, “raster” y “ggplot2”. Si no los tienes, puedes instalarlos mediante el siguiente código:\n\n# Instalar paquetes si es necesario\n\nlibrary(gstat)\nlibrary(sp)\nlibrary(raster)\nlibrary(ggplot2)\nlibrary(phylin)\n\n\nAdjuntando el paquete: 'phylin'\n\n\nThe following object is masked from 'package:gstat':\n\n    idw\n\n# Generación de datos simulados para los ejemplos\nset.seed(1029)\ncoords &lt;- data.frame(x = runif(10, 0, 100), y = runif(10, 0, 100))\nvalues &lt;- data.frame(value = rnorm(10))\n\n# Combinar 'coords' y 'values' en un solo data frame\ndata &lt;- cbind(coords, values)\n\n# Convertir 'data' en un objeto espacial\ncoordinates(data) &lt;- ~ x + y\nproj4string(data) &lt;- CRS(\"+proj=utm +zone=33 +datum=WGS84\")\n\n\n\nKriging es una técnica de interpolación espacial que se basa en la teoría de la estadística espacial. La idea fundamental detrás de Kriging es que la estimación del valor desconocido en una ubicación dada se hace como una combinación lineal ponderada de los valores conocidos en las ubicaciones vecinas. Los pesos de esta combinación se determinan utilizando la información de covarianza entre los puntos en el espacio. Esta técnica se utiliza comúnmente en estadística espacial, geología, minería, geofísica, oceanografía y otros campos que involucran la toma de medidas en lugares dispersos en el espacio.\nEl nombre “Kriging” proviene del geólogo Danie G. Krige, quien fue el primero en aplicar esta técnica para la exploración de minerales en Sudáfrica en la década de 1950\n\n\n\nEn esta sección se explica el método de kriging simple, que es una técnica de interpolación espacial que utiliza una función de tendencia conocida y un modelo de variograma ajustado a los datos. El objetivo es estimar el valor de una variable Z en una ubicación s0 a partir de los valores observados en n ubicaciones si cercanas. El kriging simple asume que la variable Z se puede descomponer como:\n\\[Z(s) = μ(s) + ε(s),\\]\ndonde \\(μ(s)\\) es la función de tendencia conocida y \\(ε(s)\\) es un proceso espacial aleatorio con media cero y covarianza \\(C(s_i,s_j) = Cov(ε(s_i),ε(s_j))\\). El predictor del kriging simple es una combinación lineal de los valores observados:\n\\[p(Z,s_0) = μ(s_0) + ∑_{i=1}^n λ_i (Z(s_i) - μ(s_i)),\\]\ndonde los pesos \\(λ_i\\) se obtienen resolviendo el sistema de ecuaciones:\n\\[∑_{j=1}^n λ_j C(s_i,s_j) - C(s_i,s_0) = 0, \\  i = 1,...,n.\\]\nEl kriging simple minimiza el error cuadrático medio entre el valor estimado y el verdadero, que se denomina varianza kriging y se calcula como:\n\\[σ^2 KS(s_0) = C(s_0,s_0) - ∑_{i=1}^n ∑_{j=1}^n λ_i λ_j C(s_i,s_j).\\]\nPara implementar el kriging simple en R se puede utilizar la función krig del paquete phylin, que requiere como argumentos los valores observados, las coordenadas de las ubicaciones muestreadas y las ubicaciones a interpolar, el modelo de variograma ajustado y el valor conocido de la media (o NA para usar kriging ordinario). A continuación se muestra un ejemplo con datos simulados:\n\n# Calcular el variograma experimental\nvgram &lt;- variogram(value ~ 1, data)\n\n# Ajustar un modelo de variograma\nmodel &lt;- vgm(psill = 1, model = \"Sph\", range = 50, nugget = 0)\nvfit &lt;- fit.variogram(vgram, model)\n\nWarning in fit.variogram(vgram, model): linear model has singular covariance\nmatrix\n\n\nWarning in fit.variogram(vgram, model): singular model in variogram fit\n\n\nWarning in fit.variogram(object, model, fit.sills = fit.sills, fit.ranges =\nfit.ranges, : No convergence after 200 iterations: try different initial\nvalues?\n\n# Crear una cuadrícula de predicción\ngrd &lt;- expand.grid(x = seq(0, 100, by = 5), y = seq(0, 100, by = 5))\ncoordinates(grd) &lt;- ~ x + y\ngridded(grd) &lt;- TRUE\nproj4string(grd) &lt;- CRS(\"+proj=utm +zone=33 +datum=WGS84\")\n\n# Kriging Simple\nkriged_values &lt;- krige(value ~ 1, data, grd, model = vfit, nmax = 5)\n\n[using ordinary kriging]\n\n\n\n# Visualización\n#spplot(kriged_values[\"var1.pred\"], main = \"Kriging Simple Prediction\")\n\n\n\n\nEl kriging ordinario es el tipo más general y más utilizado de kriging. Presupone que el valor medio constante es desconocido y lo estima a partir de los datos disponibles. Esta es una suposición razonable a menos que haya una razón científica para rechazarla.\nEl kriging ordinario se puede expresar como:\n\\[Z^*(x_0) = \\sum_{i=1}^n \\lambda_i Z(x_i)\\]\nDonde \\(Z^*(x_0)\\) es el valor estimado en el punto \\(x_0\\), \\(Z(x_i)\\) son los valores medidos en los puntos \\(x_i\\), \\(n\\) es el número de puntos medidos y \\(\\lambda_i\\) son los pesos óptimos que minimizan la varianza del error de estimación.\nLos pesos óptimos se obtienen resolviendo un sistema de ecuaciones lineales conocido como sistema krigiano:\n\\[\n\\begin{bmatrix}\n\\gamma_{11} & \\gamma_{12} & \\cdots & \\gamma_{1n} & 1 \\\\\n\\gamma_{21} & \\gamma_{22} & \\cdots & \\gamma_{2n} & 1 \\\\\n\\vdots      & \\vdots      & \\ddots & \\vdots      & 1 \\\\\n\\gamma_{n1} & \\gamma_{n2} & \\cdots & \\gamma_{nn} & 1 \\\\\n1           & 1           & \\cdots & 1           & 0\n\\end{bmatrix}\n\\begin{bmatrix}\n\\lambda_1 \\\\\n\\lambda_2 \\\\\n\\vdots    \\\\\n\\lambda_n \\\\\nm\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\gamma(x_0,x_1) \\\\\n\\gamma(x_0,x_2) \\\\\n\\vdots          \\\\\n\\gamma(x_0,x_n) \\\\\n-1\n\\end{bmatrix}\n\\]\nDonde \\(\\gamma_{ij}\\) son los semivariogramas entre los puntos medidos, \\(\\gamma(x_0,x_i)\\) son los semivariogramas entre el punto a estimar y los puntos medidos y \\(m\\) es un multiplicador lagrangeano que representa la estimación del valor medio constante.\nPara implementar el kriging ordinario en R, se pueden utilizar las librerías “gstat” o “kriging”. A continuación se muestra un ejemplo usando la librería “gstat”.\n\n# Ajustar modelo de variograma para kriging ordinario\nvgram &lt;- variogram(value ~ 1, data)\nvfit &lt;- fit.variogram(vgram, model)\n\nWarning in fit.variogram(vgram, model): linear model has singular covariance\nmatrix\n\n\nWarning in fit.variogram(vgram, model): singular model in variogram fit\n\n\nWarning in fit.variogram(object, model, fit.sills = fit.sills, fit.ranges =\nfit.ranges, : No convergence after 200 iterations: try different initial\nvalues?\n\n# Kriging ordinario\nkriged_values_ordinary &lt;- krige(value ~ 1, data, grd, model = vfit, nmax = 5)\n\n[using ordinary kriging]\n\n\n\n# Visualización\n#spplot(kriged_values_ordinary[\"var1.pred\"], main = \"Kriging Ordinario Prediction\")\n\n\n\n\nEl kriging universal es una variante del kriging que permite incorporar variables auxiliares que influyen en la variable de interés. Por ejemplo, si queremos interpolar la temperatura en una región, podemos usar como variables auxiliares la altitud, la latitud o la distancia al mar. El kriging universal asume que la variable de interés se puede expresar como una combinación lineal de las variables auxiliares más un error espacialmente correlacionado. Es decir:\n\\[\nZ(s) = p ∑_{j=0} X_j(s)β_j +ε(s),\n\\]\ndonde \\(Z(s)\\) es la variable de interés en el punto \\(s\\), \\(X_j(s)\\) son las variables auxiliares (incluyendo una constante), βj son los coeficientes desconocidos y ε(s) es el error espacial con variograma conocido.\nPara estimar \\(Z(s_0)\\) en un punto no observado \\(s_0\\), se usa el predictor del kriging universal:\n\\[\np(Z,s_0) = ∑_{i=1}^n λ_iZ(s_i),\n\\]\ndonde \\(λ_i\\) son los pesos que minimizan el error cuadrático medio de predicción sujeto a las restricciones:\n\\[λ^⊤X = x^⊤ 0,\\]\ndonde \\(X\\) es una matriz con las variables auxiliares en los puntos observados y \\(x_0\\) es un vector con las variables auxiliares en el punto \\(s_0\\).\nPara implementar el kriging universal en R, podemos usar el paquete gstat y la función krige. Esta función requiere una fórmula que defina la variable dependiente como un modelo lineal de las variables independientes, un objeto espacial con las coordenadas y los datos observados, un objeto espacial con las coordenadas de los puntos a predecir y un modelo de variograma para el error espacial.\nA continuación se muestra un ejemplo de cómo usar krige para realizar kriging universal con dos variables auxiliares: \\(x\\) e \\(y\\).\n\n# Añadir variables auxiliares al conjunto de datos\nvalues$x &lt;- coordinates(data)[,1]\nvalues$y &lt;- coordinates(data)[,2]\n\n# Ajustar variograma\nvgram_universal &lt;- variogram(value ~ x + y, data)\nvfit_universal &lt;- fit.variogram(vgram_universal, vgm(model = \"Sph\", psill = 1, range = 50, nugget = 0))\n\nWarning in fit.variogram(vgram_universal, vgm(model = \"Sph\", psill = 1, :\nsingular model in variogram fit\n\n\nWarning in fit.variogram(object, model, fit.sills = fit.sills, fit.ranges =\nfit.ranges, : No convergence after 200 iterations: try different initial\nvalues?\n\n# Kriging Universal\nkriged_values_universal &lt;- krige(value ~ x + y, data, grd, model = vfit_universal)\n\n[using universal kriging]\n\n# Visualización\n#spplot(kriged_values_universal[\"var1.pred\"], main = \"Kriging Universal Prediction\")",
    "crumbs": [
      "Geoestadística",
      "Kriging"
    ]
  },
  {
    "objectID": "Kriging_puntual.html#introducción-kriging",
    "href": "Kriging_puntual.html#introducción-kriging",
    "title": "Kriging_Puntual",
    "section": "",
    "text": "Kriging es una técnica de interpolación espacial que se basa en la teoría de la estadística espacial. La idea fundamental detrás de Kriging es que la estimación del valor desconocido en una ubicación dada se hace como una combinación lineal ponderada de los valores conocidos en las ubicaciones vecinas. Los pesos de esta combinación se determinan utilizando la información de covarianza entre los puntos en el espacio. Esta técnica se utiliza comúnmente en estadística espacial, geología, minería, geofísica, oceanografía y otros campos que involucran la toma de medidas en lugares dispersos en el espacio.\nEl nombre “Kriging” proviene del geólogo Danie G. Krige, quien fue el primero en aplicar esta técnica para la exploración de minerales en Sudáfrica en la década de 1950",
    "crumbs": [
      "Geoestadística",
      "Kriging"
    ]
  },
  {
    "objectID": "Kriging_puntual.html#kriging-simple",
    "href": "Kriging_puntual.html#kriging-simple",
    "title": "Kriging_Puntual",
    "section": "",
    "text": "En esta sección se explica el método de kriging simple, que es una técnica de interpolación espacial que utiliza una función de tendencia conocida y un modelo de variograma ajustado a los datos. El objetivo es estimar el valor de una variable Z en una ubicación s0 a partir de los valores observados en n ubicaciones si cercanas. El kriging simple asume que la variable Z se puede descomponer como:\n\\[Z(s) = μ(s) + ε(s),\\]\ndonde \\(μ(s)\\) es la función de tendencia conocida y \\(ε(s)\\) es un proceso espacial aleatorio con media cero y covarianza \\(C(s_i,s_j) = Cov(ε(s_i),ε(s_j))\\). El predictor del kriging simple es una combinación lineal de los valores observados:\n\\[p(Z,s_0) = μ(s_0) + ∑_{i=1}^n λ_i (Z(s_i) - μ(s_i)),\\]\ndonde los pesos \\(λ_i\\) se obtienen resolviendo el sistema de ecuaciones:\n\\[∑_{j=1}^n λ_j C(s_i,s_j) - C(s_i,s_0) = 0, \\  i = 1,...,n.\\]\nEl kriging simple minimiza el error cuadrático medio entre el valor estimado y el verdadero, que se denomina varianza kriging y se calcula como:\n\\[σ^2 KS(s_0) = C(s_0,s_0) - ∑_{i=1}^n ∑_{j=1}^n λ_i λ_j C(s_i,s_j).\\]\nPara implementar el kriging simple en R se puede utilizar la función krig del paquete phylin, que requiere como argumentos los valores observados, las coordenadas de las ubicaciones muestreadas y las ubicaciones a interpolar, el modelo de variograma ajustado y el valor conocido de la media (o NA para usar kriging ordinario). A continuación se muestra un ejemplo con datos simulados:\n\n# Calcular el variograma experimental\nvgram &lt;- variogram(value ~ 1, data)\n\n# Ajustar un modelo de variograma\nmodel &lt;- vgm(psill = 1, model = \"Sph\", range = 50, nugget = 0)\nvfit &lt;- fit.variogram(vgram, model)\n\nWarning in fit.variogram(vgram, model): linear model has singular covariance\nmatrix\n\n\nWarning in fit.variogram(vgram, model): singular model in variogram fit\n\n\nWarning in fit.variogram(object, model, fit.sills = fit.sills, fit.ranges =\nfit.ranges, : No convergence after 200 iterations: try different initial\nvalues?\n\n# Crear una cuadrícula de predicción\ngrd &lt;- expand.grid(x = seq(0, 100, by = 5), y = seq(0, 100, by = 5))\ncoordinates(grd) &lt;- ~ x + y\ngridded(grd) &lt;- TRUE\nproj4string(grd) &lt;- CRS(\"+proj=utm +zone=33 +datum=WGS84\")\n\n# Kriging Simple\nkriged_values &lt;- krige(value ~ 1, data, grd, model = vfit, nmax = 5)\n\n[using ordinary kriging]\n\n\n\n# Visualización\n#spplot(kriged_values[\"var1.pred\"], main = \"Kriging Simple Prediction\")",
    "crumbs": [
      "Geoestadística",
      "Kriging"
    ]
  },
  {
    "objectID": "Kriging_puntual.html#kriging-ordinario",
    "href": "Kriging_puntual.html#kriging-ordinario",
    "title": "Kriging_Puntual",
    "section": "",
    "text": "El kriging ordinario es el tipo más general y más utilizado de kriging. Presupone que el valor medio constante es desconocido y lo estima a partir de los datos disponibles. Esta es una suposición razonable a menos que haya una razón científica para rechazarla.\nEl kriging ordinario se puede expresar como:\n\\[Z^*(x_0) = \\sum_{i=1}^n \\lambda_i Z(x_i)\\]\nDonde \\(Z^*(x_0)\\) es el valor estimado en el punto \\(x_0\\), \\(Z(x_i)\\) son los valores medidos en los puntos \\(x_i\\), \\(n\\) es el número de puntos medidos y \\(\\lambda_i\\) son los pesos óptimos que minimizan la varianza del error de estimación.\nLos pesos óptimos se obtienen resolviendo un sistema de ecuaciones lineales conocido como sistema krigiano:\n\\[\n\\begin{bmatrix}\n\\gamma_{11} & \\gamma_{12} & \\cdots & \\gamma_{1n} & 1 \\\\\n\\gamma_{21} & \\gamma_{22} & \\cdots & \\gamma_{2n} & 1 \\\\\n\\vdots      & \\vdots      & \\ddots & \\vdots      & 1 \\\\\n\\gamma_{n1} & \\gamma_{n2} & \\cdots & \\gamma_{nn} & 1 \\\\\n1           & 1           & \\cdots & 1           & 0\n\\end{bmatrix}\n\\begin{bmatrix}\n\\lambda_1 \\\\\n\\lambda_2 \\\\\n\\vdots    \\\\\n\\lambda_n \\\\\nm\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\gamma(x_0,x_1) \\\\\n\\gamma(x_0,x_2) \\\\\n\\vdots          \\\\\n\\gamma(x_0,x_n) \\\\\n-1\n\\end{bmatrix}\n\\]\nDonde \\(\\gamma_{ij}\\) son los semivariogramas entre los puntos medidos, \\(\\gamma(x_0,x_i)\\) son los semivariogramas entre el punto a estimar y los puntos medidos y \\(m\\) es un multiplicador lagrangeano que representa la estimación del valor medio constante.\nPara implementar el kriging ordinario en R, se pueden utilizar las librerías “gstat” o “kriging”. A continuación se muestra un ejemplo usando la librería “gstat”.\n\n# Ajustar modelo de variograma para kriging ordinario\nvgram &lt;- variogram(value ~ 1, data)\nvfit &lt;- fit.variogram(vgram, model)\n\nWarning in fit.variogram(vgram, model): linear model has singular covariance\nmatrix\n\n\nWarning in fit.variogram(vgram, model): singular model in variogram fit\n\n\nWarning in fit.variogram(object, model, fit.sills = fit.sills, fit.ranges =\nfit.ranges, : No convergence after 200 iterations: try different initial\nvalues?\n\n# Kriging ordinario\nkriged_values_ordinary &lt;- krige(value ~ 1, data, grd, model = vfit, nmax = 5)\n\n[using ordinary kriging]\n\n\n\n# Visualización\n#spplot(kriged_values_ordinary[\"var1.pred\"], main = \"Kriging Ordinario Prediction\")",
    "crumbs": [
      "Geoestadística",
      "Kriging"
    ]
  },
  {
    "objectID": "Kriging_puntual.html#kriging-universal",
    "href": "Kriging_puntual.html#kriging-universal",
    "title": "Kriging_Puntual",
    "section": "",
    "text": "El kriging universal es una variante del kriging que permite incorporar variables auxiliares que influyen en la variable de interés. Por ejemplo, si queremos interpolar la temperatura en una región, podemos usar como variables auxiliares la altitud, la latitud o la distancia al mar. El kriging universal asume que la variable de interés se puede expresar como una combinación lineal de las variables auxiliares más un error espacialmente correlacionado. Es decir:\n\\[\nZ(s) = p ∑_{j=0} X_j(s)β_j +ε(s),\n\\]\ndonde \\(Z(s)\\) es la variable de interés en el punto \\(s\\), \\(X_j(s)\\) son las variables auxiliares (incluyendo una constante), βj son los coeficientes desconocidos y ε(s) es el error espacial con variograma conocido.\nPara estimar \\(Z(s_0)\\) en un punto no observado \\(s_0\\), se usa el predictor del kriging universal:\n\\[\np(Z,s_0) = ∑_{i=1}^n λ_iZ(s_i),\n\\]\ndonde \\(λ_i\\) son los pesos que minimizan el error cuadrático medio de predicción sujeto a las restricciones:\n\\[λ^⊤X = x^⊤ 0,\\]\ndonde \\(X\\) es una matriz con las variables auxiliares en los puntos observados y \\(x_0\\) es un vector con las variables auxiliares en el punto \\(s_0\\).\nPara implementar el kriging universal en R, podemos usar el paquete gstat y la función krige. Esta función requiere una fórmula que defina la variable dependiente como un modelo lineal de las variables independientes, un objeto espacial con las coordenadas y los datos observados, un objeto espacial con las coordenadas de los puntos a predecir y un modelo de variograma para el error espacial.\nA continuación se muestra un ejemplo de cómo usar krige para realizar kriging universal con dos variables auxiliares: \\(x\\) e \\(y\\).\n\n# Añadir variables auxiliares al conjunto de datos\nvalues$x &lt;- coordinates(data)[,1]\nvalues$y &lt;- coordinates(data)[,2]\n\n# Ajustar variograma\nvgram_universal &lt;- variogram(value ~ x + y, data)\nvfit_universal &lt;- fit.variogram(vgram_universal, vgm(model = \"Sph\", psill = 1, range = 50, nugget = 0))\n\nWarning in fit.variogram(vgram_universal, vgm(model = \"Sph\", psill = 1, :\nsingular model in variogram fit\n\n\nWarning in fit.variogram(object, model, fit.sills = fit.sills, fit.ranges =\nfit.ranges, : No convergence after 200 iterations: try different initial\nvalues?\n\n# Kriging Universal\nkriged_values_universal &lt;- krige(value ~ x + y, data, grd, model = vfit_universal)\n\n[using universal kriging]\n\n# Visualización\n#spplot(kriged_values_universal[\"var1.pred\"], main = \"Kriging Universal Prediction\")",
    "crumbs": [
      "Geoestadística",
      "Kriging"
    ]
  },
  {
    "objectID": "spatfd_object.html",
    "href": "spatfd_object.html",
    "title": "Objetos SpatFD",
    "section": "",
    "text": "El objeto SpatFD crea objetos univariados y multivariados de clase SpatFD a partir de coordenadas espaciales, funciones o series temporales observadas en cada ubicación espacial. El término “series temporales” es genérico, ya que las observaciones pueden estar relacionadas con la frecuencia u otra dimensión espacial, como la profundidad, en lugar del tiempo.",
    "crumbs": [
      "Objetos",
      "SpatFD"
    ]
  },
  {
    "objectID": "spatfd_object.html#argumentos",
    "href": "spatfd_object.html#argumentos",
    "title": "Objetos SpatFD",
    "section": "Argumentos",
    "text": "Argumentos\n\ndata: Los datos deben ser proporcionados en un data-frame o una matriz donde cada columna corresponde a una ubicación, y las filas son una secuencia de puntos de datos, ordenados según el tiempo, frecuencia, profundidad, etc. También puede ser un objeto fd del paquete fda.\ncoords: Un data-frame o matriz con coordenadas espaciales (x, y). El número de columnas en data debe coincidir con el número de filas en coords para cada variable.\nbasis: Funciones base. Puede ser “Fourier” o “Bsplines” (predeterminado: “Bsplines”).\nnbasis: El número de funciones base.\nlambda: Valor del parámetro de suavizado.\nnharm: Número de armónicos o funciones propias reportados en los resultados de Componentes Principales Funcionales.\nname: Se puede asignar un nuevo nombre a los datos.\nadd: Se pueden agregar otras variables para la predicción funcional multivariada espacial (cokriging funcional). No es necesario que todas las variables estén observadas en las mismas ubicaciones espaciales.\n…: Argumentos adicionales de fda como create.bspline.basis o create.fourier.basis.",
    "crumbs": [
      "Objetos",
      "SpatFD"
    ]
  },
  {
    "objectID": "spatfd_object.html#detalles",
    "href": "spatfd_object.html#detalles",
    "title": "Objetos SpatFD",
    "section": "Detalles",
    "text": "Detalles\nLos objetos SpatFD almacenan los datos funcionales, sus parámetros, los resultados de análisis de componentes principales funcionales, y las coordenadas espaciales para cada variable. Cada variable tiene su propio conjunto de datos funcionales, data-frame o matriz, y archivo de coordenadas espaciales.",
    "crumbs": [
      "Objetos",
      "SpatFD"
    ]
  },
  {
    "objectID": "spatfd_object.html#valor",
    "href": "spatfd_object.html#valor",
    "title": "Objetos SpatFD",
    "section": "Valor",
    "text": "Valor\nPara cada variable: Se proporcionan los datos funcionales y los componentes principales funcionales vinculados con las coordenadas espaciales.",
    "crumbs": [
      "Objetos",
      "SpatFD"
    ]
  },
  {
    "objectID": "spatfd_object.html#notas",
    "href": "spatfd_object.html#notas",
    "title": "Objetos SpatFD",
    "section": "Notas",
    "text": "Notas\n\nAunque no hay un límite para el número de variables en el cokriging funcional, la verdadera limitación está en los requisitos para encontrar un modelo de covarianza multivariada válido. Se recomienda aplicar el principio de parsimonia.\nLas ubicaciones deben estar en la misma región de interés para que tenga sentido incluirlas en el mismo modelo de predicción. Sin embargo, cada variable puede estar observada en diferentes ubicaciones espaciales y tener un número diferente de observaciones.\n\n\nForma de uso\n\n# Cargar datos\ndata(AirQualityBogota)\n\n# Crear un objeto univariado usando 2 nharm\nSFD_PM10 &lt;- SpatFD(PM10, coords = coord[,2:3], basis = \"Bsplines\", nbasis = 91,\nlambda = 0.00002, nharm = 2)\n\n\nstr(SFD_PM10)\n\nList of 1\n $ PM10:List of 7\n  ..$ data         :'data.frame':   8761 obs. of  10 variables:\n  .. ..$ Bosque       : int [1:8761] 29 32 32 24 29 31 24 26 25 36 ...\n  .. ..$ IDRD         : int [1:8761] 53 48 25 36 17 7 9 12 12 13 ...\n  .. ..$ Carvajal_Sony: int [1:8761] 72 69 61 30 42 44 30 39 53 49 ...\n  .. ..$ Guaymaral    : int [1:8761] 74 55 58 51 41 39 46 60 54 41 ...\n  .. ..$ Suba_Corpas  : int [1:8761] 53 52 45 45 38 40 44 67 51 41 ...\n  .. ..$ Fontibon     : int [1:8761] 65 49 35 40 26 23 21 29 32 30 ...\n  .. ..$ PteAranda    : int [1:8761] 91 70 45 43 33 11 15 28 24 31 ...\n  .. ..$ MAVDT        : int [1:8761] 31 32 32 29 21 21 25 29 26 32 ...\n  .. ..$ Kennedy      : int [1:8761] 135 94 68 53 47 45 49 59 62 71 ...\n  .. ..$ Tunal        : int [1:8761] 38 29 18 17 24 24 19 15 20 35 ...\n  ..$ coords       :'data.frame':   10 obs. of  2 variables:\n  .. ..$ X: num [1:10] 105076 99661 92104 103675 98239 ...\n  .. ..$ Y: num [1:10] 112526 106572 99968 120780 118365 ...\n  ..$ coordsnames  : chr [1:10] \"Bosque\" \"IDRD\" \"Carvajal_Sony\" \"Guaymaral\" ...\n  ..$ data_fd      :List of 3\n  .. ..$ coefs  : num [1:91, 1:10] 22.6 37.3 13.3 40.6 26.2 ...\n  .. .. ..- attr(*, \"dimnames\")=List of 2\n  .. .. .. ..$ : chr [1:91] \"bspl4.1\" \"bspl4.2\" \"bspl4.3\" \"bspl4.4\" ...\n  .. .. .. ..$ : chr [1:10] \"Bosque\" \"IDRD\" \"Carvajal_Sony\" \"Guaymaral\" ...\n  .. ..$ basis  :List of 10\n  .. .. ..$ call       : language basisfd(type = type, rangeval = rangeval, nbasis = nbasis, params = params,      dropind = dropind, quadvals = qu| __truncated__\n  .. .. ..$ type       : chr \"bspline\"\n  .. .. ..$ rangeval   : num [1:2] 1 8761\n  .. .. ..$ nbasis     : num 91\n  .. .. ..$ params     : num [1:87] 101 200 300 399 499 ...\n  .. .. ..$ dropind    : NULL\n  .. .. ..$ quadvals   : NULL\n  .. .. ..$ values     : list()\n  .. .. ..$ basisvalues: list()\n  .. .. ..$ names      : chr [1:91] \"bspl4.1\" \"bspl4.2\" \"bspl4.3\" \"bspl4.4\" ...\n  .. .. ..- attr(*, \"class\")= chr \"basisfd\"\n  .. ..$ fdnames:List of 3\n  .. .. ..$ time  : chr [1:8761] \"1\" \"2\" \"3\" \"4\" ...\n  .. .. ..$ reps  : chr [1:10] \"Bosque\" \"IDRD\" \"Carvajal_Sony\" \"Guaymaral\" ...\n  .. .. ..$ values: chr \"value\"\n  .. ..- attr(*, \"class\")= chr \"fd\"\n  ..$ fpca         :List of 5\n  .. ..$ harmonics:List of 3\n  .. .. ..$ coefs  : num [1:91, 1:2] 0.006843 0.006646 0.013123 0.000889 0.005331 ...\n  .. .. .. ..- attr(*, \"dimnames\")=List of 2\n  .. .. .. .. ..$ : chr [1:91] \"bspl4.1\" \"bspl4.2\" \"bspl4.3\" \"bspl4.4\" ...\n  .. .. .. .. ..$ : chr [1:2] \"PC1\" \"PC2\"\n  .. .. ..$ basis  :List of 10\n  .. .. .. ..$ call       : language basisfd(type = type, rangeval = rangeval, nbasis = nbasis, params = params,      dropind = dropind, quadvals = qu| __truncated__\n  .. .. .. ..$ type       : chr \"bspline\"\n  .. .. .. ..$ rangeval   : num [1:2] 1 8761\n  .. .. .. ..$ nbasis     : num 91\n  .. .. .. ..$ params     : num [1:87] 101 200 300 399 499 ...\n  .. .. .. ..$ dropind    : NULL\n  .. .. .. ..$ quadvals   : NULL\n  .. .. .. ..$ values     : list()\n  .. .. .. ..$ basisvalues: list()\n  .. .. .. ..$ names      : chr [1:91] \"bspl4.1\" \"bspl4.2\" \"bspl4.3\" \"bspl4.4\" ...\n  .. .. .. ..- attr(*, \"class\")= chr \"basisfd\"\n  .. .. ..$ fdnames:List of 3\n  .. .. .. ..$ : chr [1:91] \"bspl4.1\" \"bspl4.2\" \"bspl4.3\" \"bspl4.4\" ...\n  .. .. .. ..$ : chr [1:2] \"PC1\" \"PC2\"\n  .. .. .. ..$ : chr \"values\"\n  .. .. ..- attr(*, \"class\")= chr \"fd\"\n  .. ..$ values   : num [1:91] 2634394 107330 53673 42406 38477 ...\n  .. ..$ scores   : num [1:10, 1:2] -1448 -1888 3430 112 515 ...\n  .. ..$ varprop  : num [1:2] 0.9006 0.0367\n  .. ..$ meanfd   :List of 3\n  .. .. ..$ coefs  : num [1:91, 1] 28.1 47 43.8 40.4 34.9 ...\n  .. .. .. ..- attr(*, \"dimnames\")=List of 2\n  .. .. .. .. ..$ : NULL\n  .. .. .. .. ..$ : chr \"mean\"\n  .. .. ..$ basis  :List of 10\n  .. .. .. ..$ call       : language basisfd(type = type, rangeval = rangeval, nbasis = nbasis, params = params,      dropind = dropind, quadvals = qu| __truncated__\n  .. .. .. ..$ type       : chr \"bspline\"\n  .. .. .. ..$ rangeval   : num [1:2] 1 8761\n  .. .. .. ..$ nbasis     : num 91\n  .. .. .. ..$ params     : num [1:87] 101 200 300 399 499 ...\n  .. .. .. ..$ dropind    : NULL\n  .. .. .. ..$ quadvals   : NULL\n  .. .. .. ..$ values     : list()\n  .. .. .. ..$ basisvalues: list()\n  .. .. .. ..$ names      : chr [1:91] \"bspl4.1\" \"bspl4.2\" \"bspl4.3\" \"bspl4.4\" ...\n  .. .. .. ..- attr(*, \"class\")= chr \"basisfd\"\n  .. .. ..$ fdnames:List of 3\n  .. .. .. ..$ time  : chr [1:8761] \"1\" \"2\" \"3\" \"4\" ...\n  .. .. .. ..$ reps  : chr \"mean\"\n  .. .. .. ..$ values: chr \"mean value\"\n  .. .. ..- attr(*, \"class\")= chr \"fd\"\n  .. ..- attr(*, \"class\")= chr \"pca.fd\"\n  ..$ variable_name: chr \"PM10\"\n  ..$ call_args    :List of 9\n  .. ..$ data   :'data.frame':  8761 obs. of  10 variables:\n  .. .. ..$ Bosque       : int [1:8761] 29 32 32 24 29 31 24 26 25 36 ...\n  .. .. ..$ IDRD         : int [1:8761] 53 48 25 36 17 7 9 12 12 13 ...\n  .. .. ..$ Carvajal_Sony: int [1:8761] 72 69 61 30 42 44 30 39 53 49 ...\n  .. .. ..$ Guaymaral    : int [1:8761] 74 55 58 51 41 39 46 60 54 41 ...\n  .. .. ..$ Suba_Corpas  : int [1:8761] 53 52 45 45 38 40 44 67 51 41 ...\n  .. .. ..$ Fontibon     : int [1:8761] 65 49 35 40 26 23 21 29 32 30 ...\n  .. .. ..$ PteAranda    : int [1:8761] 91 70 45 43 33 11 15 28 24 31 ...\n  .. .. ..$ MAVDT        : int [1:8761] 31 32 32 29 21 21 25 29 26 32 ...\n  .. .. ..$ Kennedy      : int [1:8761] 135 94 68 53 47 45 49 59 62 71 ...\n  .. .. ..$ Tunal        : int [1:8761] 38 29 18 17 24 24 19 15 20 35 ...\n  .. ..$ coords :'data.frame':  10 obs. of  2 variables:\n  .. .. ..$ X: num [1:10] 105076 99661 92104 103675 98239 ...\n  .. .. ..$ Y: num [1:10] 112526 106572 99968 120780 118365 ...\n  .. ..$ basis  : chr \"Bsplines\"\n  .. ..$ nbasis : num 91\n  .. ..$ lambda : num 2e-05\n  .. ..$ nharm  : num 2\n  .. ..$ name   : NULL\n  .. ..$ add    : NULL\n  .. ..$ basisfd:List of 10\n  .. .. ..$ call       : language basisfd(type = type, rangeval = rangeval, nbasis = nbasis, params = params,      dropind = dropind, quadvals = qu| __truncated__\n  .. .. ..$ type       : chr \"bspline\"\n  .. .. ..$ rangeval   : num [1:2] 1 8761\n  .. .. ..$ nbasis     : num 91\n  .. .. ..$ params     : num [1:87] 101 200 300 399 499 ...\n  .. .. ..$ dropind    : NULL\n  .. .. ..$ quadvals   : NULL\n  .. .. ..$ values     : list()\n  .. .. ..$ basisvalues: list()\n  .. .. ..$ names      : chr [1:91] \"bspl4.1\" \"bspl4.2\" \"bspl4.3\" \"bspl4.4\" ...\n  .. .. ..- attr(*, \"class\")= chr \"basisfd\"\n - attr(*, \"class\")= chr \"SpatFD\"\n\n\nPara cada variable incluida en el objeto SpatFD, la función summary retorna:\n\nHead of data: Primeras filas de los datos asociados.\nCoordinates: Coordenadas espaciales correspondientes a cada ubicación.\nEigenvalues: Valores propios de la descomposición en componentes principales.\nMean coefficients: Coeficientes medios de la representación funcional.\nProportion of explained variance by each component: Proporción de varianza explicada por cada componente principal.\n\n\nsummary(SFD_PM10)\n\n#  PM10 \n## Data \n     Bosque IDRD Carvajal_Sony Guaymaral Suba_Corpas Fontibon PteAranda MAVDT\n1        29   53            72        74          53       65        91    31\n2        32   48            69        55          52       49        70    32\n3        32   25            61        58          45       35        45    32\n4        24   36            30        51          45       40        43    29\n5       ...  ...           ...       ...         ...      ...       ...   ...\n8758     50   88            99        27          41       66        56    61\n8759     40   73            99        27          43       36        71    43\n8760     52   37            84        92          57       39        58    44\n8761     46   45            87        65          60       49        38    40\n     Kennedy Tunal\n1        135    38\n2         94    29\n3         68    18\n4         53    17\n5        ...   ...\n8758      64    39\n8759      76    32\n8760      75    48\n8761      79    17\n\n ## Coordinates \n           X          Y\n1 105075.655 112526.216\n2 99661.2289 106572.463\n3 92103.6962 99967.8739\n4 103675.229 120779.813\n5        ...        ...\n\n ## Eigenvalues \n                ev\n1 2634394.04728212\n2 107329.989552922\n3 53673.3376594282\n4 42406.3364006517\n5              ...\n\n ## Mean coefficients \n               mean\n1  28.1142060830838\n2  46.9632482975211\n3  43.8359915678551\n4  40.4199430064293\n5               ...\n88 68.0581607089687\n89 65.8120473593034\n90 20.2318977856245\n91 74.2871948785061\n\n ## Proportion of explained variance by component \n     varprop\n1 0.90063221\n2 0.03669339",
    "crumbs": [
      "Objetos",
      "SpatFD"
    ]
  }
]