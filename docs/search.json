[
  {
    "objectID": "vowels.html",
    "href": "vowels.html",
    "title": "Vowels",
    "section": "",
    "text": "El conjunto de datos vowels contiene señales de electroencefalograma (EEG) tomadas de 21 electrodos, durante la actividad mental de imaginar las cinco vocales del idioma español. Este conjunto de datos se desarrolló para ser aplicado en una interfaz cerebro-computadora (BCI, por sus siglas en inglés) destinada al control de una prótesis de mano.\n\n\nUna BCI permite a las personas controlar dispositivos externos, como prótesis, usando únicamente señales cerebrales. En este caso, el conjunto de datos recoge la actividad cerebral relacionada con el pensamiento imaginario de las vocales, lo que se espera que ayude a entrenar modelos para la clasificación y control de una prótesis.\n\n\n\nBrain BCI, Adindva1, CC BY-SA 4.0"
  },
  {
    "objectID": "vowels.html#descripción",
    "href": "vowels.html#descripción",
    "title": "Vowels",
    "section": "",
    "text": "El conjunto de datos vowels contiene señales de electroencefalograma (EEG) tomadas de 21 electrodos, durante la actividad mental de imaginar las cinco vocales del idioma español. Este conjunto de datos se desarrolló para ser aplicado en una interfaz cerebro-computadora (BCI, por sus siglas en inglés) destinada al control de una prótesis de mano.\n\n\nUna BCI permite a las personas controlar dispositivos externos, como prótesis, usando únicamente señales cerebrales. En este caso, el conjunto de datos recoge la actividad cerebral relacionada con el pensamiento imaginario de las vocales, lo que se espera que ayude a entrenar modelos para la clasificación y control de una prótesis.\n\n\n\nBrain BCI, Adindva1, CC BY-SA 4.0"
  },
  {
    "objectID": "vowels.html#uso",
    "href": "vowels.html#uso",
    "title": "Vowels",
    "section": "Uso",
    "text": "Uso\nPara cargar los datos en R, usa el siguiente comando:\n\ndata(vowels)\n\nWarning in data(vowels): data set 'vowels' not found"
  },
  {
    "objectID": "regresion_espacial.html",
    "href": "regresion_espacial.html",
    "title": "Modelos de regresión espacial",
    "section": "",
    "text": "En este apartado se comparan varios tipos de modelos de regresión espacial para ver con cuál se obtiene el mejor ajuste. Se consideran modelos autoregresivos y de medias móviles así como su combinación."
  },
  {
    "objectID": "regresion_espacial.html#estudio-de-mercadeo",
    "href": "regresion_espacial.html#estudio-de-mercadeo",
    "title": "Modelos de regresión espacial",
    "section": "",
    "text": "En este apartado se comparan varios tipos de modelos de regresión espacial para ver con cuál se obtiene el mejor ajuste. Se consideran modelos autoregresivos y de medias móviles así como su combinación."
  },
  {
    "objectID": "regresion_espacial.html#preparación",
    "href": "regresion_espacial.html#preparación",
    "title": "Modelos de regresión espacial",
    "section": "Preparación",
    "text": "Preparación\n\nPaquetes\n\nlibrary(ggplot2)    # Graphics library\nlibrary(sf)         # Spatial data types and handling\n\nLinking to GEOS 3.12.2, GDAL 3.9.3, PROJ 9.4.1; sf_use_s2() is TRUE\n\nlibrary(mapview)    # Visualize spatial data\nlibrary(spdep)      # Diagnosing spatial dependence\n\nCargando paquete requerido: spData\n\n\nTo access larger datasets in this package, install the spDataLarge\npackage with: `install.packages('spDataLarge',\nrepos='https://nowosad.github.io/drat/', type='source')`\n\nlibrary(spatialreg) # Spatial lag and spatial error model\n\nCargando paquete requerido: Matrix\n\n\n\nAdjuntando el paquete: 'spatialreg'\n\n\nThe following objects are masked from 'package:spdep':\n\n    get.ClusterOption, get.coresOption, get.mcOption,\n    get.VerboseOption, get.ZeroPolicyOption, set.ClusterOption,\n    set.coresOption, set.mcOption, set.VerboseOption,\n    set.ZeroPolicyOption\n\nlibrary(readxl)\nlibrary(sp)\nlibrary(openxlsx)\nlibrary(dplyr)\n\n\nAdjuntando el paquete: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(GISTools)\nlibrary(spdep)\nlibrary(car)\n\nCargando paquete requerido: carData\n\n\n\nAdjuntando el paquete: 'car'\n\n\nThe following object is masked from 'package:dplyr':\n\n    recode\n\nlibrary(psych)\n\n\nAdjuntando el paquete: 'psych'\n\n\nThe following object is masked from 'package:car':\n\n    logit\n\n\nThe following objects are masked from 'package:ggplot2':\n\n    %+%, alpha\n\nlibrary(FactoClass)\n\nCargando paquete requerido: ade4\n\n\n\nAdjuntando el paquete: 'ade4'\n\n\nThe following object is masked from 'package:spdep':\n\n    mstree\n\n\nCargando paquete requerido: ggrepel\n\n\nCargando paquete requerido: xtable\n\n\nCargando paquete requerido: scatterplot3d\n\nrequire(\"GWmodel\")\n\nCargando paquete requerido: GWmodel\n\n\nCargando paquete requerido: robustbase\n\n\nCargando paquete requerido: Rcpp\n\n\nWelcome to GWmodel version 2.4-2.\n\nlibrary(viridis)\n\nCargando paquete requerido: viridisLite\n\nlibrary(\"mapsRinteractive\")\nlibrary(ggspatial)\n\nEn este paso, se cargan los datos principales desde un archivo Excel (BASE.xlsx) y se leen las fronteras geográficas de Colombia por departamentos usando un archivo shapefile. Los datos espaciales en formato shapefile son cargados con la función st_read de la librería sf.\n\n# Lectura de Datos\nBASE &lt;- read_excel(\"data/BASE.xlsx\")\n# Lectura del Shape de Colombia por Departamentos\nColombia = st_read(dsn = \"data/Geodatabase Colombia\", \n                   layer = \"departamentos\")\n\nReading layer `departamentos' from data source \n  `D:\\SpatFD-Functional-Geostatistics\\data\\Geodatabase Colombia' \n  using driver `ESRI Shapefile'\nSimple feature collection with 33 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 166883.7 ymin: 23827.08 xmax: 1804084 ymax: 1984107\nCRS:           NA\n\n\n\n\nCruce de información y arreglo de coordenadas\nRealizamos un cruce de los datos de los departamentos de Colombia con los datos de mercado. Además, se transforma el sistema de coordenadas geográficas de los datos al sistema UTM (Universal Transverse Mercator) para mejorar la precisión en los cálculos espaciales. Esto es especialmente relevante en análisis de distancias y vecindades.\n\nInsumo = merge(Colombia, BASE, by.x=\"COD_DANE\", by.y=\"Cod\")\nInsumo = subset(Insumo[c(1:31,33),])\n# Conversión a Coordenadas UTM\nCrs.geo &lt;- \"+proj=tmerc +lat_0=4.599047222222222 +lon_0=-74.08091666666667 +k=1 +x_0=1000000 +y_0=1000000 +ellps=intl +towgs84=307,304,-318,0,0,0,0 +units=m +no_defs\"\nst_crs(Insumo) &lt;- Crs.geo\nInsumo.utm &lt;- st_transform(Insumo, crs = 3724)"
  },
  {
    "objectID": "regresion_espacial.html#mapa-de-valores-observados",
    "href": "regresion_espacial.html#mapa-de-valores-observados",
    "title": "Modelos de regresión espacial",
    "section": "Mapa de valores observados",
    "text": "Mapa de valores observados\n\n#  Mapa de Valores Observados\n#dev.new() #windows()\nggplot(Insumo) +\n  geom_sf(aes(fill = CAP_BAC)) +\n  \n  scale_fill_viridis_c(option='viridis') +  # Escala de colores para la variable\n  labs(fill = \"Valores Locales\") +\n  theme_minimal() +\n  ggtitle(\"Valores Observados para las captaciones del banco agrario\\nen Colombia, cuarto trimestre 2020\") +\n  \n  # Añadir la leyenda personalizada\n  theme(legend.position = \"right\") +\n  \n  # Añadir escala\n  annotation_scale(location = \"bl\", width_hint = 0.15) +\n  annotation_north_arrow(location = \"tr\", which_north = \"true\", height = unit(1, \"cm\"), width = unit(1, \"cm\"))"
  },
  {
    "objectID": "regresion_espacial.html#matriz-de-vecindades",
    "href": "regresion_espacial.html#matriz-de-vecindades",
    "title": "Modelos de regresión espacial",
    "section": "Matriz de vecindades",
    "text": "Matriz de vecindades\nEn el análisis espacial, las matrices de vecindad son estructuras que definen las relaciones espaciales entre las unidades de observación. En este caso, cada departamento de Colombia tiene una “vecindad” que se define por su proximidad a otros departamentos.\nCentroides de las Áreas: Primero, calculamos los centroides de cada uno de los polígonos (departamentos) usando st_centroid(). Los centroides son los puntos centrales de los polígonos, lo que nos permite calcular distancias entre ellos.\nMatriz de Distancias: Usamos st_distance() para calcular la matriz de distancias entre los centroides de los departamentos. Esto nos da una medida de la cercanía geográfica entre las unidades.\nMatriz de Vecindades (Insumo.nb): Se utiliza la función poly2nb() del paquete spdep para crear una lista de vecinos basada en la geometría de los departamentos. El parámetro queen = TRUE asegura que un departamento se considere vecino de otro si comparten una frontera común o un vértice.\n\n## Centroides de las Áreas\nCentroids &lt;- st_centroid(Insumo.utm)\n\nWarning: st_centroid assumes attributes are constant over geometries\n\n# Matriz de Distancias entre los Centroides\nWdist &lt;- st_distance(Centroids)\n\n# Matriz W de vecindades\nInsumo.nb &lt;- poly2nb(Insumo.utm, queen = TRUE)\n\nWarning in poly2nb(Insumo.utm, queen = TRUE): some observations have no neighbours;\nif this seems unexpected, try increasing the snap argument.\n\n\nWarning in poly2nb(Insumo.utm, queen = TRUE): neighbour object has 2 sub-graphs;\nif this sub-graph count seems unexpected, try increasing the snap argument.\n\n\n\nTipos de Matrices de Vecindad\nLas matrices de vecindad pueden definirse de diferentes maneras. Aquí se muestran algunas opciones comunes:\nMatriz binaria de vecindad: Una matriz donde los valores son 1 si los departamentos son vecinos (según la geometría), y 0 si no lo son. Esto es útil para análisis como los modelos de regresión espacial, donde la vecindad puede influir en la variable dependiente.\n\nDepartamentos &lt;- Insumo$Departamento\n\nn &lt;- length(Insumo.nb)\nMatW &lt;- matrix(0, n, n, dimnames = list(Departamentos, Departamentos))\n\nfor (i in 1:n) {\n  vecinos &lt;- Insumo.nb[[i]]\n  MatW[i, vecinos] &lt;- 1\n}\n\n\nMatrices de vecindad ponderadas: Existen varios tipos de ponderación para las matrices de vecindad, que reflejan diferentes grados de proximidad entre los departamentos. Estas ponderaciones pueden basarse en distancias o en relaciones de contigüidad. Los estilos más comunes son:\n\nEstilo “B” (Binary): Simplemente indica si dos departamentos son vecinos o no (como la matriz binaria).\nEstilo “C” (Contiguity): Se utiliza cuando los vecinos comparten una frontera común.\nEstilo “W” (Weights): Utiliza una matriz de pesos basada en distancias, donde los vecinos más cercanos tienen mayor peso.\nEstilo “U”(Unweighted): En este estilo, los vecinos se definen de forma binaria (con un valor de 1 si hay vecindad y 0 si no la hay), pero a diferencia de otros estilos, no se toma en cuenta el tipo de vecindad exacta (como si comparten frontera o vértice).\n\n\n\n#---\n# MATRIZ DE VECINDADES (W)\n#---\n\n# Opcional: convierte la lista de vecinos en una matriz binaria de vecindades si se necesita\nDepartamentos &lt;- Insumo$Departamento\nn &lt;- length(Insumo.nb)\nMatW &lt;- matrix(0, n, n, dimnames = list(Departamentos, Departamentos))\n\nfor (i in 1:n) {\n  vecinos &lt;- Insumo.nb[[i]]\n  MatW[i, vecinos] &lt;- 1\n}\n\n# Alternativamente, usa diferentes estilos de ponderación\nInsumo.lw &lt;- nb2listw(Insumo.nb, zero.policy = TRUE )\nInsumo.lwb &lt;- nb2listw(Insumo.nb, style = \"B\",zero.policy = TRUE)\nInsumo.lwc &lt;- nb2listw(Insumo.nb, style = \"C\",zero.policy = TRUE)\nInsumo.lwu &lt;- nb2listw(Insumo.nb, style = \"U\",zero.policy = TRUE)\nInsumo.lww &lt;- nb2listw(Insumo.nb, style = \"W\",zero.policy = TRUE)"
  },
  {
    "objectID": "regresion_espacial.html#pruebas-de-autocorrelación",
    "href": "regresion_espacial.html#pruebas-de-autocorrelación",
    "title": "Modelos de regresión espacial",
    "section": "Pruebas de Autocorrelación",
    "text": "Pruebas de Autocorrelación\n\nÍndice de Moran\nEl índice de Moran es una medida global utilizada para cuantificar la autocorrelación espacial en un conjunto de datos geoespaciales. Este índice evalúa si los valores de una variable en una región tienden a estar agrupados en áreas vecinas o, por el contrario, dispersos. Se calcula comparando el valor de la variable en cada unidad espacial con los valores en sus vecinas, ponderados por la distancia o vecindad. El índice varía entre -1 y 1: un valor cercano a 1 indica que los valores de la variable están positivamente autocorrelacionados, es decir, las unidades cercanas tienen valores similares; un valor cercano a -1 sugiere autocorrelación negativa, donde las unidades cercanas tienen valores opuestos; y un valor cercano a 0 implica ausencia de autocorrelación espacial, lo que significa que los valores están distribuidos aleatoriamente.\n\nmoran.test(Insumo$CAP_BAC, Insumo.lw)\n\n\n    Moran I test under randomisation\n\ndata:  Insumo$CAP_BAC  \nweights: Insumo.lw  \nn reduced by no-neighbour observations  \n\nMoran I statistic standard deviate = 1.8248, p-value = 0.03401\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.140449554      -0.033333333       0.009069006 \n\n\nEl resultado del test de Moran que se presenta indica lo siguiente:\nMoran I statistic: En este caso, el valor de 0.1404 sugiere una autocorrelación espacial positiva débil, lo que implica que los valores cercanos de la variable CAP_BAC podrían presentar una ligera tendencia a estar agrupados.\nExpectation (Esperanza): La esperanza teórica del índice de Moran bajo la hipótesis nula es -0.0333. Este valor refleja la media esperada del índice de Moran si no existiera autocorrelación espacial (es decir, si los valores de la variable se distribuyeran aleatoriamente).\nVariance (Varianza): La varianza de la estadística de Moran es 0.0091. La varianza describe la dispersión de los valores observados del índice de Moran respecto a su valor esperado bajo la hipótesis nula.\nMoran I statistic standard deviate: La desviación estándar de la estadística de Moran es 1.8248. p-value: El valor p es 0.03401. Esto indica que la probabilidad de observar una estadística de Moran igual o más extrema que la observada bajo la hipótesis nula (sin autocorrelación espacial) es de aproximadamente 3.4%. Dado que este valor p es menor que el umbral común de 0.05, podemos rechazar la hipótesis nula de que no hay autocorrelación espacial significativa y concluir que hay evidencia estadística de autocorrelación espacial positiva en los datos de la variable CAP_BAC.\n\nmoran.plot(Insumo$CAP_BAC, \n           Insumo.lw, \n           labels=as.character(Insumo$Departamento), \n           xlab=\"Captaciones BAC\", \n           ylab=\"Captaciones BAC rezagado\", \n           las=1, \n           pch=16, \n           cex=0.5)\n\nlegend(\"bottomright\", \n       legend=c(\"I de Moran: 0.1530\", \"Valor P:      0.02262\"), \n       cex=1,\n       bg='lightgreen')\n\ntitle(\"Dispersograma de Moran para las captaciones del banco agrario en \nlos Departamentos de Colombia, cuarto trimestre 2020\", cex.main=1)\n\n\n\n\n\n\n\n\n\n\nLocal G\nEl Local G es un índice de autocorrelación espacial que complementa el índice de Moran al permitir la identificación de patrones locales de agrupamiento o dispersión en los datos. Mientras que el índice de Moran proporciona una medida global de la autocorrelación espacial, el Local G permite detectar si ciertas áreas específicas presentan una concentración significativa de valores similares (o diferentes). Este índice se calcula para cada unidad espacial, tomando en cuenta los valores en sus vecinas más cercanas. Los valores de Local G más altos indican áreas de alta concentración de valores similares, mientras que los valores negativos o bajos indican zonas de baja concentración o patrones de dispersión. Es útil para identificar clústeres locales de alta o baja intensidad, lo que permite un análisis más detallado de las estructuras espaciales en los datos.\n\nnearng = dnearneigh(st_coordinates(Insumo.utm)[, 1:2], 0, 550)\nInsumo.lw.g = nb2listw(nearng, style=\"B\", zero.policy = T)\n\n\ndnearneigh: Esta función calcula las vecindades entre los elementos espaciales según una distancia determinada. En este caso, se utiliza st_coordinates(Insumo.utm)[, 1:2] para obtener las coordenadas de los departamentos en el sistema de referencia espacial UTM, y se establecen dos parámetros: 0 (distancia mínima) y 550 (distancia máxima) para definir qué unidades espaciales están cerca entre sí.\nnb2listw: Convierte la vecindad obtenida (nearng) en una lista de pesos espaciales, donde style=“B” indica que la matriz de vecindad será binaria (vecinos cercanos reciben un valor de 1, y los demás reciben 0). Además, zero.policy = T indica que se manejan correctamente los casos en los que algunas unidades no tienen vecinos (se asigna un valor de 0).\nlocalG: Esta función calcula el índice Local G para la variable CAP_BAC, utilizando la matriz de vecindad definida anteriormente. El resultado muestra el valor de Local G para cada unidad espacial (departamento), lo que permite identificar los clústeres locales de valores similares en CAP_BAC.\n\n\n# Local G\nlocalG = localG(Insumo$CAP_BAC, Insumo.lw); localG\n\n [1]  0.155681557 -0.712138366  1.156581529  0.223053281  1.225680585\n [6]  1.780856038 -0.731942275 -0.060298220 -0.295608194  0.657477592\n[11]  2.277561982  0.871102293  2.294286018 -0.656017332 -0.999281109\n[16]  1.681892858  0.023724727  1.074391458 -0.147838109  0.353880133\n[21]  1.377877204 -0.579569282  0.003748916 -0.484612682  0.115533100\n[26]  0.331016021 -0.382174908          NaN -0.691581293 -1.040470926\n[31] -1.026671692 -1.054907095\nattr(,\"internals\")\n               Gi      E(Gi)        V(Gi)        Z(Gi) Pr(z != E(Gi))\n [1,] 0.034341489 0.03225806 0.0001790941  0.155681557     0.87628404\n [2,] 0.013326210 0.03225806 0.0007067366 -0.712138366     0.47637910\n [3,] 0.051335768 0.03225806 0.0002720819  1.156581529     0.24744337\n [4,] 0.035157388 0.03225806 0.0001689570  0.223053281     0.82349404\n [5,] 0.047456292 0.03225806 0.0001537557  1.225680585     0.22031890\n [6,] 0.060877660 0.03225806 0.0002582673  1.780856038     0.07493597\n [7,] 0.021853899 0.03225806 0.0002020509 -0.731942275     0.46420380\n [8,] 0.031367743 0.03225806 0.0002180140 -0.060298220     0.95191812\n [9,] 0.027504594 0.03225806 0.0002585763 -0.295608194     0.76752932\n[10,] 0.046354798 0.03225806 0.0004597006  0.657477592     0.51087387\n[11,] 0.063046196 0.03225806 0.0001827369  2.277561982     0.02275269\n[12,] 0.050790538 0.03225806 0.0004526145  0.871102293     0.38369830\n[13,] 0.065765757 0.03225806 0.0002133015  2.294286018     0.02177408\n[14,] 0.014971771 0.03225806 0.0006943415 -0.656017332     0.51181297\n[15,] 0.014214548 0.03225806 0.0003260371 -0.999281109     0.31765853\n[16,] 0.052551797 0.03225806 0.0001455885  1.681892858     0.09258962\n[17,] 0.032909872 0.03225806 0.0007548078  0.023724727     0.98107218\n[18,] 0.055869899 0.03225806 0.0004829858  1.074391458     0.28264727\n[19,] 0.029120083 0.03225806 0.0004505345 -0.147838109     0.88247053\n[20,] 0.037283549 0.03225806 0.0002016710  0.353880133     0.72342872\n[21,] 0.055190592 0.03225806 0.0002770019  1.377877204     0.16824120\n[22,] 0.016800765 0.03225806 0.0007113061 -0.579569282     0.56220511\n[23,] 0.032308100 0.03225806 0.0001781310  0.003748916     0.99700880\n[24,] 0.024333024 0.03225806 0.0002674320 -0.484612682     0.62795112\n[25,] 0.034715170 0.03225806 0.0004523084  0.115533100     0.90802259\n[26,] 0.037589783 0.03225806 0.0002594396  0.331016021     0.74063238\n[27,] 0.025280301 0.03225806 0.0003333559 -0.382174908     0.70233163\n[28,] 0.000000000 0.00000000 0.0000000000          NaN            NaN\n[29,] 0.014222756 0.03225806 0.0006800810 -0.691581293     0.48920031\n[30,] 0.004592077 0.03225806 0.0007070212 -1.040470926     0.29812117\n[31,] 0.013839331 0.03225806 0.0003218521 -1.026671692     0.30457508\n[32,] 0.015701595 0.03225806 0.0002463242 -1.054907095     0.29146782\nattr(,\"cluster\")\n [1] High Low  High Low  High Low  Low  High Low  Low  High Low  High Low  Low \n[16] Low  High High Low  Low  High Low  High High Low  Low  Low  Low  Low  Low \n[31] Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = Insumo$CAP_BAC, listw = Insumo.lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\nSimulación Monte Carlo: Para evaluar la significancia de los resultados obtenidos con el índice Local G, se realizan 1000 simulaciones donde se barajan aleatoriamente los valores de CAP_BAC y se vuelve a calcular el índice Local G para cada permutación. Esto permite comparar los valores observados de Local G con una distribución aleatoria. sweep(sim.G, 2, localG, “&gt;=”): Compara los valores de localGobservados con los valores simulados. Elsweepcompara cada valor desim.Gcon el valor correspondiente delocalG` para cada unidad espacial. Si el valor simulado es mayor o igual que el valor observado, se cuenta como un 1, lo que indica que el valor simulado es al menos tan grande como el observado. colSums(…)+1: Suma cuántos de los valores simulados son mayores o iguales a los valores observados de Local G, añadiendo 1 para evitar valores p de 0. (nrow(sim.G)+1): Se normaliza por el número total de simulaciones (1000), de manera que se obtiene un valor p para cada unidad espacial, indicando la probabilidad de obtener un valor de Local G tan extremo como el observado bajo la distribución aleatoria.\n\n# Simulaci?n montecarlo\nsim.G = matrix(0,1000,32)\nfor(i in 1:1000) sim.G[i,] = localG(sample(Insumo$CAP_BAC),Insumo.lw)\nmc.pvalor.G = (colSums(sweep(sim.G,2,localG,\"&gt;=\"))+1)/(nrow(sim.G)+1)\nmc.pvalor.G\n\n [1] 0.34165834 0.75824176 0.11788212 0.37062937 0.13886114 0.07392607\n [7] 0.73726274 0.48051948 0.52747253 0.19380619 0.02097902 0.15784216\n[13] 0.02197802 0.72827173 0.88211788 0.06793207 0.35364635 0.14585415\n[19] 0.45054945 0.30469530 0.12187812 0.65734266 0.41558442 0.59640360\n[25] 0.31368631 0.28771229 0.59840160         NA 0.76023976 0.98901099\n[31] 0.90609391 0.88811189\n\n\nLos valores p calculados (mc.pvalor.G) indican la significancia estadística de los patrones espaciales observados. Un valor p bajo (generalmente menor que 0.05) sugiere que la autocorrelación espacial observada en un departamento es significativamente diferente de la aleatoriedad, lo que indica un clúster local de alta o baja concentración de valores. Los departamentos con valores p bajos pueden considerarse como áreas con patrones espaciales significativos, lo cual es útil para identificar zonas con características especiales en la variable de interés. #### Mapas\n\nlibrary(ggplot2)\nlocalG= as.numeric(localG)\n# Mapa de G\nggplot(Insumo.utm) + \n  geom_sf(aes(fill = localG)) +\n  scale_fill_viridis_c() +\n  ggtitle(\"G Getis Ord Local para las captaciones del banco agrario en Colombia, cuarto trimestre 2020\") +\n  theme_minimal()\n\n\n\n\n\n\n\n# Mapa de p-valor\nggplot(Insumo.utm) + \n  geom_sf(aes(fill = mc.pvalor.G)) +\n  scale_fill_viridis_c() +\n  ggtitle(\"P-Valor de G Getis Ord Local para las captaciones del banco agrario en Colombia, cuarto trimestre 2020\") +\n  theme_minimal()"
  },
  {
    "objectID": "regresion_espacial.html#regresión-espacial",
    "href": "regresion_espacial.html#regresión-espacial",
    "title": "Modelos de regresión espacial",
    "section": "Regresión Espacial",
    "text": "Regresión Espacial\nLos modelos de regresión espacial son fundamentales para capturar la dependencia espacial entre observaciones, un fenómeno común en datos geoespaciales. ### OLS \\[y=\\mathbf{X}\\beta+\\varepsilon\\] El modelo OLS es la regresión lineal clásica, donde \\(y\\) es la variable dependiente, \\(\\mathbf{X}\\) es la matriz de covariables, \\(\\beta\\) son los coeficientes a estimar y \\(\\varepsilon\\) es el término de error. Este modelo no captura ninguna dependencia espacial en los errores, lo que puede ser una limitación cuando hay correlación espacial entre las observaciones.\n\nreg.eq1=CAP_BAC ~ PIB + NBI + CAP_BOG+CAP_BC + CAP_OCC + CAP_CS+ Población\nreg1=lm(reg.eq1,data=Insumo)                                     #OLS            y=XB+e,    \nsummary(reg1)\n\n\nCall:\nlm(formula = reg.eq1, data = Insumo)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-285.63  -79.51  -10.25   45.42  402.00 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)  1.313e+02  7.573e+01   1.734   0.0958 .\nPIB          3.930e-03  3.321e-03   1.183   0.2482  \nNBI         -1.278e+00  1.878e+00  -0.680   0.5028  \nCAP_BOG     -6.148e-02  5.542e-02  -1.109   0.2783  \nCAP_BC       2.751e-03  5.994e-03   0.459   0.6504  \nCAP_OCC     -4.705e-02  2.152e-02  -2.186   0.0388 *\nCAP_CS       4.444e-01  3.203e-01   1.388   0.1780  \nPoblación    1.521e-05  6.709e-05   0.227   0.8226  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 142.7 on 24 degrees of freedom\nMultiple R-squared:  0.8798,    Adjusted R-squared:  0.8447 \nF-statistic: 25.09 on 7 and 24 DF,  p-value: 1.43e-09\n\n\n\nSLX (Spatial Lag of X)\n\\[y=\\mathbf{X\\beta}+\\mathbf{WX\\theta}+\\varepsilon\\] El modelo SLX (Spatial Lag of X) extiende el OLS al incluir el “lag” espacial de las variables explicativas \\((\\mathbf{WX\\theta})\\), donde \\(\\mathbf{W}\\) es la matriz de vecindad y \\(\\mathbf{\\theta}\\) es el vector de coeficientes correspondientes a las variables explicativas laggeadas. Este modelo captura la influencia de los valores de las covariables de los vecinos en la variable dependiente.\n\nreg2=lmSLX(reg.eq1,data=Insumo, Insumo.lw,, zero.policy = TRUE)                       #SLX            y=XB+WxT+e\nsummary(reg2)\n\n\nCall:\nlm(formula = formula(paste(\"y ~ \", paste(colnames(x)[-1], collapse = \"+\"))), \n    data = as.data.frame(x), weights = weights)\n\nCoefficients:\n               Estimate    Std. Error  t value     Pr(&gt;|t|)  \n(Intercept)     1.057e+02   1.456e+02   7.260e-01   4.777e-01\nPIB             3.620e-03   4.007e-03   9.033e-01   3.790e-01\nNBI            -9.757e-02   2.781e+00  -3.508e-02   9.724e-01\nCAP_BOG        -8.925e-03   7.998e-02  -1.116e-01   9.125e-01\nCAP_BC         -4.774e-03   9.727e-03  -4.908e-01   6.298e-01\nCAP_OCC        -6.427e-02   3.416e-02  -1.882e+00   7.711e-02\nCAP_CS          1.336e-01   4.529e-01   2.950e-01   7.716e-01\nPoblación       1.052e-04   1.162e-04   9.057e-01   3.777e-01\nlag.PIB         3.786e-03   9.844e-03   3.847e-01   7.053e-01\nlag.NBI        -1.050e+00   4.323e+00  -2.429e-01   8.110e-01\nlag.CAP_BOG    -1.822e-01   1.654e-01  -1.101e+00   2.861e-01\nlag.CAP_BC      2.917e-03   1.550e-02   1.882e-01   8.529e-01\nlag.CAP_OCC    -1.146e-02   5.798e-02  -1.976e-01   8.457e-01\nlag.CAP_CS      9.438e-01   9.882e-01   9.552e-01   3.529e-01\nlag.Población  -1.448e-04   1.795e-04  -8.065e-01   4.311e-01\n\n\nClaro, aquí tienes todo el contenido en formato Markdown para que puedas copiarlo y pegarlo:\n\n\nModelo Lag (SAR - Spatial Autoregressive)\n\\[\ny = \\mathbf{X\\beta} + \\mathbf{\\rho W y} + u \\quad \\text{y} \\quad u = \\lambda W u + \\varepsilon\n\\]\nEl modelo SAR (Spatial Autoregressive) incluye un término de “lag” en la variable dependiente (\\(\\mathbf{W y}\\)), donde ( \\(\\mathbf{rho}\\)) es el coeficiente asociado al lag espacial. Este modelo captura la dependencia espacial en los valores de la variable dependiente entre vecinos. El término de error ( \\(u\\)) también está modelado como un proceso autoregresivo espacial (es decir, ( \\(u = \\lambda W u + \\varepsilon\\) )), lo que significa que el error de una observación también depende de los errores de sus vecinos.\n\nreg3 = lagsarlm(reg.eq1, data = Insumo, Insumo.lw, zero.policy = TRUE)\n\nWarning in lagsarlm(reg.eq1, data = Insumo, Insumo.lw, zero.policy = TRUE): inversion of asymptotic covariance matrix failed for tol.solve = 2.22044604925031e-16 \n  número de condición recíproco = 5.86692e-18 - using numerical Hessian.\n\nsummary(reg3)\n\n\nCall:lagsarlm(formula = reg.eq1, data = Insumo, listw = Insumo.lw, \n    zero.policy = TRUE)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-214.497  -61.665  -15.071   34.870  395.222 \n\nType: lag \nRegions with no neighbours included:\n 28 \nCoefficients: (numerical Hessian approximate standard errors) \n               Estimate  Std. Error z value Pr(&gt;|z|)\n(Intercept)  6.8199e+01  7.2159e+01  0.9451  0.34459\nPIB          3.1708e-03  2.7729e-03  1.1435  0.25283\nNBI         -1.0169e+00  1.5539e+00 -0.6544  0.51284\nCAP_BOG     -4.7766e-02  4.6328e-02 -1.0310  0.30253\nCAP_BC       4.7788e-03  5.0817e-03  0.9404  0.34702\nCAP_OCC     -3.5245e-02  1.8997e-02 -1.8553  0.06355\nCAP_CS       3.6931e-01  2.6724e-01  1.3820  0.16699\nPoblación    1.0303e-05  5.5724e-05  0.1849  0.85331\n\nRho: 0.2533, LR test value: 2.8104, p-value: 0.093656\nApproximate (numerical Hessian) standard error: 0.14574\n    z-value: 1.738, p-value: 0.082208\nWald statistic: 3.0207, p-value: 0.082208\n\nLog likelihood: -198.1508 for lag model\nML residual variance (sigma squared): 13793, (sigma: 117.44)\nNumber of observations: 32 \nNumber of parameters estimated: 10 \nAIC: 416.3, (AIC for lm: 417.11)\n\n\n\n\nModelo de Error Espacial (SEM - Spatial Error Model)\n\\[y = X\\beta + \\varepsilon \\quad \\text{y} \\quad \\varepsilon = \\lambda W \\varepsilon + u\\]\nEl Modelo de Error Espacial (SEM) incluye una corrección para la dependencia espacial en los errores ($ $), donde ( \\(\\lambda\\) ) es el coeficiente que mide la fuerza de la correlación espacial en los errores. El modelo SEM no incluye un “lag” espacial en la variable dependiente, sino que captura la dependencia espacial en el término de error.\n\nreg4 = errorsarlm(reg.eq1, data = Insumo, Insumo.lw, zero.policy = TRUE)\n\nWarning in errorsarlm(reg.eq1, data = Insumo, Insumo.lw, zero.policy = TRUE): inversion of asymptotic covariance matrix failed for tol.solve = 2.22044604925031e-16 \n  número de condición recíproco = 9.31736e-18 - using numerical Hessian.\n\nsummary(reg4)\n\n\nCall:errorsarlm(formula = reg.eq1, data = Insumo, listw = Insumo.lw, \n    zero.policy = TRUE)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-218.740  -53.251  -12.473   40.884  430.689 \n\nType: error \nRegions with no neighbours included:\n 28 \nCoefficients: (asymptotic standard errors) \n               Estimate  Std. Error z value Pr(&gt;|z|)\n(Intercept)  8.1541e+01  6.6482e+01  1.2265 0.220010\nPIB          3.4910e-03  2.6338e-03  1.3254 0.185024\nNBI         -5.7398e-01  1.5259e+00 -0.3762 0.706802\nCAP_BOG     -2.2704e-02  4.9984e-02 -0.4542 0.649667\nCAP_BC       1.5961e-05  5.3543e-03  0.0030 0.997622\nCAP_OCC     -5.2267e-02  1.9001e-02 -2.7508 0.005945\nCAP_CS       2.3351e-01  2.8637e-01  0.8154 0.414840\nPoblación    5.7012e-05  6.5438e-05  0.8712 0.383627\n\nLambda: 0.52347, LR test value: 4.2435, p-value: 0.0394\nApproximate (numerical Hessian) standard error: 0.20488\n    z-value: 2.5551, p-value: 0.010617\nWald statistic: 6.5283, p-value: 0.010617\n\nLog likelihood: -197.4342 for error model\nML residual variance (sigma squared): 12472, (sigma: 111.68)\nNumber of observations: 32 \nNumber of parameters estimated: 10 \nAIC: 414.87, (AIC for lm: 417.11)\n\n\n\n\nModelo de Durbin Espacial con Error (SDEM - Spatial Durbin Error Model)\n\\[y = X\\beta + W X \\theta + u \\quad \\text{y} \\quad u = \\lambda W u + \\varepsilon\\]\nEl Modelo de Durbin Espacial con Error (SDEM) es una combinación del modelo de error espacial y el modelo de regresión espacial Durbin. En este modelo, no solo se incluye un término de “lag” espacial para la variable dependiente, sino también para las variables explicativas. El término de error (\\(u\\)) sigue un proceso autoregresivo espacial. Este modelo captura tanto la dependencia espacial en las variables dependientes como en las explicativas.\n\nreg5 = errorsarlm(reg.eq1, data = Insumo, Insumo.lw, etype = \"emixed\", zero.policy = TRUE)\n\nWarning in errorsarlm(reg.eq1, data = Insumo, Insumo.lw, etype = \"emixed\", : inversion of asymptotic covariance matrix failed for tol.solve = 2.22044604925031e-16 \n  número de condición recíproco = 9.13061e-18 - using numerical Hessian.\n\nsummary(reg5)\n\n\nCall:errorsarlm(formula = reg.eq1, data = Insumo, listw = Insumo.lw, \n    etype = \"emixed\", zero.policy = TRUE)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-211.810  -47.834  -11.501   56.293  377.775 \n\nType: error \nRegions with no neighbours included:\n 28 \nCoefficients: (asymptotic standard errors) \n                 Estimate  Std. Error z value Pr(&gt;|z|)\n(Intercept)    2.8964e+01  1.0590e+02  0.2735   0.7845\nPIB            4.4110e-03  2.8308e-03  1.5582   0.1192\nNBI            3.5633e-01  1.8031e+00  0.1976   0.8433\nCAP_BOG       -3.8107e-02  5.4243e-02 -0.7025   0.4824\nCAP_BC        -1.6123e-03  6.6418e-03 -0.2427   0.8082\nCAP_OCC       -5.3413e-02  2.3321e-02 -2.2903   0.0220\nCAP_CS         2.8575e-01  3.0596e-01  0.9339   0.3503\nPoblación      5.3045e-05  7.7522e-05  0.6843   0.4938\nlag.PIB        4.1782e-03  7.6459e-03  0.5465   0.5847\nlag.NBI       -5.8691e-01  3.1145e+00 -0.1884   0.8505\nlag.CAP_BOG   -1.0933e-01  1.1822e-01 -0.9248   0.3551\nlag.CAP_BC    -5.3450e-03  1.0944e-02 -0.4884   0.6253\nlag.CAP_OCC   -1.7609e-02  4.3079e-02 -0.4088   0.6827\nlag.CAP_CS     5.0040e-01  7.0948e-01  0.7053   0.4806\nlag.Población -5.1562e-05  1.2903e-04 -0.3996   0.6894\n\nLambda: 0.46671, LR test value: 2.1801, p-value: 0.13981\nApproximate (numerical Hessian) standard error: 0.27542\n    z-value: 1.6945, p-value: 0.090164\nWald statistic: 2.8714, p-value: 0.090164\n\nLog likelihood: -196.0596 for error model\nML residual variance (sigma squared): 11631, (sigma: 107.85)\nNumber of observations: 32 \nNumber of parameters estimated: 17 \nAIC: 426.12, (AIC for lm: 426.3)\n\n\n\n\nModelo Durbin Espacial (SDM - Spatial Durbin Model)\n\\[y = X\\beta + W y \\rho + W X \\theta + \\varepsilon\\]\nEl Modelo Durbin Espacial (SDM) es una extensión del modelo SAR que incluye tanto un “lag” espacial de la variable dependiente como un “lag” espacial de las variables explicativas. Este modelo permite que las variables explicativas influyan tanto directamente como a través de sus efectos espaciales en la variable dependiente.\n\nreg6 = lagsarlm(reg.eq1, data = Insumo, Insumo.lw, type = \"mixed\", zero.policy = TRUE)\n\nWarning in lagsarlm(reg.eq1, data = Insumo, Insumo.lw, type = \"mixed\", zero.policy = TRUE): inversion of asymptotic covariance matrix failed for tol.solve = 2.22044604925031e-16 \n  número de condición recíproco = 4.58189e-18 - using numerical Hessian.\n\nsummary(reg6)\n\n\nCall:lagsarlm(formula = reg.eq1, data = Insumo, listw = Insumo.lw, \n    type = \"mixed\", zero.policy = TRUE)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-203.5501  -57.4964   -9.1121   49.0668  377.8941 \n\nType: mixed \nRegions with no neighbours included:\n 28 \nCoefficients: (numerical Hessian approximate standard errors) \n                 Estimate  Std. Error z value Pr(&gt;|z|)\n(Intercept)    5.6710e+01  1.0611e+02  0.5344  0.59304\nPIB            3.8566e-03  2.7986e-03  1.3781  0.16819\nNBI            1.4678e-01  2.1429e+00  0.0685  0.94539\nCAP_BOG       -1.4527e-02  5.7942e-02 -0.2507  0.80203\nCAP_BC        -2.9294e-03  6.8930e-03 -0.4250  0.67085\nCAP_OCC       -5.8433e-02  2.3689e-02 -2.4666  0.01364\nCAP_CS         1.6655e-01  3.2580e-01  0.5112  0.60922\nPoblación      7.9995e-05  8.3984e-05  0.9525  0.34084\nlag.PIB        1.1073e-03  6.6845e-03  0.1657  0.86843\nlag.NBI       -1.1460e+00  3.1540e+00 -0.3634  0.71633\nlag.CAP_BOG   -1.1343e-01  1.1758e-01 -0.9647  0.33469\nlag.CAP_BC    -1.2808e-04  1.0278e-02 -0.0125  0.99006\nlag.CAP_OCC    7.3867e-03  4.4739e-02  0.1651  0.86886\nlag.CAP_CS     5.3185e-01  6.9614e-01  0.7640  0.44487\nlag.Población -9.8368e-05  1.3609e-04 -0.7228  0.46979\n\nRho: 0.38762, LR test value: 2.4703, p-value: 0.11602\nApproximate (numerical Hessian) standard error: 0.22804\n    z-value: 1.6998, p-value: 0.089166\nWald statistic: 2.8894, p-value: 0.089166\n\nLog likelihood: -195.9145 for mixed model\nML residual variance (sigma squared): 11739, (sigma: 108.34)\nNumber of observations: 32 \nNumber of parameters estimated: 17 \nAIC: 425.83, (AIC for lm: 426.3)\n\n\n\n\nModelo Manski (Manski Model)\n\\[y = \\rho W y + X \\beta + W X \\theta + u \\quad \\text{y} \\quad u = \\lambda W u + \\varepsilon\\]\nEl Modelo Manski es similar al modelo SDM, pero tiene una estructura más compleja en cuanto a la autocorrelación espacial de los errores. Este modelo incluye tanto el “lag” espacial de la variable dependiente, como los “lags” espaciales de las variables explicativas. La diferencia principal con el modelo SDM es el tratamiento más complejo de los términos de error.\n\nreg7 = sacsarlm(reg.eq1, data = Insumo, Insumo.lw, type = \"sacmixed\", zero.policy = TRUE)\n\nWarning in sacsarlm(reg.eq1, data = Insumo, Insumo.lw, type = \"sacmixed\", : inversion of asymptotic covariance matrix failed for tol.solve = 2.22044604925031e-16 \n  número de condición recíproco = 4.61347e-18 - using numerical Hessian.\n\nsummary(reg7)\n\n\nCall:sacsarlm(formula = reg.eq1, data = Insumo, listw = Insumo.lw, \n    type = \"sacmixed\", zero.policy = TRUE)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-204.541  -53.811  -12.538   51.980  382.238 \n\nType: sacmixed \nCoefficients: (numerical Hessian approximate standard errors) \n                 Estimate  Std. Error z value Pr(&gt;|z|)\n(Intercept)    4.8808e+01  1.1502e+02  0.4243  0.67131\nPIB            4.0090e-03  2.8803e-03  1.3919  0.16396\nNBI            2.1612e-01  1.9200e+00  0.1126  0.91038\nCAP_BOG       -2.2486e-02  6.9157e-02 -0.3251  0.74507\nCAP_BC        -2.3158e-03  7.5058e-03 -0.3085  0.75768\nCAP_OCC       -5.6496e-02  2.5908e-02 -2.1806  0.02921\nCAP_CS         2.0887e-01  3.8203e-01  0.5467  0.58456\nPoblación      6.9346e-05  9.6780e-05  0.7165  0.47366\nlag.PIB        1.5704e-03  7.9396e-03  0.1978  0.84321\nlag.NBI       -9.9232e-01  3.1209e+00 -0.3180  0.75051\nlag.CAP_BOG   -1.1048e-01  1.2387e-01 -0.8919  0.37243\nlag.CAP_BC    -1.5701e-03  1.3233e-02 -0.1187  0.90555\nlag.CAP_OCC    2.5166e-03  5.0022e-02  0.0503  0.95988\nlag.CAP_CS     5.1478e-01  7.4300e-01  0.6928  0.48841\nlag.Población -8.2594e-05  1.4845e-04 -0.5564  0.57796\n\nRho: 0.31266\nApproximate (numerical Hessian) standard error: 0.50048\n    z-value: 0.62472, p-value: 0.53215\nLambda: 0.13054\nApproximate (numerical Hessian) standard error: 0.71242\n    z-value: 0.18324, p-value: 0.85461\n\nLR test value: 7.3157, p-value: 0.60429\n\nLog likelihood: -195.8981 for sacmixed model\nML residual variance (sigma squared): 11840, (sigma: 108.81)\nNumber of observations: 32 \nNumber of parameters estimated: 18 \nAIC: 427.8, (AIC for lm: 417.11)\n\n\n\n\nModelo SARAR (Kelejian-Prucha, Cliff-Ord, SAC)\n\\[y = X\\beta + \\rho W y + u \\quad \\text{y} \\quad u = \\lambda W u + \\varepsilon\\]\nEl Modelo SARAR (también conocido como modelo Kelejian-Prucha o Cliff-Ord) es un modelo que combina características del modelo SAR y SEM. Este modelo tiene un término de “lag” espacial en la variable dependiente y un término de error espacial autoregresivo, lo que permite capturar tanto la dependencia espacial en la variable dependiente como en el error.\n\nreg8 = sacsarlm(reg.eq1, data = Insumo, Insumo.lw, type = \"sac\", zero.policy = TRUE)\n\nWarning in sacsarlm(reg.eq1, data = Insumo, Insumo.lw, type = \"sac\", zero.policy = TRUE): inversion of asymptotic covariance matrix failed for tol.solve = 2.22044604925031e-16 \n  número de condición recíproco = 8.70662e-18 - using numerical Hessian.\n\nsummary(reg8)\n\n\nCall:sacsarlm(formula = reg.eq1, data = Insumo, listw = Insumo.lw, \n    type = \"sac\", zero.policy = TRUE)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-205.1587  -56.7315   -9.4429   31.9574  422.6304 \n\nType: sac \nCoefficients: (numerical Hessian approximate standard errors) \n               Estimate  Std. Error z value Pr(&gt;|z|)\n(Intercept)  6.4572e+01  7.2349e+01  0.8925  0.37212\nPIB          3.2940e-03  2.6769e-03  1.2305  0.21850\nNBI         -6.2802e-01  1.5495e+00 -0.4053  0.68526\nCAP_BOG     -3.2650e-02  5.1324e-02 -0.6361  0.52468\nCAP_BC       2.2998e-03  6.0593e-03  0.3795  0.70428\nCAP_OCC     -4.4343e-02  2.1685e-02 -2.0449  0.04086\nCAP_CS       2.8775e-01  2.9320e-01  0.9814  0.32638\nPoblación    3.8417e-05  6.7901e-05  0.5658  0.57155\n\nRho: 0.13272\nApproximate (numerical Hessian) standard error: 0.18411\n    z-value: 0.72086, p-value: 0.471\nLambda: 0.40988\nApproximate (numerical Hessian) standard error: 0.27523\n    z-value: 1.4892, p-value: 0.13643\n\nLR test value: 4.7255, p-value: 0.094163\n\nLog likelihood: -197.1932 for sac model\nML residual variance (sigma squared): 12607, (sigma: 112.28)\nNumber of observations: 32 \nNumber of parameters estimated: 11 \nAIC: 416.39, (AIC for lm: 417.11)\n\n\n\n\nCálculo de variables significativas\nPueden calcularse las variables significativas de cada modelo de regresión, proporcionando los coeficientes estimados y los valores p asociados.\n\n#Calculo de variables significativas\nreg.eq2=CAP_BAC ~ PIB + CAP_BOG+CAP_BC + CAP_OCC + CAP_CS+ Población\nreg4=errorsarlm(reg.eq2,data=Insumo, Insumo.lw, zero.policy = TRUE)\n\nWarning in errorsarlm(reg.eq2, data = Insumo, Insumo.lw, zero.policy = TRUE): inversion of asymptotic covariance matrix failed for tol.solve = 2.22044604925031e-16 \n  número de condición recíproco = 9.34261e-18 - using numerical Hessian.\n\ns = summary\ns(reg4)#Lag Error (SEM)\n\n\nCall:errorsarlm(formula = reg.eq2, data = Insumo, listw = Insumo.lw, \n    zero.policy = TRUE)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-211.532  -51.640  -10.342   43.439  434.624 \n\nType: error \nRegions with no neighbours included:\n 28 \nCoefficients: (asymptotic standard errors) \n               Estimate  Std. Error z value Pr(&gt;|z|)\n(Intercept)  6.5053e+01  5.2382e+01  1.2419 0.214276\nPIB          3.7321e-03  2.5473e-03  1.4651 0.142880\nCAP_BOG     -2.6478e-02  4.8603e-02 -0.5448 0.585908\nCAP_BC       2.1298e-05  5.3721e-03  0.0040 0.996837\nCAP_OCC     -5.2253e-02  1.9059e-02 -2.7417 0.006113\nCAP_CS       2.5082e-01  2.8122e-01  0.8919 0.372449\nPoblación    5.3526e-05  6.4802e-05  0.8260 0.408807\n\nLambda: 0.53453, LR test value: 4.7167, p-value: 0.029871\nApproximate (numerical Hessian) standard error: 0.19933\n    z-value: 2.6816, p-value: 0.007327\nWald statistic: 7.191, p-value: 0.007327\n\nLog likelihood: -197.5033 for error model\nML residual variance (sigma squared): 12482, (sigma: 111.72)\nNumber of observations: 32 \nNumber of parameters estimated: 9 \nAIC: 413.01, (AIC for lm: 415.72)\n\nreg.eq3=CAP_BAC ~ PIB + CAP_BOG + CAP_OCC + CAP_CS+ Población\nreg4=errorsarlm(reg.eq3,data=Insumo, Insumo.lw, zero.policy = TRUE)\n\nWarning in errorsarlm(reg.eq3, data = Insumo, Insumo.lw, zero.policy = TRUE): inversion of asymptotic covariance matrix failed for tol.solve = 2.22044604925031e-16 \n  número de condición recíproco = 9.39308e-18 - using numerical Hessian.\n\ns(reg4)#Lag Error (SEM)\n\n\nCall:errorsarlm(formula = reg.eq3, data = Insumo, listw = Insumo.lw, \n    zero.policy = TRUE)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-211.604  -51.658  -10.314   43.452  434.644 \n\nType: error \nRegions with no neighbours included:\n 28 \nCoefficients: (asymptotic standard errors) \n               Estimate  Std. Error z value  Pr(&gt;|z|)\n(Intercept)  6.4949e+01  4.6184e+01  1.4063 0.1596331\nPIB          3.7353e-03  2.4024e-03  1.5548 0.1199876\nCAP_BOG     -2.6340e-02  3.5604e-02 -0.7398 0.4594136\nCAP_OCC     -5.2300e-02  1.4786e-02 -3.5372 0.0004044\nCAP_CS       2.5002e-01  2.0469e-01  1.2215 0.2219007\nPoblación    5.3668e-05  5.4615e-05  0.9827 0.3257723\n\nLambda: 0.53464, LR test value: 4.9211, p-value: 0.02653\nApproximate (numerical Hessian) standard error: 0.19966\n    z-value: 2.6777, p-value: 0.0074134\nWald statistic: 7.17, p-value: 0.0074134\n\nLog likelihood: -197.5033 for error model\nML residual variance (sigma squared): 12482, (sigma: 111.72)\nNumber of observations: 32 \nNumber of parameters estimated: 8 \nAIC: 411.01, (AIC for lm: 413.93)\n\nreg.eq4=CAP_BAC ~ PIB + CAP_OCC + CAP_CS+ Población\nreg4=errorsarlm(reg.eq4,data=Insumo, Insumo.lw, zero.policy = TRUE)\n\nWarning in errorsarlm(reg.eq4, data = Insumo, Insumo.lw, zero.policy = TRUE): inversion of asymptotic covariance matrix failed for tol.solve = 2.22044604925031e-16 \n  número de condición recíproco = 9.49253e-18 - using numerical Hessian.\n\ns(reg4)#Lag Error (SEM)\n\n\nCall:errorsarlm(formula = reg.eq4, data = Insumo, listw = Insumo.lw, \n    zero.policy = TRUE)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-197.278  -57.885  -10.374   35.522  448.779 \n\nType: error \nRegions with no neighbours included:\n 28 \nCoefficients: (asymptotic standard errors) \n               Estimate  Std. Error z value  Pr(&gt;|z|)\n(Intercept)  6.5631e+01  4.8473e+01  1.3540 0.1757428\nPIB          3.5303e-03  2.3971e-03  1.4727 0.1408221\nCAP_OCC     -5.0850e-02  1.4681e-02 -3.4638 0.0005327\nCAP_CS       1.0179e-01  3.7538e-02  2.7115 0.0066982\nPoblación    6.3364e-05  5.3434e-05  1.1858 0.2356933\n\nLambda: 0.57217, LR test value: 7.0658, p-value: 0.0078569\nApproximate (numerical Hessian) standard error: 0.17965\n    z-value: 3.185, p-value: 0.0014477\nWald statistic: 10.144, p-value: 0.0014477\n\nLog likelihood: -197.7534 for error model\nML residual variance (sigma squared): 12518, (sigma: 111.88)\nNumber of observations: 32 \nNumber of parameters estimated: 7 \nAIC: 409.51, (AIC for lm: 414.57)\n\nreg.eq5=CAP_BAC ~ PIB + CAP_OCC + CAP_CS\nreg4=errorsarlm(reg.eq5,data=Insumo, Insumo.lw, zero.policy = TRUE)\ns(reg4)#Lag Error (SEM)\n\n\nCall:errorsarlm(formula = reg.eq5, data = Insumo, listw = Insumo.lw, \n    zero.policy = TRUE)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-184.748  -63.304  -12.444   40.679  448.841 \n\nType: error \nRegions with no neighbours included:\n 28 \nCoefficients: (asymptotic standard errors) \n               Estimate  Std. Error z value  Pr(&gt;|z|)\n(Intercept) 88.65061930 44.45631621  1.9941  0.046140\nPIB          0.00617514  0.00092824  6.6525 2.881e-11\nCAP_OCC     -0.04719334  0.01471065 -3.2081  0.001336\nCAP_CS       0.07187945  0.02876778  2.4986  0.012468\n\nLambda: 0.55051, LR test value: 6.002, p-value: 0.014289\nAsymptotic standard error: 0.17223\n    z-value: 3.1964, p-value: 0.0013917\nWald statistic: 10.217, p-value: 0.0013917\n\nLog likelihood: -198.4352 for error model\nML residual variance (sigma squared): 13162, (sigma: 114.72)\nNumber of observations: 32 \nNumber of parameters estimated: 6 \nAIC: 408.87, (AIC for lm: 412.87)\n\n\n\n\nMapa estimado\n\nfit &lt;- reg2$fitted.values\nggplot(Insumo.utm) +\n  geom_sf(aes(fill = fit)) +\n  scale_fill_viridis_c() +\n  ggtitle(\"Valores ajustados mediante el modelo SEM para las captaciones del banco agrario en Colombia, cuarto trimestre 2020\") +\n  theme_minimal()\n\n\n\n\n\n\n\n###Test de moran residuales modelo SEM\nmoran.test(reg4$residuals, Insumo.lw)\n\n\n    Moran I test under randomisation\n\ndata:  reg4$residuals  \nweights: Insumo.lw  \nn reduced by no-neighbour observations  \n\nMoran I statistic standard deviate = 0.81038, p-value = 0.2089\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n       0.05128789       -0.03333333        0.01090389"
  },
  {
    "objectID": "Kriging_escalar.html",
    "href": "Kriging_escalar.html",
    "title": "Kriging_Puntual",
    "section": "",
    "text": "Kriging es una técnica de interpolación espacial que permite estimar valores desconocidos en una superficie a partir de los valores conocidos en ubicaciones cercanas. Es especialmente útil para datos de alta densidad y para datos con estructuras espaciales complejas. En este cuaderno, vamos a explorar los diferentes tipos de Kriging y cómo implementarlos en R.\nAntes de comenzar, asegúrate de tener instalados los siguientes paquetes de R: “gstat”, “sp”, “raster” y “ggplot2”. Si no los tienes, puedes instalarlos mediante el siguiente código:\n\n# Instalar paquetes si es necesario\n\nlibrary(gstat)\nlibrary(sp)\nlibrary(raster)\nlibrary(ggplot2)\nlibrary(phylin)\n\n\nAdjuntando el paquete: 'phylin'\n\n\nThe following object is masked from 'package:gstat':\n\n    idw\n\n# Generación de datos simulados para los ejemplos\nset.seed(1029)\ncoords &lt;- data.frame(x = runif(10, 0, 100), y = runif(10, 0, 100))\nvalues &lt;- data.frame(value = rnorm(10))\n\n# Combinar 'coords' y 'values' en un solo data frame\ndata &lt;- cbind(coords, values)\n\n# Convertir 'data' en un objeto espacial\ncoordinates(data) &lt;- ~ x + y\nproj4string(data) &lt;- CRS(\"+proj=utm +zone=33 +datum=WGS84\")\n\n\n\nKriging es una técnica de interpolación espacial que se basa en la teoría de la estadística espacial. La idea fundamental detrás de Kriging es que la estimación del valor desconocido en una ubicación dada se hace como una combinación lineal ponderada de los valores conocidos en las ubicaciones vecinas. Los pesos de esta combinación se determinan utilizando la información de covarianza entre los puntos en el espacio. Esta técnica se utiliza comúnmente en estadística espacial, geología, minería, geofísica, oceanografía y otros campos que involucran la toma de medidas en lugares dispersos en el espacio.\nEl nombre “Kriging” proviene del geólogo Danie G. Krige, quien fue el primero en aplicar esta técnica para la exploración de minerales en Sudáfrica en la década de 1950\n\n\n\nEn esta sección se explica el método de kriging simple, que es una técnica de interpolación espacial que utiliza una función de tendencia conocida y un modelo de variograma ajustado a los datos. El objetivo es estimar el valor de una variable Z en una ubicación s0 a partir de los valores observados en n ubicaciones si cercanas. El kriging simple asume que la variable Z se puede descomponer como:\n\\[Z(s) = μ(s) + ε(s),\\]\ndonde \\(μ(s)\\) es la función de tendencia conocida y \\(ε(s)\\) es un proceso espacial aleatorio con media cero y covarianza \\(C(s_i,s_j) = Cov(ε(s_i),ε(s_j))\\). El predictor del kriging simple es una combinación lineal de los valores observados:\n\\[p(Z,s_0) = μ(s_0) + ∑_{i=1}^n λ_i (Z(s_i) - μ(s_i)),\\]\ndonde los pesos \\(λ_i\\) se obtienen resolviendo el sistema de ecuaciones:\n\\[∑_{j=1}^n λ_j C(s_i,s_j) - C(s_i,s_0) = 0, \\  i = 1,...,n.\\]\nEl kriging simple minimiza el error cuadrático medio entre el valor estimado y el verdadero, que se denomina varianza kriging y se calcula como:\n\\[σ^2 KS(s_0) = C(s_0,s_0) - ∑_{i=1}^n ∑_{j=1}^n λ_i λ_j C(s_i,s_j).\\]\nPara implementar el kriging simple en R se puede utilizar la función krig del paquete phylin, que requiere como argumentos los valores observados, las coordenadas de las ubicaciones muestreadas y las ubicaciones a interpolar, el modelo de variograma ajustado y el valor conocido de la media (o NA para usar kriging ordinario). A continuación se muestra un ejemplo con datos simulados:\n\n# Calcular el variograma experimental\nvgram &lt;- variogram(value ~ 1, data)\n\n# Ajustar un modelo de variograma\nmodel &lt;- vgm(psill = 1, model = \"Sph\", range = 50, nugget = 0)\nvfit &lt;- fit.variogram(vgram, model)\n\nWarning in fit.variogram(vgram, model): linear model has singular covariance\nmatrix\n\n\nWarning in fit.variogram(vgram, model): singular model in variogram fit\n\n\nWarning in fit.variogram(object, model, fit.sills = fit.sills, fit.ranges =\nfit.ranges, : No convergence after 200 iterations: try different initial\nvalues?\n\n# Crear una cuadrícula de predicción\ngrd &lt;- expand.grid(x = seq(0, 100, by = 5), y = seq(0, 100, by = 5))\ncoordinates(grd) &lt;- ~ x + y\ngridded(grd) &lt;- TRUE\nproj4string(grd) &lt;- CRS(\"+proj=utm +zone=33 +datum=WGS84\")\n\n# Kriging Simple\nkriged_values &lt;- krige(value ~ 1, data, grd, model = vfit, nmax = 5)\n\n[using ordinary kriging]\n\n\n\n# Visualización\nspplot(kriged_values[\"var1.pred\"], main = \"Kriging Simple Prediction\")\n\n\n\n\n\n\n\n\n\n\n\nEl kriging ordinario es el tipo más general y más utilizado de kriging. Presupone que el valor medio constante es desconocido y lo estima a partir de los datos disponibles. Esta es una suposición razonable a menos que haya una razón científica para rechazarla.\nEl kriging ordinario se puede expresar como:\n\\[Z^*(x_0) = \\sum_{i=1}^n \\lambda_i Z(x_i)\\]\nDonde \\(Z^*(x_0)\\) es el valor estimado en el punto \\(x_0\\), \\(Z(x_i)\\) son los valores medidos en los puntos \\(x_i\\), \\(n\\) es el número de puntos medidos y \\(\\lambda_i\\) son los pesos óptimos que minimizan la varianza del error de estimación.\nLos pesos óptimos se obtienen resolviendo un sistema de ecuaciones lineales conocido como sistema krigiano:\n\\[\n\\begin{bmatrix}\n\\gamma_{11} & \\gamma_{12} & \\cdots & \\gamma_{1n} & 1 \\\\\n\\gamma_{21} & \\gamma_{22} & \\cdots & \\gamma_{2n} & 1 \\\\\n\\vdots      & \\vdots      & \\ddots & \\vdots      & 1 \\\\\n\\gamma_{n1} & \\gamma_{n2} & \\cdots & \\gamma_{nn} & 1 \\\\\n1           & 1           & \\cdots & 1           & 0\n\\end{bmatrix}\n\\begin{bmatrix}\n\\lambda_1 \\\\\n\\lambda_2 \\\\\n\\vdots    \\\\\n\\lambda_n \\\\\nm\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\gamma(x_0,x_1) \\\\\n\\gamma(x_0,x_2) \\\\\n\\vdots          \\\\\n\\gamma(x_0,x_n) \\\\\n-1\n\\end{bmatrix}\n\\]\nDonde \\(\\gamma_{ij}\\) son los semivariogramas entre los puntos medidos, \\(\\gamma(x_0,x_i)\\) son los semivariogramas entre el punto a estimar y los puntos medidos y \\(m\\) es un multiplicador lagrangeano que representa la estimación del valor medio constante.\nPara implementar el kriging ordinario en R, se pueden utilizar las librerías “gstat” o “kriging”. A continuación se muestra un ejemplo usando la librería “gstat”.\n\n# Ajustar modelo de variograma para kriging ordinario\nvgram &lt;- variogram(value ~ 1, data)\nvfit &lt;- fit.variogram(vgram, model)\n\nWarning in fit.variogram(vgram, model): linear model has singular covariance\nmatrix\n\n\nWarning in fit.variogram(vgram, model): singular model in variogram fit\n\n\nWarning in fit.variogram(object, model, fit.sills = fit.sills, fit.ranges =\nfit.ranges, : No convergence after 200 iterations: try different initial\nvalues?\n\n# Kriging ordinario\nkriged_values_ordinary &lt;- krige(value ~ 1, data, grd, model = vfit, nmax = 5)\n\n[using ordinary kriging]\n\n\n\n# Visualización\nspplot(kriged_values_ordinary[\"var1.pred\"], main = \"Kriging Ordinario Prediction\")\n\n\n\n\n\n\n\n\n\n\n\nEl kriging universal es una variante del kriging que permite incorporar variables auxiliares que influyen en la variable de interés. Por ejemplo, si queremos interpolar la temperatura en una región, podemos usar como variables auxiliares la altitud, la latitud o la distancia al mar. El kriging universal asume que la variable de interés se puede expresar como una combinación lineal de las variables auxiliares más un error espacialmente correlacionado. Es decir:\n\\[\nZ(s) = p ∑_{j=0} X_j(s)β_j +ε(s),\n\\]\ndonde \\(Z(s)\\) es la variable de interés en el punto \\(s\\), \\(X_j(s)\\) son las variables auxiliares (incluyendo una constante), βj son los coeficientes desconocidos y ε(s) es el error espacial con variograma conocido.\nPara estimar \\(Z(s_0)\\) en un punto no observado \\(s_0\\), se usa el predictor del kriging universal:\n\\[\np(Z,s_0) = ∑_{i=1}^n λ_iZ(s_i),\n\\]\ndonde \\(λ_i\\) son los pesos que minimizan el error cuadrático medio de predicción sujeto a las restricciones:\n\\[λ^⊤X = x^⊤ 0,\\]\ndonde \\(X\\) es una matriz con las variables auxiliares en los puntos observados y \\(x_0\\) es un vector con las variables auxiliares en el punto \\(s_0\\).\nPara implementar el kriging universal en R, podemos usar el paquete gstat y la función krige. Esta función requiere una fórmula que defina la variable dependiente como un modelo lineal de las variables independientes, un objeto espacial con las coordenadas y los datos observados, un objeto espacial con las coordenadas de los puntos a predecir y un modelo de variograma para el error espacial.\nA continuación se muestra un ejemplo de cómo usar krige para realizar kriging universal con dos variables auxiliares: \\(x\\) e \\(y\\).\n\n# Añadir variables auxiliares al conjunto de datos\nvalues$x &lt;- coordinates(data)[,1]\nvalues$y &lt;- coordinates(data)[,2]\n\n# Ajustar variograma\nvgram_universal &lt;- variogram(value ~ x + y, data)\nvfit_universal &lt;- fit.variogram(vgram_universal, vgm(model = \"Sph\", psill = 1, range = 50, nugget = 0))\n\nWarning in fit.variogram(vgram_universal, vgm(model = \"Sph\", psill = 1, :\nsingular model in variogram fit\n\n\nWarning in fit.variogram(object, model, fit.sills = fit.sills, fit.ranges =\nfit.ranges, : No convergence after 200 iterations: try different initial\nvalues?\n\n# Kriging Universal\nkriged_values_universal &lt;- krige(value ~ x + y, data, grd, model = vfit_universal)\n\n[using universal kriging]\n\n# Visualización\nspplot(kriged_values_universal[\"var1.pred\"], main = \"Kriging Universal Prediction\")"
  },
  {
    "objectID": "Kriging_escalar.html#introducción-kriging",
    "href": "Kriging_escalar.html#introducción-kriging",
    "title": "Kriging_Puntual",
    "section": "",
    "text": "Kriging es una técnica de interpolación espacial que se basa en la teoría de la estadística espacial. La idea fundamental detrás de Kriging es que la estimación del valor desconocido en una ubicación dada se hace como una combinación lineal ponderada de los valores conocidos en las ubicaciones vecinas. Los pesos de esta combinación se determinan utilizando la información de covarianza entre los puntos en el espacio. Esta técnica se utiliza comúnmente en estadística espacial, geología, minería, geofísica, oceanografía y otros campos que involucran la toma de medidas en lugares dispersos en el espacio.\nEl nombre “Kriging” proviene del geólogo Danie G. Krige, quien fue el primero en aplicar esta técnica para la exploración de minerales en Sudáfrica en la década de 1950"
  },
  {
    "objectID": "Kriging_escalar.html#kriging-simple",
    "href": "Kriging_escalar.html#kriging-simple",
    "title": "Kriging_Puntual",
    "section": "",
    "text": "En esta sección se explica el método de kriging simple, que es una técnica de interpolación espacial que utiliza una función de tendencia conocida y un modelo de variograma ajustado a los datos. El objetivo es estimar el valor de una variable Z en una ubicación s0 a partir de los valores observados en n ubicaciones si cercanas. El kriging simple asume que la variable Z se puede descomponer como:\n\\[Z(s) = μ(s) + ε(s),\\]\ndonde \\(μ(s)\\) es la función de tendencia conocida y \\(ε(s)\\) es un proceso espacial aleatorio con media cero y covarianza \\(C(s_i,s_j) = Cov(ε(s_i),ε(s_j))\\). El predictor del kriging simple es una combinación lineal de los valores observados:\n\\[p(Z,s_0) = μ(s_0) + ∑_{i=1}^n λ_i (Z(s_i) - μ(s_i)),\\]\ndonde los pesos \\(λ_i\\) se obtienen resolviendo el sistema de ecuaciones:\n\\[∑_{j=1}^n λ_j C(s_i,s_j) - C(s_i,s_0) = 0, \\  i = 1,...,n.\\]\nEl kriging simple minimiza el error cuadrático medio entre el valor estimado y el verdadero, que se denomina varianza kriging y se calcula como:\n\\[σ^2 KS(s_0) = C(s_0,s_0) - ∑_{i=1}^n ∑_{j=1}^n λ_i λ_j C(s_i,s_j).\\]\nPara implementar el kriging simple en R se puede utilizar la función krig del paquete phylin, que requiere como argumentos los valores observados, las coordenadas de las ubicaciones muestreadas y las ubicaciones a interpolar, el modelo de variograma ajustado y el valor conocido de la media (o NA para usar kriging ordinario). A continuación se muestra un ejemplo con datos simulados:\n\n# Calcular el variograma experimental\nvgram &lt;- variogram(value ~ 1, data)\n\n# Ajustar un modelo de variograma\nmodel &lt;- vgm(psill = 1, model = \"Sph\", range = 50, nugget = 0)\nvfit &lt;- fit.variogram(vgram, model)\n\nWarning in fit.variogram(vgram, model): linear model has singular covariance\nmatrix\n\n\nWarning in fit.variogram(vgram, model): singular model in variogram fit\n\n\nWarning in fit.variogram(object, model, fit.sills = fit.sills, fit.ranges =\nfit.ranges, : No convergence after 200 iterations: try different initial\nvalues?\n\n# Crear una cuadrícula de predicción\ngrd &lt;- expand.grid(x = seq(0, 100, by = 5), y = seq(0, 100, by = 5))\ncoordinates(grd) &lt;- ~ x + y\ngridded(grd) &lt;- TRUE\nproj4string(grd) &lt;- CRS(\"+proj=utm +zone=33 +datum=WGS84\")\n\n# Kriging Simple\nkriged_values &lt;- krige(value ~ 1, data, grd, model = vfit, nmax = 5)\n\n[using ordinary kriging]\n\n\n\n# Visualización\nspplot(kriged_values[\"var1.pred\"], main = \"Kriging Simple Prediction\")"
  },
  {
    "objectID": "Kriging_escalar.html#kriging-ordinario",
    "href": "Kriging_escalar.html#kriging-ordinario",
    "title": "Kriging_Puntual",
    "section": "",
    "text": "El kriging ordinario es el tipo más general y más utilizado de kriging. Presupone que el valor medio constante es desconocido y lo estima a partir de los datos disponibles. Esta es una suposición razonable a menos que haya una razón científica para rechazarla.\nEl kriging ordinario se puede expresar como:\n\\[Z^*(x_0) = \\sum_{i=1}^n \\lambda_i Z(x_i)\\]\nDonde \\(Z^*(x_0)\\) es el valor estimado en el punto \\(x_0\\), \\(Z(x_i)\\) son los valores medidos en los puntos \\(x_i\\), \\(n\\) es el número de puntos medidos y \\(\\lambda_i\\) son los pesos óptimos que minimizan la varianza del error de estimación.\nLos pesos óptimos se obtienen resolviendo un sistema de ecuaciones lineales conocido como sistema krigiano:\n\\[\n\\begin{bmatrix}\n\\gamma_{11} & \\gamma_{12} & \\cdots & \\gamma_{1n} & 1 \\\\\n\\gamma_{21} & \\gamma_{22} & \\cdots & \\gamma_{2n} & 1 \\\\\n\\vdots      & \\vdots      & \\ddots & \\vdots      & 1 \\\\\n\\gamma_{n1} & \\gamma_{n2} & \\cdots & \\gamma_{nn} & 1 \\\\\n1           & 1           & \\cdots & 1           & 0\n\\end{bmatrix}\n\\begin{bmatrix}\n\\lambda_1 \\\\\n\\lambda_2 \\\\\n\\vdots    \\\\\n\\lambda_n \\\\\nm\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\gamma(x_0,x_1) \\\\\n\\gamma(x_0,x_2) \\\\\n\\vdots          \\\\\n\\gamma(x_0,x_n) \\\\\n-1\n\\end{bmatrix}\n\\]\nDonde \\(\\gamma_{ij}\\) son los semivariogramas entre los puntos medidos, \\(\\gamma(x_0,x_i)\\) son los semivariogramas entre el punto a estimar y los puntos medidos y \\(m\\) es un multiplicador lagrangeano que representa la estimación del valor medio constante.\nPara implementar el kriging ordinario en R, se pueden utilizar las librerías “gstat” o “kriging”. A continuación se muestra un ejemplo usando la librería “gstat”.\n\n# Ajustar modelo de variograma para kriging ordinario\nvgram &lt;- variogram(value ~ 1, data)\nvfit &lt;- fit.variogram(vgram, model)\n\nWarning in fit.variogram(vgram, model): linear model has singular covariance\nmatrix\n\n\nWarning in fit.variogram(vgram, model): singular model in variogram fit\n\n\nWarning in fit.variogram(object, model, fit.sills = fit.sills, fit.ranges =\nfit.ranges, : No convergence after 200 iterations: try different initial\nvalues?\n\n# Kriging ordinario\nkriged_values_ordinary &lt;- krige(value ~ 1, data, grd, model = vfit, nmax = 5)\n\n[using ordinary kriging]\n\n\n\n# Visualización\nspplot(kriged_values_ordinary[\"var1.pred\"], main = \"Kriging Ordinario Prediction\")"
  },
  {
    "objectID": "Kriging_escalar.html#kriging-universal",
    "href": "Kriging_escalar.html#kriging-universal",
    "title": "Kriging_Puntual",
    "section": "",
    "text": "El kriging universal es una variante del kriging que permite incorporar variables auxiliares que influyen en la variable de interés. Por ejemplo, si queremos interpolar la temperatura en una región, podemos usar como variables auxiliares la altitud, la latitud o la distancia al mar. El kriging universal asume que la variable de interés se puede expresar como una combinación lineal de las variables auxiliares más un error espacialmente correlacionado. Es decir:\n\\[\nZ(s) = p ∑_{j=0} X_j(s)β_j +ε(s),\n\\]\ndonde \\(Z(s)\\) es la variable de interés en el punto \\(s\\), \\(X_j(s)\\) son las variables auxiliares (incluyendo una constante), βj son los coeficientes desconocidos y ε(s) es el error espacial con variograma conocido.\nPara estimar \\(Z(s_0)\\) en un punto no observado \\(s_0\\), se usa el predictor del kriging universal:\n\\[\np(Z,s_0) = ∑_{i=1}^n λ_iZ(s_i),\n\\]\ndonde \\(λ_i\\) son los pesos que minimizan el error cuadrático medio de predicción sujeto a las restricciones:\n\\[λ^⊤X = x^⊤ 0,\\]\ndonde \\(X\\) es una matriz con las variables auxiliares en los puntos observados y \\(x_0\\) es un vector con las variables auxiliares en el punto \\(s_0\\).\nPara implementar el kriging universal en R, podemos usar el paquete gstat y la función krige. Esta función requiere una fórmula que defina la variable dependiente como un modelo lineal de las variables independientes, un objeto espacial con las coordenadas y los datos observados, un objeto espacial con las coordenadas de los puntos a predecir y un modelo de variograma para el error espacial.\nA continuación se muestra un ejemplo de cómo usar krige para realizar kriging universal con dos variables auxiliares: \\(x\\) e \\(y\\).\n\n# Añadir variables auxiliares al conjunto de datos\nvalues$x &lt;- coordinates(data)[,1]\nvalues$y &lt;- coordinates(data)[,2]\n\n# Ajustar variograma\nvgram_universal &lt;- variogram(value ~ x + y, data)\nvfit_universal &lt;- fit.variogram(vgram_universal, vgm(model = \"Sph\", psill = 1, range = 50, nugget = 0))\n\nWarning in fit.variogram(vgram_universal, vgm(model = \"Sph\", psill = 1, :\nsingular model in variogram fit\n\n\nWarning in fit.variogram(object, model, fit.sills = fit.sills, fit.ranges =\nfit.ranges, : No convergence after 200 iterations: try different initial\nvalues?\n\n# Kriging Universal\nkriged_values_universal &lt;- krige(value ~ x + y, data, grd, model = vfit_universal)\n\n[using universal kriging]\n\n# Visualización\nspplot(kriged_values_universal[\"var1.pred\"], main = \"Kriging Universal Prediction\")"
  },
  {
    "objectID": "intro_spatial.html",
    "href": "intro_spatial.html",
    "title": "Cudernos de Estadística Espacial",
    "section": "",
    "text": "En los siguientes cuadernos encontrará ejemplos con código sobre estadística espacial escalar y funcional. Para poder correr todos los ejemplos clone el repositorio de la siguiente forma. Debe tener instalado previamente git en su computador.\ngit clone --branch gh-pages  https://github.com/mpbohorquezc/SpatFD-Functional-Geostatistics.git \nSi esta corriendo sobre Ubuntu o Mint es importante tener algunos compiladores previamente instalados para poder instanciar algunas de las librerías. En general con los siguientes comandos podría correr cualquiera de los cuadernos sin problema\nsudo apt-get install r-base-dev\nsudo apt install liblapack-dev libopenblas-dev\nSi alguna dependencia hace falta algunos repositorios los puede descargar e instalar a manera de archivo .tar.gz o se encuentran simplemente en los repositorios del CRAN."
  },
  {
    "objectID": "gfdata.html",
    "href": "gfdata.html",
    "title": "gfdata",
    "section": "",
    "text": "Los objetos de clase gfdata son una extensión de los objetos SpatFD para mediciones repetidas, combinan coordenadas espaciales con funciones o series temporales observadas en cada ubicación espacial. Aunque el término “serie temporal” es genérico, las observaciones también pueden estar distribuidas según la frecuencia, profundidad u otra dimensión espacial, en lugar de tiempo."
  },
  {
    "objectID": "gfdata.html#descripción",
    "href": "gfdata.html#descripción",
    "title": "gfdata",
    "section": "",
    "text": "Los objetos de clase gfdata son una extensión de los objetos SpatFD para mediciones repetidas, combinan coordenadas espaciales con funciones o series temporales observadas en cada ubicación espacial. Aunque el término “serie temporal” es genérico, las observaciones también pueden estar distribuidas según la frecuencia, profundidad u otra dimensión espacial, en lugar de tiempo."
  },
  {
    "objectID": "gfdata.html#argumentos",
    "href": "gfdata.html#argumentos",
    "title": "gfdata",
    "section": "Argumentos",
    "text": "Argumentos\n\ndata: Matriz que contiene los datos, donde cada columna corresponde a un sujeto, y las filas representan una secuencia de puntos de datos (ordenados según el tiempo, frecuencia, profundidad, etc.). La última columna debe incluir las clases para clasificación.\np: Número de repeticiones para cada clase.\nbasis: Tipo de funciones base a utilizar. Puede ser “Fourier” o “Bsplines” (predeterminado es “Bsplines”).\ncoords: Matriz con las coordenadas espaciales (x, y).\nnbasis: Número de funciones base.\nnames: Nombres de las clases de datos.\nlambda: Valor del parámetro de suavizado."
  },
  {
    "objectID": "gfdata.html#detalles",
    "href": "gfdata.html#detalles",
    "title": "gfdata",
    "section": "Detalles",
    "text": "Detalles\nLos objetos de clase gfdata almacenan los datos funcionales, sus parámetros, los resultados del análisis de componentes principales funcionales (PCA funcional), y las coordenadas espaciales para cada variable. Cada variable tiene su propio conjunto de datos funcionales, data.frame o matriz, y su correspondiente archivo de coordenadas espaciales.\n\ndata(vowels)\n\n# Definir parámetros y nombres para los datos\np = 228\nnelec = 21\nnvow = 5\nnames_vowels = c(\"a\", \"e\", \"i\", \"o\", \"u\")\nn.basis = c(14, 13, 12, 13, 11)\n\n# Crear el objeto gfdata\ns4.gfdata = gfdata(data = vowels, p = p, names = names_vowels, coords = vowels_coords, nbasis = n.basis)"
  },
  {
    "objectID": "gfdata.html#summary",
    "href": "gfdata.html#summary",
    "title": "gfdata",
    "section": "Summary",
    "text": "Summary\nPara cada variable incluida en el objeto gfdata, esta función devuelve:\n\nHead of data: Muestra las primeras filas de los datos funcionales.\nCoordinates: Muestra las coordenadas espaciales asociadas a las observaciones.\nEigenvalues: Valores propios obtenidos del análisis de componentes principales.\nMean coefficients: Coeficientes medios de las funciones base.\nProportion of explained variance by each component: Proporción de la varianza explicada por cada componente principal.\n\n\n#summary.gfdata(s4.gfdata)"
  },
  {
    "objectID": "GeoestadisticaUnivariadaConGeoR.html",
    "href": "GeoestadisticaUnivariadaConGeoR.html",
    "title": "Geoestadística univariada con geoR",
    "section": "",
    "text": "Lista de librerías con link a la documentación.\n\nfields\ngeoR\nakima Usado para gráficos descriptivos\n\n\nrm(list=ls())\nlibrary(fields)\n\nCargando paquete requerido: spam\n\n\nSpam version 2.11-0 (2024-10-03) is loaded.\nType 'help( Spam)' or 'demo( spam)' for a short introduction \nand overview of this package.\nHelp for individual functions is also obtained by adding the\nsuffix '.spam' to the function name, e.g. 'help( chol.spam)'.\n\n\n\nAdjuntando el paquete: 'spam'\n\n\nThe following objects are masked from 'package:base':\n\n    backsolve, forwardsolve\n\n\nCargando paquete requerido: viridisLite\n\n\n\nTry help(fields) to get started.\n\nlibrary(geoR)\n\n--------------------------------------------------------------\n Analysis of Geostatistical Data\n For an Introduction to geoR go to http://www.leg.ufpr.br/geoR\n geoR version 1.9-4 (built on 2024-02-14) is now loaded\n--------------------------------------------------------------\n\nlibrary(akima)\n\n\n\n\n\naquifer &lt;- read.table(\"data/aquifer.txt\", head = TRUE, dec = \",\")\n\nEncabezado de datos aquifer.txt\n\nhead(aquifer)\n\n       Este     Norte Profundidad\n1  42.78275 127.62282        1464\n2 -27.39691  90.78732        2553\n3  -1.16289  84.89600        2158\n4 -18.61823  76.45199        2455\n5  96.46549  64.58058        1756\n6 108.56243  82.92325        1702\n\n\nSummary de los datos aquifer.txt\n\nsummary(aquifer)\n\n      Este             Norte          Profundidad  \n Min.   :-145.24   Min.   :  9.414   Min.   :1024  \n 1st Qu.: -21.30   1st Qu.: 33.682   1st Qu.:1548  \n Median :  11.66   Median : 59.158   Median :1797  \n Mean   :  16.89   Mean   : 79.361   Mean   :2002  \n 3rd Qu.:  70.90   3rd Qu.:131.825   3rd Qu.:2540  \n Max.   : 112.80   Max.   :184.766   Max.   :3571  \n\n\n\n\n\n\n\n\n\nDocumentación as.geodata\n\n\naquiferg &lt;- as.geodata(aquifer)\nsummary(aquiferg)\n\nNumber of data points: 85 \n\nCoordinates summary\n         Este     Norte\nmin -145.2365   9.41441\nmax  112.8045 184.76636\n\nDistance summary\n        min         max \n  0.2211656 271.0615463 \n\nData summary\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n1024.000 1548.000 1797.000 2002.282 2540.000 3571.000 \n\n\n\n\n\n\nDocumentación plotgeodata\n\nGráfico del objeto geodata\n\nplot(aquiferg, qt.col = c(\"purple\",\n                         \"pink\",\n                         \"green\",\n                         \"yellow\"))\n\n\n\n\n\n\n\n\nGráfico con el parametro 3d\n\nplot(aquiferg, scatter3d = T)\n\n\n\n\n\n\n\n\nGráfico removiendo la tendencia (trend )\n\nplot(aquiferg, trend = \"1st\")\n\n\n\n\n\n\n\n\n\n\n\n\nDocumentación Interpolación inderp\nDocumentación persp\nDocumentación drape.plot\n\n\npar(mfrow = c(2, 2),\n    mar = c(3, 3, 1, 1),\n    mgp = c(2, 1, 0))\n# Esta función agrupa los siguientes gráficos en\n# una matrix 2x2\n\ngrillas &lt;- interp(aquifer$Este,\n                  aquifer$Norte,\n                  aquifer$Profundidad)\n\npersp(grillas$x,\n      grillas$y,\n      grillas$z,\n      xlab = \"Este\",\n      ylab = \"Norte\",\n      zlab = \"Nivel freatico\",\n      phi = 30,\n      theta = 20,\n      col = \"lightblue\",\n      expand = .5,\n      ticktype = \"detailed\")\n\ndrape.plot(grillas$x,\n           grillas$y,\n           grillas$z,\n           xlab = \"Este\",\n           ylab = \"Norte\",\n           zlab = \"z\",\n           theta = 45,\n           col = topo.colors(64),\n           expand = .5,\n           ticktype = \"detailed\")\n\n\ndrape.plot(grillas$x,\n           grillas$y,\n           grillas$z,\n           xlab = \"Este\",\n           ylab = \"Norte\",\n           zlab = \"z\",\n           theta = -10,\n           col = topo.colors(64),\n           expand = .5,\n           ticktype = \"detailed\")\n\n\ndrape.plot(grillas$x,\n           grillas$y,\n           grillas$z,\n           xlab = \"Este\",\n           ylab = \"Norte\",\n           zlab = \"z\",\n           theta = 60,\n           col = topo.colors(64),\n           expand = .5,\n           ticktype = \"detailed\")\n\n\n\n\n\n\n\n\n\n\n\n\nDocumentación contour\nDocumentación filled.contour\n\n\npar(mfrow = c(2, 1),\n    mar = c(1,1,1,1))\n\ncontour(grillas, nlevels = 10, main = \"Contorno\")\nimage(grillas$z, main =  \"Grilla\")\n\n\n\n\n\n\n\n\n\nfilled.contour(grillas, levels = seq(1000,\n                                     5000,\n                                     len = 10),\n               col = heat.colors(10),\n                main = \"grilla niveles\")\n\n\n\n\n\n\n\n\n\n\n\n\nh &lt;- seq(0, 1, len = 50)\nu &lt;- seq(0, 1, len = 50)\n\nejemplo1CH  &lt;- function(h, u, sigma, a, b, c, d, delta) {\n    (sigma^2/((a^2*u^2+c)^(d/2)))*exp(-(b^2*h^2)/(a^2*u^2+c))*exp(-delta*u^2)\n    }\nh &lt;- seq(0, 1, len = 20)\nu &lt;- seq(1, 10, len = 20)\nf &lt;- outer(h, u, ejemplo1CH, sigma=3, a=1, b=3, c=1, d=2, delta=0)\n\npar(mfrow = c(2, 2),\n    mar = c(3, 3, 1, 1),\n    mgp = c(2, 1, 0))\n\ndrape.plot(h,\n           u,\n           f,\n           main = \"Cressie-Huang; 1 (25,1,0.6)\",\n           xlab = \"h\",\n           ylab = \"u\",\n           zlab = \"Covarianza\",\n           ltheta = 75,\n           col = terrain.colors(64))\n\ndrape.plot(h,\n           u,\n           f,\n           main = \"Cressie-Huang; 1 (25,1,0.6)\",\n           xlab = \"h\",\n           ylab = \"u\",\n           zlab = \"Covarianza\",\n           theta = -150,\n           col = terrain.colors(64))\npersp(h,\n      u,\n      f,\n      main = \"Cressie-Huang; 1 (25,1,0.6)\",\n      xlab = \"h\",\n      ylab = \"u\",\n      zlab = \"Covarianza\",\n      ltheta = 75)\n\ncontour(h,\n        u,\n        f,\n        col = topo.colors(10),\n        xlim = c(0,0.6))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nreg1 &lt;- lm(Profundidad ~ Este + Norte, data = aquifer)\nresiduales1  &lt;-  residuals(reg1)\nsummary(reg1)\n\n\nCall:\nlm(formula = Profundidad ~ Este + Norte, data = aquifer)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-366.96 -161.53  -30.71  148.15  651.20 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 2591.4302    38.9599   66.52   &lt;2e-16 ***\nEste          -6.7514     0.3438  -19.64   &lt;2e-16 ***\nNorte         -5.9872     0.4066  -14.73   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 203.3 on 82 degrees of freedom\nMultiple R-squared:  0.8921,    Adjusted R-squared:  0.8894 \nF-statistic: 338.9 on 2 and 82 DF,  p-value: &lt; 2.2e-16\n\nanova(reg1)\n\nAnalysis of Variance Table\n\nResponse: Profundidad\n          Df   Sum Sq  Mean Sq F value    Pr(&gt;F)    \nEste       1 19045642 19045642  460.95 &lt; 2.2e-16 ***\nNorte      1  8960172  8960172  216.86 &lt; 2.2e-16 ***\nResiduals 82  3388069    41318                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\nreg2 &lt;- lm(Profundidad ~ Este + Norte +\n           I(Este^2) + I(Norte^2) +\n           I(Este * Norte),\n           data = aquifer)\nresiduales2  &lt;-  residuals(reg2)\nsummary(reg2)\n\n\nCall:\nlm(formula = Profundidad ~ Este + Norte + I(Este^2) + I(Norte^2) + \n    I(Este * Norte), data = aquifer)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-407.43 -138.76   -5.74  128.84  648.16 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      2.481e+03  6.813e+01  36.424  &lt; 2e-16 ***\nEste            -8.374e+00  5.525e-01 -15.157  &lt; 2e-16 ***\nNorte           -2.043e+00  1.764e+00  -1.159 0.250146    \nI(Este^2)        1.417e-03  4.987e-03   0.284 0.777096    \nI(Norte^2)      -2.464e-02  9.298e-03  -2.650 0.009708 ** \nI(Este * Norte)  2.680e-02  7.413e-03   3.616 0.000526 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 185.9 on 79 degrees of freedom\nMultiple R-squared:  0.9131,    Adjusted R-squared:  0.9076 \nF-statistic:   166 on 5 and 79 DF,  p-value: &lt; 2.2e-16\n\nanova(reg2)\n\nAnalysis of Variance Table\n\nResponse: Profundidad\n                Df   Sum Sq  Mean Sq  F value    Pr(&gt;F)    \nEste             1 19045642 19045642 551.3469 &lt; 2.2e-16 ***\nNorte            1  8960172  8960172 259.3855 &lt; 2.2e-16 ***\nI(Este^2)        1    55368    55368   1.6028 0.2092235    \nI(Norte^2)       1   152170   152170   4.4051 0.0390253 *  \nI(Este * Norte)  1   451567   451567  13.0723 0.0005259 ***\nResiduals       79  2728964    34544                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\nreg3 &lt;- lm(Profundidad ~ Este * Norte,\n           data = aquifer)\nresiduales3  &lt;-  residuals(reg3)\nsummary(reg3)\n\n\nCall:\nlm(formula = Profundidad ~ Este * Norte, data = aquifer)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-406.30 -138.88  -13.04  129.36  722.48 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  2.627e+03  3.833e+01  68.546  &lt; 2e-16 ***\nEste        -8.287e+00  5.658e-01 -14.646  &lt; 2e-16 ***\nNorte       -6.649e+00  4.327e-01 -15.366  &lt; 2e-16 ***\nEste:Norte   2.452e-02  7.401e-03   3.314  0.00138 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 191.9 on 81 degrees of freedom\nMultiple R-squared:  0.905, Adjusted R-squared:  0.9014 \nF-statistic: 257.1 on 3 and 81 DF,  p-value: &lt; 2.2e-16\n\nanova(reg3)\n\nAnalysis of Variance Table\n\nResponse: Profundidad\n           Df   Sum Sq  Mean Sq F value    Pr(&gt;F)    \nEste        1 19045642 19045642  517.06 &lt; 2.2e-16 ***\nNorte       1  8960172  8960172  243.25 &lt; 2.2e-16 ***\nEste:Norte  1   404448   404448   10.98  0.001379 ** \nResiduals  81  2983621    36835                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\nDocumentación variog\n\n\nvari2 &lt;- variog(aquiferg, trend = \"1st\")\n\nvariog: computing omnidirectional variogram\n\nvari2Cloud &lt;- variog(aquiferg, op = \"cloud\", trend = \"1st\")\n\nvariog: computing omnidirectional variogram\n\nvari2BinCloud &lt;- variog(aquiferg,\n                       max.dist = 200,\n                       op = \"cloud\",\n                       bin.cloud = TRUE)\n\nvariog: computing omnidirectional variogram\n\nvari2Sm &lt;- variog(aquiferg,\n                  trend = \"1st\",\n                  op = \"sm\",\n                  band=11)\n\nvariog: computing omnidirectional variogram\n\n\n\npar(mfrow = c(2, 2), mar = c(3, 3, 1, 1), mgp = c(2, 1, 0))\n     plot(vari2$u, vari2$v, main = \"binned variogram\") \n     plot(vari2Cloud$u, vari2Cloud$v, main = \"variogram cloud\")\n     plot(vari2BinCloud$u, vari2BinCloud$v, main = \"clouds for binned variogram\")\n     plot(vari2Sm$u, vari2Sm$v, main = \"smoothed variogram\")\n\n\n\n\n\n\n\n\n\n\n\nvari1 &lt;- variog(aquiferg)\n\nvariog: computing omnidirectional variogram\n\nvari2 &lt;- variog(aquiferg, trend = \"1st\")\n\nvariog: computing omnidirectional variogram\n\nvari3 &lt;- variog(aquiferg, trend = \"2nd\")\n\nvariog: computing omnidirectional variogram\n\n\n\nplot(vari1$u,vari1$v, main = \"Sin remover tendencia\")\n\n\n\n\n\n\n\nplot(vari2$u,vari2$v, main  = \"Trend 1 \")\n\n\n\n\n\n\n\nplot(vari3$u,vari3$v, main  = \"Trend 2 \")\n\n\n\n\n\n\n\n\n\n\n\n\nvari1 &lt;- variog(aquiferg, estimator.type = \"modulus\")\n\nvariog: computing omnidirectional variogram\n\nvari2 &lt;- variog(aquiferg, trend = \"1st\", estimator.type = \"modulus\")\n\nvariog: computing omnidirectional variogram\n\nvari3 &lt;- variog(aquiferg, trend = \"2nd\", estimator.type = \"modulus\")\n\nvariog: computing omnidirectional variogram\n\n\n\nplot(vari1$u,vari1$v, main = \"Sin remover tendencia\")\n\n\n\n\n\n\n\nplot(vari2$u,vari2$v, main  = \"Trend 1 \")\n\n\n\n\n\n\n\nplot(vari3$u,vari3$v, main  = \"Trend 2 \")\n\n\n\n\n\n\n\n\n\n\n\n\nvari_0 &lt;- variog(aquiferg,\n                 trend = \"1st\",\n                 max.dist = 200,\n                 dir = 0)\n\nvariog: computing variogram for direction = 0 degrees (0 radians)\n        tolerance angle = 22.5 degrees (0.393 radians)\n\nvari_45 &lt;- variog(aquiferg,\n                  trend = \"1st\",\n                  max.dist = 200,\n                  dir = pi / 4)\n\nvariog: computing variogram for direction = 45 degrees (0.785 radians)\n        tolerance angle = 22.5 degrees (0.393 radians)\n\nvari_90 &lt;- variog(aquiferg,\n                  trend = \"1st\",\n                  max.dist = 200,\n                  dir = pi / 2)\n\nvariog: computing variogram for direction = 90 degrees (1.571 radians)\n        tolerance angle = 22.5 degrees (0.393 radians)\n\nvari_135 &lt;- variog(aquiferg,\n                   trend = \"1st\",\n                   max.dist = 200,\n                   dir = 3 * pi / 4)\n\nvariog: computing variogram for direction = 135 degrees (2.356 radians)\n        tolerance angle = 22.5 degrees (0.393 radians)\n\npar(mfrow = c(2, 2),\n    mar = c(3, 3, 1, 1),\n    mgp = c(2, 1, 0))\n\nplot(vari_0$u,vari_0$v, main = \"vari 0\")\nplot(vari_45$u,vari_45$v, main = \"vari 45\")\nplot(vari_90$u,vari_90$v, main = \"vari 90\")\nplot(vari_135$u,vari_135$v, main = \"vari 195\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nDocumentación eyefit\nDocumentación variofit\nDocumentación likfit\n\n\nvar1 &lt;- variog(aquiferg,trend=\"1st\",max.dist=200)\n\nvariog: computing omnidirectional variogram\n\n#ini1 &lt;- eyefit(var1)\n#cov.model  sigmasq phi   tausq kappa kappa2   practicalRange\n#1      wave 30805.52  13 8984.94  &lt;NA&gt;   &lt;NA&gt; 38.8889336320589\nini1 &lt;- c(30805.52, 13)\nfitvar1 &lt;- variofit(var1,\n                    cov.model = \"wave\",\n                    ini1,\n                    fix.nugget = TRUE,\n                    nugget = 8984.94,\n                    wei = \"equal\")\n\nvariofit: covariance model used is wave \nvariofit: weights used: equal \nvariofit: minimisation function used: optim \n\nfitvar2 &lt;- variofit(var1,\n                    cov.model = \"wave\",\n                    ini1,\n                    fix.nugget = TRUE,\n                    nugget = 8984.94,\n                    wei = \"npairs\")\n\nvariofit: covariance model used is wave \nvariofit: weights used: npairs \nvariofit: minimisation function used: optim \n\nfitvar3 &lt;- variofit(var1,\n                    ini1,\n                    fix.nugget = TRUE,\n                    nugget = 8984.94,\n                    wei = \"cressie\")\n\nvariofit: covariance model used is matern \nvariofit: weights used: cressie \nvariofit: minimisation function used: optim \n\nfitvar4 &lt;- likfit(aquiferg,\n                  coords = aquiferg$coords,\n                  data = aquiferg$data,\n                  trend = \"1st\",\n                  ini.cov.pars = ini1,\n                  fix.nugget = T,\n                  nugget = 8984.94,\n                  cov.model = \"wave\",\n                  lik.method = \"ML\")\n\nkappa not used for the wave correlation function\n---------------------------------------------------------------\nlikfit: likelihood maximisation using the function optim.\nlikfit: Use control() to pass additional\n         arguments for the maximisation function.\n        For further details see documentation for optim.\nlikfit: It is highly advisable to run this function several\n        times with different initial values for the parameters.\nlikfit: WARNING: This step can be time demanding!\n---------------------------------------------------------------\nlikfit: end of numerical maximisation.\n\nfitvar5 &lt;- likfit(aquiferg,\n                  coords = aquiferg$coords,\n                  data = aquiferg$data,\n                  trend = \"1st\",\n                  ini.cov.pars = ini1,\n                  fix.nugget = T,\n                  nugget = 8984.94,\n                  cov.model = \"wave\",\n                  lik.method = \"REML\")\n\nkappa not used for the wave correlation function\n---------------------------------------------------------------\nlikfit: likelihood maximisation using the function optim.\nlikfit: Use control() to pass additional\n         arguments for the maximisation function.\n        For further details see documentation for optim.\nlikfit: It is highly advisable to run this function several\n        times with different initial values for the parameters.\nlikfit: WARNING: This step can be time demanding!\n---------------------------------------------------------------\nlikfit: end of numerical maximisation.\n\n\n\nplot(var1$u,var1$v,\n     xlab = \"h\",\n     ylab = \"semivarianza\",\n     cex.lab = 1.3,\n     cex.axis = 1.2,\n     main = \"Estimación teórica del modelo de semivariograma\",\n     col.main = 4, cex.main =1.3)\nlines(fitvar1, col = 1)\nlines(fitvar2, col = 2)\nlines(fitvar3, col = 3)\nlines(fitvar4, col = 4)\nlines(fitvar5, col = 5)\nlegend(130, 18000,\n       c(\"MCO\", \"MCPnpairs\", \"MCPcressie\", \"ML\", \"REML\"),\n       lwd = 2,\n       lty = 2:7,\n       col = 2:7,\n       box.col = 9,\n       text.col = 2:7)\n\n\n\n\n\n\n\n\n\n\n\n\n#summary(fitvar1)\n#summary(fitvar2)\n#summary(fitvar3)\n#summary(fitvar4)\n#summary(fitvar5)\n\n\n\n\nEsta es una alternativa al modelamiento de la media cuando los modelos de regresión polinómicos usuales no logran el objetivo de eliminar la tendencia ya sea porque el tipo de tendencia corresponde mas a unas ventanas móviles o porque hay presentes datos atípicos.\n\n\nLista de librerías con link a la documentación.\n\nrm(list=ls())\nlibrary(gstat)\nlibrary(sp)\nlibrary(mvtnorm)\n\n\nAdjuntando el paquete: 'mvtnorm'\n\n\nThe following objects are masked from 'package:spam':\n\n    rmvnorm, rmvt\n\n\n\ngstat\nsp\n\n\n\n\n\nn_x &lt;- 4\nn_y &lt;- 6\nx &lt;- seq(0, 1, len = n_x)\ny &lt;- seq(0, 1, len = n_y)\ncoordenadas &lt;- as.data.frame(expand.grid(x, y))\nnames(coordenadas) &lt;- c(\"X\", \"Y\")\n\nEncabezado coordenadas\n\n\n\nX\nY\n\n\n\n\n0.0000000\n0.0\n\n\n0.3333333\n0.0\n\n\n0.6666667\n0.0\n\n\n1.0000000\n0.0\n\n\n0.0000000\n0.2\n\n\n0.3333333\n0.2\n\n\n\n\n\n\nEsto define un objeto vgm que es el tipo de objeto que usa el paquete gstat para los modelos teóricos de variograma. Con este objeto se pueden definir modelos anidados.\n\nvgm\n\n\nvario &lt;- vgm(10, # Punto de silla\n             \"Exp\", # Modelo, ver documentación\n             0.5)  # Rango\nprint(vario)\n\n  model psill range\n1   Exp    10   0.5\n\n\n\n\n\n\nvgmArea\ncoordinates\n\n\ncoordinates(coordenadas) &lt;- ~X + Y\n#class(coordenadas) # Cambio de objedto dataframe a sp\n\n\ncov_mat &lt;- vgmArea(coordenadas, # Matriz de ubiaciones SP\n        vgm = vario) # VGM object\n\nprint(dim(cov_mat))\n\n[1] 24 24\n\n\n\n\n\nSimulación dada la media y la matriz de varianza\n\nmu  &lt;- rep(0, n_x * n_y) # Media del proceso\nsimu &lt;- rmvnorm(1,\n                mean = mu,\n                sigma = cov_mat)\nprint(simu[1:5])\n\n[1]  0.3720653  4.1971497  3.3336331  3.1950061 -0.7517423\n\n\n\n\n\nUnir las coordenadas con la columna de simulación\n\ndata &lt;- as.data.frame(cbind(coordenadas@coords,\n                            Simula = t(simu)))\nnames(data) &lt;- c(\"X\", \"Y\", \"Var\")\nprint(head(data))\n\n          X   Y        Var\n1 0.0000000 0.0  0.3720653\n2 0.3333333 0.0  4.1971497\n3 0.6666667 0.0  3.3336331\n4 1.0000000 0.0  3.1950061\n5 0.0000000 0.2 -0.7517423\n6 0.3333333 0.2  5.9296301\n\n\nReshape para matriz, esto transforma la tabla de datos en matriz\n\ntabla &lt;- reshape2::dcast(data,\n                         X ~ Y,\n                         value.var = \"Var\")\nrownames(tabla) &lt;- tabla[, 1]\ntabla &lt;- tabla[, c(-1)]\nprint(tabla)\n\n                          0        0.2       0.4       0.6       0.8          1\n0                 0.3720653 -0.7517423 0.2332209 -1.449911 -1.564889 -1.0484684\n0.333333333333333 4.1971497  5.9296301 2.9753045  8.577112  1.388929  0.6956084\n0.666666666666667 3.3336331  2.9183525 3.8052988  4.158139  6.448563  5.9056287\n1                 3.1950061  1.9372674 3.1493069  6.759089  1.524677  1.5311836\n\n\nPulimiento de medianas de la tabla\n\nmed &lt;- medpolish(tabla)\n\n1: 28.9252\n2: 26.10114\n3: 25.71408\nFinal: 25.7125\n\n\n\ngeo_data &lt;- reshape2::melt(med$residuals)\nprint(med)\n\n\nMedian Polish Results (Dataset: \"tabla\")\n\nOverall: 2.84403\n\nRow Effects:\n                0 0.333333333333333 0.666666666666667                 1 \n       -3.1148691         0.2208515         0.5177958        -0.2208515 \n\nColumn Effects:\n         0        0.2        0.4        0.6        0.8          1 \n 0.6073662 -0.4621881  0.4737667  2.4661122 -1.1962754 -0.9348120 \n\nResiduals:\n                          0       0.2       0.4     0.6       0.8        1\n0                  0.035538 -0.018715  0.030294 -3.6452 -0.097774  0.15718\n0.333333333333333  0.524902  3.326937 -0.563344  3.0461 -0.479677 -1.43446\n0.666666666666667 -0.635559  0.018715 -0.030294 -1.6698  4.283013  3.47862\n1                 -0.035538 -0.223723  0.052362  1.6698  0.097774 -0.15718\n\n\nReshape de los datos, con efecto de la fila y la columna\n\ntabla_residuales &lt;- as.data.frame(med$residuals)\nnames(tabla_residuales) &lt;- med$col\nrownames(tabla_residuales) &lt;- med$row\ngeo_data &lt;- reshape2::melt(as.matrix(tabla_residuales))\n\ngeo_data &lt;- cbind(data,\n                  geo_data,\n                  med$overall)\nnames(geo_data) &lt;- c(\"X\",\n                     \"Y\",\n                     \"Var\",\n                     \"Efecto fila\",\n                     \"Efecto columa\",\n                     \"Residual\",\n                     \"Efecto Global\")\nprint(geo_data)\n\n           X   Y        Var Efecto fila Efecto columa    Residual Efecto Global\n1  0.0000000 0.0  0.3720653  -3.1148691     0.6073662  0.03553839       2.84403\n2  0.3333333 0.0  4.1971497   0.2208515     0.6073662  0.52490213       2.84403\n3  0.6666667 0.0  3.3336331   0.5177958     0.6073662 -0.63555871       2.84403\n4  1.0000000 0.0  3.1950061  -0.2208515     0.6073662 -0.03553839       2.84403\n5  0.0000000 0.2 -0.7517423  -3.1148691    -0.4621881 -0.01871497       2.84403\n6  0.3333333 0.2  5.9296301   0.2208515    -0.4621881  3.32693684       2.84403\n7  0.6666667 0.2  2.9183525   0.5177958    -0.4621881  0.01871497       2.84403\n8  1.0000000 0.2  1.9372674  -0.2208515    -0.4621881 -0.22372281       2.84403\n9  0.0000000 0.4  0.2332209  -3.1148691     0.4737667  0.03029352       2.84403\n10 0.3333333 0.4  2.9753045   0.2208515     0.4737667 -0.56334354       2.84403\n11 0.6666667 0.4  3.8052988   0.5177958     0.4737667 -0.03029352       2.84403\n12 1.0000000 0.4  3.1493069  -0.2208515     0.4737667  0.05236182       2.84403\n13 0.0000000 0.6 -1.4499113  -3.1148691     2.4661122 -3.64518426       2.84403\n14 0.3333333 0.6  8.5771124   0.2208515     2.4661122  3.04611888       2.84403\n15 0.6666667 0.6  4.1581392   0.5177958     2.4661122 -1.66979863       2.84403\n16 1.0000000 0.6  6.7590892  -0.2208515     2.4661122  1.66979863       2.84403\n17 0.0000000 0.8 -1.5648888  -3.1148691    -1.1962754 -0.09777411       2.84403\n18 0.3333333 0.8  1.3889292   0.2208515    -1.1962754 -0.47967672       2.84403\n19 0.6666667 0.8  6.4485628   0.5177958    -1.1962754  4.28301258       2.84403\n20 1.0000000 0.8  1.5246770  -0.2208515    -1.1962754  0.09777411       2.84403\n21 0.0000000 1.0 -1.0484684  -3.1148691    -0.9348120  0.15718281       2.84403\n22 0.3333333 1.0  0.6956084   0.2208515    -0.9348120 -1.43446102       2.84403\n23 0.6666667 1.0  5.9056287   0.5177958    -0.9348120  3.47861503       2.84403\n24 1.0000000 1.0  1.5311836  -0.2208515    -0.9348120 -0.15718281       2.84403\n\n\nValidación de la descomposición\n\nvalida &lt;- cbind(geo_data$Var,\n                geo_data[[\"Efecto fila\"]] +\n                geo_data[[\"Efecto columa\"]] +\n                geo_data[[\"Residual\"]] +\n                geo_data[[\"Efecto Global\"]])\nvalida &lt;- as.data.frame(valida)\nnames(valida) &lt;- c(\"datos\", \"suma\")\nprint(valida)\n\n        datos       suma\n1   0.3720653  0.3720653\n2   4.1971497  4.1971497\n3   3.3336331  3.3336331\n4   3.1950061  3.1950061\n5  -0.7517423 -0.7517423\n6   5.9296301  5.9296301\n7   2.9183525  2.9183525\n8   1.9372674  1.9372674\n9   0.2332209  0.2332209\n10  2.9753045  2.9753045\n11  3.8052988  3.8052988\n12  3.1493069  3.1493069\n13 -1.4499113 -1.4499113\n14  8.5771124  8.5771124\n15  4.1581392  4.1581392\n16  6.7590892  6.7590892\n17 -1.5648888 -1.5648888\n18  1.3889292  1.3889292\n19  6.4485628  6.4485628\n20  1.5246770  1.5246770\n21 -1.0484684 -1.0484684\n22  0.6956084  0.6956084\n23  5.9056287  5.9056287\n24  1.5311836  1.5311836"
  },
  {
    "objectID": "GeoestadisticaUnivariadaConGeoR.html#parte-descriptiva",
    "href": "GeoestadisticaUnivariadaConGeoR.html#parte-descriptiva",
    "title": "Geoestadística univariada con geoR",
    "section": "",
    "text": "Lista de librerías con link a la documentación.\n\nfields\ngeoR\nakima Usado para gráficos descriptivos\n\n\nrm(list=ls())\nlibrary(fields)\n\nCargando paquete requerido: spam\n\n\nSpam version 2.11-0 (2024-10-03) is loaded.\nType 'help( Spam)' or 'demo( spam)' for a short introduction \nand overview of this package.\nHelp for individual functions is also obtained by adding the\nsuffix '.spam' to the function name, e.g. 'help( chol.spam)'.\n\n\n\nAdjuntando el paquete: 'spam'\n\n\nThe following objects are masked from 'package:base':\n\n    backsolve, forwardsolve\n\n\nCargando paquete requerido: viridisLite\n\n\n\nTry help(fields) to get started.\n\nlibrary(geoR)\n\n--------------------------------------------------------------\n Analysis of Geostatistical Data\n For an Introduction to geoR go to http://www.leg.ufpr.br/geoR\n geoR version 1.9-4 (built on 2024-02-14) is now loaded\n--------------------------------------------------------------\n\nlibrary(akima)\n\n\n\n\n\naquifer &lt;- read.table(\"data/aquifer.txt\", head = TRUE, dec = \",\")\n\nEncabezado de datos aquifer.txt\n\nhead(aquifer)\n\n       Este     Norte Profundidad\n1  42.78275 127.62282        1464\n2 -27.39691  90.78732        2553\n3  -1.16289  84.89600        2158\n4 -18.61823  76.45199        2455\n5  96.46549  64.58058        1756\n6 108.56243  82.92325        1702\n\n\nSummary de los datos aquifer.txt\n\nsummary(aquifer)\n\n      Este             Norte          Profundidad  \n Min.   :-145.24   Min.   :  9.414   Min.   :1024  \n 1st Qu.: -21.30   1st Qu.: 33.682   1st Qu.:1548  \n Median :  11.66   Median : 59.158   Median :1797  \n Mean   :  16.89   Mean   : 79.361   Mean   :2002  \n 3rd Qu.:  70.90   3rd Qu.:131.825   3rd Qu.:2540  \n Max.   : 112.80   Max.   :184.766   Max.   :3571"
  },
  {
    "objectID": "GeoestadisticaUnivariadaConGeoR.html#geo_data",
    "href": "GeoestadisticaUnivariadaConGeoR.html#geo_data",
    "title": "Geoestadística univariada con geoR",
    "section": "",
    "text": "Documentación as.geodata\n\n\naquiferg &lt;- as.geodata(aquifer)\nsummary(aquiferg)\n\nNumber of data points: 85 \n\nCoordinates summary\n         Este     Norte\nmin -145.2365   9.41441\nmax  112.8045 184.76636\n\nDistance summary\n        min         max \n  0.2211656 271.0615463 \n\nData summary\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n1024.000 1548.000 1797.000 2002.282 2540.000 3571.000 \n\n\n\n\n\n\nDocumentación plotgeodata\n\nGráfico del objeto geodata\n\nplot(aquiferg, qt.col = c(\"purple\",\n                         \"pink\",\n                         \"green\",\n                         \"yellow\"))\n\n\n\n\n\n\n\n\nGráfico con el parametro 3d\n\nplot(aquiferg, scatter3d = T)\n\n\n\n\n\n\n\n\nGráfico removiendo la tendencia (trend )\n\nplot(aquiferg, trend = \"1st\")\n\n\n\n\n\n\n\n\n\n\n\n\nDocumentación Interpolación inderp\nDocumentación persp\nDocumentación drape.plot\n\n\npar(mfrow = c(2, 2),\n    mar = c(3, 3, 1, 1),\n    mgp = c(2, 1, 0))\n# Esta función agrupa los siguientes gráficos en\n# una matrix 2x2\n\ngrillas &lt;- interp(aquifer$Este,\n                  aquifer$Norte,\n                  aquifer$Profundidad)\n\npersp(grillas$x,\n      grillas$y,\n      grillas$z,\n      xlab = \"Este\",\n      ylab = \"Norte\",\n      zlab = \"Nivel freatico\",\n      phi = 30,\n      theta = 20,\n      col = \"lightblue\",\n      expand = .5,\n      ticktype = \"detailed\")\n\ndrape.plot(grillas$x,\n           grillas$y,\n           grillas$z,\n           xlab = \"Este\",\n           ylab = \"Norte\",\n           zlab = \"z\",\n           theta = 45,\n           col = topo.colors(64),\n           expand = .5,\n           ticktype = \"detailed\")\n\n\ndrape.plot(grillas$x,\n           grillas$y,\n           grillas$z,\n           xlab = \"Este\",\n           ylab = \"Norte\",\n           zlab = \"z\",\n           theta = -10,\n           col = topo.colors(64),\n           expand = .5,\n           ticktype = \"detailed\")\n\n\ndrape.plot(grillas$x,\n           grillas$y,\n           grillas$z,\n           xlab = \"Este\",\n           ylab = \"Norte\",\n           zlab = \"z\",\n           theta = 60,\n           col = topo.colors(64),\n           expand = .5,\n           ticktype = \"detailed\")\n\n\n\n\n\n\n\n\n\n\n\n\nDocumentación contour\nDocumentación filled.contour\n\n\npar(mfrow = c(2, 1),\n    mar = c(1,1,1,1))\n\ncontour(grillas, nlevels = 10, main = \"Contorno\")\nimage(grillas$z, main =  \"Grilla\")\n\n\n\n\n\n\n\n\n\nfilled.contour(grillas, levels = seq(1000,\n                                     5000,\n                                     len = 10),\n               col = heat.colors(10),\n                main = \"grilla niveles\")\n\n\n\n\n\n\n\n\n\n\n\n\nh &lt;- seq(0, 1, len = 50)\nu &lt;- seq(0, 1, len = 50)\n\nejemplo1CH  &lt;- function(h, u, sigma, a, b, c, d, delta) {\n    (sigma^2/((a^2*u^2+c)^(d/2)))*exp(-(b^2*h^2)/(a^2*u^2+c))*exp(-delta*u^2)\n    }\nh &lt;- seq(0, 1, len = 20)\nu &lt;- seq(1, 10, len = 20)\nf &lt;- outer(h, u, ejemplo1CH, sigma=3, a=1, b=3, c=1, d=2, delta=0)\n\npar(mfrow = c(2, 2),\n    mar = c(3, 3, 1, 1),\n    mgp = c(2, 1, 0))\n\ndrape.plot(h,\n           u,\n           f,\n           main = \"Cressie-Huang; 1 (25,1,0.6)\",\n           xlab = \"h\",\n           ylab = \"u\",\n           zlab = \"Covarianza\",\n           ltheta = 75,\n           col = terrain.colors(64))\n\ndrape.plot(h,\n           u,\n           f,\n           main = \"Cressie-Huang; 1 (25,1,0.6)\",\n           xlab = \"h\",\n           ylab = \"u\",\n           zlab = \"Covarianza\",\n           theta = -150,\n           col = terrain.colors(64))\npersp(h,\n      u,\n      f,\n      main = \"Cressie-Huang; 1 (25,1,0.6)\",\n      xlab = \"h\",\n      ylab = \"u\",\n      zlab = \"Covarianza\",\n      ltheta = 75)\n\ncontour(h,\n        u,\n        f,\n        col = topo.colors(10),\n        xlim = c(0,0.6))"
  },
  {
    "objectID": "GeoestadisticaUnivariadaConGeoR.html#modelando-la-media-con-regresión-polinomial",
    "href": "GeoestadisticaUnivariadaConGeoR.html#modelando-la-media-con-regresión-polinomial",
    "title": "Geoestadística univariada con geoR",
    "section": "",
    "text": "reg1 &lt;- lm(Profundidad ~ Este + Norte, data = aquifer)\nresiduales1  &lt;-  residuals(reg1)\nsummary(reg1)\n\n\nCall:\nlm(formula = Profundidad ~ Este + Norte, data = aquifer)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-366.96 -161.53  -30.71  148.15  651.20 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 2591.4302    38.9599   66.52   &lt;2e-16 ***\nEste          -6.7514     0.3438  -19.64   &lt;2e-16 ***\nNorte         -5.9872     0.4066  -14.73   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 203.3 on 82 degrees of freedom\nMultiple R-squared:  0.8921,    Adjusted R-squared:  0.8894 \nF-statistic: 338.9 on 2 and 82 DF,  p-value: &lt; 2.2e-16\n\nanova(reg1)\n\nAnalysis of Variance Table\n\nResponse: Profundidad\n          Df   Sum Sq  Mean Sq F value    Pr(&gt;F)    \nEste       1 19045642 19045642  460.95 &lt; 2.2e-16 ***\nNorte      1  8960172  8960172  216.86 &lt; 2.2e-16 ***\nResiduals 82  3388069    41318                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\nreg2 &lt;- lm(Profundidad ~ Este + Norte +\n           I(Este^2) + I(Norte^2) +\n           I(Este * Norte),\n           data = aquifer)\nresiduales2  &lt;-  residuals(reg2)\nsummary(reg2)\n\n\nCall:\nlm(formula = Profundidad ~ Este + Norte + I(Este^2) + I(Norte^2) + \n    I(Este * Norte), data = aquifer)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-407.43 -138.76   -5.74  128.84  648.16 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      2.481e+03  6.813e+01  36.424  &lt; 2e-16 ***\nEste            -8.374e+00  5.525e-01 -15.157  &lt; 2e-16 ***\nNorte           -2.043e+00  1.764e+00  -1.159 0.250146    \nI(Este^2)        1.417e-03  4.987e-03   0.284 0.777096    \nI(Norte^2)      -2.464e-02  9.298e-03  -2.650 0.009708 ** \nI(Este * Norte)  2.680e-02  7.413e-03   3.616 0.000526 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 185.9 on 79 degrees of freedom\nMultiple R-squared:  0.9131,    Adjusted R-squared:  0.9076 \nF-statistic:   166 on 5 and 79 DF,  p-value: &lt; 2.2e-16\n\nanova(reg2)\n\nAnalysis of Variance Table\n\nResponse: Profundidad\n                Df   Sum Sq  Mean Sq  F value    Pr(&gt;F)    \nEste             1 19045642 19045642 551.3469 &lt; 2.2e-16 ***\nNorte            1  8960172  8960172 259.3855 &lt; 2.2e-16 ***\nI(Este^2)        1    55368    55368   1.6028 0.2092235    \nI(Norte^2)       1   152170   152170   4.4051 0.0390253 *  \nI(Este * Norte)  1   451567   451567  13.0723 0.0005259 ***\nResiduals       79  2728964    34544                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\nreg3 &lt;- lm(Profundidad ~ Este * Norte,\n           data = aquifer)\nresiduales3  &lt;-  residuals(reg3)\nsummary(reg3)\n\n\nCall:\nlm(formula = Profundidad ~ Este * Norte, data = aquifer)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-406.30 -138.88  -13.04  129.36  722.48 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  2.627e+03  3.833e+01  68.546  &lt; 2e-16 ***\nEste        -8.287e+00  5.658e-01 -14.646  &lt; 2e-16 ***\nNorte       -6.649e+00  4.327e-01 -15.366  &lt; 2e-16 ***\nEste:Norte   2.452e-02  7.401e-03   3.314  0.00138 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 191.9 on 81 degrees of freedom\nMultiple R-squared:  0.905, Adjusted R-squared:  0.9014 \nF-statistic: 257.1 on 3 and 81 DF,  p-value: &lt; 2.2e-16\n\nanova(reg3)\n\nAnalysis of Variance Table\n\nResponse: Profundidad\n           Df   Sum Sq  Mean Sq F value    Pr(&gt;F)    \nEste        1 19045642 19045642  517.06 &lt; 2.2e-16 ***\nNorte       1  8960172  8960172  243.25 &lt; 2.2e-16 ***\nEste:Norte  1   404448   404448   10.98  0.001379 ** \nResiduals  81  2983621    36835                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "GeoestadisticaUnivariadaConGeoR.html#estimación-del-semivariograma-empírico",
    "href": "GeoestadisticaUnivariadaConGeoR.html#estimación-del-semivariograma-empírico",
    "title": "Geoestadística univariada con geoR",
    "section": "",
    "text": "Documentación variog\n\n\nvari2 &lt;- variog(aquiferg, trend = \"1st\")\n\nvariog: computing omnidirectional variogram\n\nvari2Cloud &lt;- variog(aquiferg, op = \"cloud\", trend = \"1st\")\n\nvariog: computing omnidirectional variogram\n\nvari2BinCloud &lt;- variog(aquiferg,\n                       max.dist = 200,\n                       op = \"cloud\",\n                       bin.cloud = TRUE)\n\nvariog: computing omnidirectional variogram\n\nvari2Sm &lt;- variog(aquiferg,\n                  trend = \"1st\",\n                  op = \"sm\",\n                  band=11)\n\nvariog: computing omnidirectional variogram\n\n\n\npar(mfrow = c(2, 2), mar = c(3, 3, 1, 1), mgp = c(2, 1, 0))\n     plot(vari2$u, vari2$v, main = \"binned variogram\") \n     plot(vari2Cloud$u, vari2Cloud$v, main = \"variogram cloud\")\n     plot(vari2BinCloud$u, vari2BinCloud$v, main = \"clouds for binned variogram\")\n     plot(vari2Sm$u, vari2Sm$v, main = \"smoothed variogram\")\n\n\n\n\n\n\n\n\n\n\n\nvari1 &lt;- variog(aquiferg)\n\nvariog: computing omnidirectional variogram\n\nvari2 &lt;- variog(aquiferg, trend = \"1st\")\n\nvariog: computing omnidirectional variogram\n\nvari3 &lt;- variog(aquiferg, trend = \"2nd\")\n\nvariog: computing omnidirectional variogram\n\n\n\nplot(vari1$u,vari1$v, main = \"Sin remover tendencia\")\n\n\n\n\n\n\n\nplot(vari2$u,vari2$v, main  = \"Trend 1 \")\n\n\n\n\n\n\n\nplot(vari3$u,vari3$v, main  = \"Trend 2 \")\n\n\n\n\n\n\n\n\n\n\n\n\nvari1 &lt;- variog(aquiferg, estimator.type = \"modulus\")\n\nvariog: computing omnidirectional variogram\n\nvari2 &lt;- variog(aquiferg, trend = \"1st\", estimator.type = \"modulus\")\n\nvariog: computing omnidirectional variogram\n\nvari3 &lt;- variog(aquiferg, trend = \"2nd\", estimator.type = \"modulus\")\n\nvariog: computing omnidirectional variogram\n\n\n\nplot(vari1$u,vari1$v, main = \"Sin remover tendencia\")\n\n\n\n\n\n\n\nplot(vari2$u,vari2$v, main  = \"Trend 1 \")\n\n\n\n\n\n\n\nplot(vari3$u,vari3$v, main  = \"Trend 2 \")\n\n\n\n\n\n\n\n\n\n\n\n\nvari_0 &lt;- variog(aquiferg,\n                 trend = \"1st\",\n                 max.dist = 200,\n                 dir = 0)\n\nvariog: computing variogram for direction = 0 degrees (0 radians)\n        tolerance angle = 22.5 degrees (0.393 radians)\n\nvari_45 &lt;- variog(aquiferg,\n                  trend = \"1st\",\n                  max.dist = 200,\n                  dir = pi / 4)\n\nvariog: computing variogram for direction = 45 degrees (0.785 radians)\n        tolerance angle = 22.5 degrees (0.393 radians)\n\nvari_90 &lt;- variog(aquiferg,\n                  trend = \"1st\",\n                  max.dist = 200,\n                  dir = pi / 2)\n\nvariog: computing variogram for direction = 90 degrees (1.571 radians)\n        tolerance angle = 22.5 degrees (0.393 radians)\n\nvari_135 &lt;- variog(aquiferg,\n                   trend = \"1st\",\n                   max.dist = 200,\n                   dir = 3 * pi / 4)\n\nvariog: computing variogram for direction = 135 degrees (2.356 radians)\n        tolerance angle = 22.5 degrees (0.393 radians)\n\npar(mfrow = c(2, 2),\n    mar = c(3, 3, 1, 1),\n    mgp = c(2, 1, 0))\n\nplot(vari_0$u,vari_0$v, main = \"vari 0\")\nplot(vari_45$u,vari_45$v, main = \"vari 45\")\nplot(vari_90$u,vari_90$v, main = \"vari 90\")\nplot(vari_135$u,vari_135$v, main = \"vari 195\")"
  },
  {
    "objectID": "GeoestadisticaUnivariadaConGeoR.html#estimación-teórica-del-semivariograma",
    "href": "GeoestadisticaUnivariadaConGeoR.html#estimación-teórica-del-semivariograma",
    "title": "Geoestadística univariada con geoR",
    "section": "",
    "text": "Documentación eyefit\nDocumentación variofit\nDocumentación likfit\n\n\nvar1 &lt;- variog(aquiferg,trend=\"1st\",max.dist=200)\n\nvariog: computing omnidirectional variogram\n\n#ini1 &lt;- eyefit(var1)\n#cov.model  sigmasq phi   tausq kappa kappa2   practicalRange\n#1      wave 30805.52  13 8984.94  &lt;NA&gt;   &lt;NA&gt; 38.8889336320589\nini1 &lt;- c(30805.52, 13)\nfitvar1 &lt;- variofit(var1,\n                    cov.model = \"wave\",\n                    ini1,\n                    fix.nugget = TRUE,\n                    nugget = 8984.94,\n                    wei = \"equal\")\n\nvariofit: covariance model used is wave \nvariofit: weights used: equal \nvariofit: minimisation function used: optim \n\nfitvar2 &lt;- variofit(var1,\n                    cov.model = \"wave\",\n                    ini1,\n                    fix.nugget = TRUE,\n                    nugget = 8984.94,\n                    wei = \"npairs\")\n\nvariofit: covariance model used is wave \nvariofit: weights used: npairs \nvariofit: minimisation function used: optim \n\nfitvar3 &lt;- variofit(var1,\n                    ini1,\n                    fix.nugget = TRUE,\n                    nugget = 8984.94,\n                    wei = \"cressie\")\n\nvariofit: covariance model used is matern \nvariofit: weights used: cressie \nvariofit: minimisation function used: optim \n\nfitvar4 &lt;- likfit(aquiferg,\n                  coords = aquiferg$coords,\n                  data = aquiferg$data,\n                  trend = \"1st\",\n                  ini.cov.pars = ini1,\n                  fix.nugget = T,\n                  nugget = 8984.94,\n                  cov.model = \"wave\",\n                  lik.method = \"ML\")\n\nkappa not used for the wave correlation function\n---------------------------------------------------------------\nlikfit: likelihood maximisation using the function optim.\nlikfit: Use control() to pass additional\n         arguments for the maximisation function.\n        For further details see documentation for optim.\nlikfit: It is highly advisable to run this function several\n        times with different initial values for the parameters.\nlikfit: WARNING: This step can be time demanding!\n---------------------------------------------------------------\nlikfit: end of numerical maximisation.\n\nfitvar5 &lt;- likfit(aquiferg,\n                  coords = aquiferg$coords,\n                  data = aquiferg$data,\n                  trend = \"1st\",\n                  ini.cov.pars = ini1,\n                  fix.nugget = T,\n                  nugget = 8984.94,\n                  cov.model = \"wave\",\n                  lik.method = \"REML\")\n\nkappa not used for the wave correlation function\n---------------------------------------------------------------\nlikfit: likelihood maximisation using the function optim.\nlikfit: Use control() to pass additional\n         arguments for the maximisation function.\n        For further details see documentation for optim.\nlikfit: It is highly advisable to run this function several\n        times with different initial values for the parameters.\nlikfit: WARNING: This step can be time demanding!\n---------------------------------------------------------------\nlikfit: end of numerical maximisation.\n\n\n\nplot(var1$u,var1$v,\n     xlab = \"h\",\n     ylab = \"semivarianza\",\n     cex.lab = 1.3,\n     cex.axis = 1.2,\n     main = \"Estimación teórica del modelo de semivariograma\",\n     col.main = 4, cex.main =1.3)\nlines(fitvar1, col = 1)\nlines(fitvar2, col = 2)\nlines(fitvar3, col = 3)\nlines(fitvar4, col = 4)\nlines(fitvar5, col = 5)\nlegend(130, 18000,\n       c(\"MCO\", \"MCPnpairs\", \"MCPcressie\", \"ML\", \"REML\"),\n       lwd = 2,\n       lty = 2:7,\n       col = 2:7,\n       box.col = 9,\n       text.col = 2:7)"
  },
  {
    "objectID": "GeoestadisticaUnivariadaConGeoR.html#resultados",
    "href": "GeoestadisticaUnivariadaConGeoR.html#resultados",
    "title": "Geoestadística univariada con geoR",
    "section": "",
    "text": "#summary(fitvar1)\n#summary(fitvar2)\n#summary(fitvar3)\n#summary(fitvar4)\n#summary(fitvar5)"
  },
  {
    "objectID": "GeoestadisticaUnivariadaConGeoR.html#pulimiento-de-medianas",
    "href": "GeoestadisticaUnivariadaConGeoR.html#pulimiento-de-medianas",
    "title": "Geoestadística univariada con geoR",
    "section": "",
    "text": "Esta es una alternativa al modelamiento de la media cuando los modelos de regresión polinómicos usuales no logran el objetivo de eliminar la tendencia ya sea porque el tipo de tendencia corresponde mas a unas ventanas móviles o porque hay presentes datos atípicos.\n\n\nLista de librerías con link a la documentación.\n\nrm(list=ls())\nlibrary(gstat)\nlibrary(sp)\nlibrary(mvtnorm)\n\n\nAdjuntando el paquete: 'mvtnorm'\n\n\nThe following objects are masked from 'package:spam':\n\n    rmvnorm, rmvt\n\n\n\ngstat\nsp\n\n\n\n\n\nn_x &lt;- 4\nn_y &lt;- 6\nx &lt;- seq(0, 1, len = n_x)\ny &lt;- seq(0, 1, len = n_y)\ncoordenadas &lt;- as.data.frame(expand.grid(x, y))\nnames(coordenadas) &lt;- c(\"X\", \"Y\")\n\nEncabezado coordenadas\n\n\n\nX\nY\n\n\n\n\n0.0000000\n0.0\n\n\n0.3333333\n0.0\n\n\n0.6666667\n0.0\n\n\n1.0000000\n0.0\n\n\n0.0000000\n0.2\n\n\n0.3333333\n0.2\n\n\n\n\n\n\nEsto define un objeto vgm que es el tipo de objeto que usa el paquete gstat para los modelos teóricos de variograma. Con este objeto se pueden definir modelos anidados.\n\nvgm\n\n\nvario &lt;- vgm(10, # Punto de silla\n             \"Exp\", # Modelo, ver documentación\n             0.5)  # Rango\nprint(vario)\n\n  model psill range\n1   Exp    10   0.5\n\n\n\n\n\n\nvgmArea\ncoordinates\n\n\ncoordinates(coordenadas) &lt;- ~X + Y\n#class(coordenadas) # Cambio de objedto dataframe a sp\n\n\ncov_mat &lt;- vgmArea(coordenadas, # Matriz de ubiaciones SP\n        vgm = vario) # VGM object\n\nprint(dim(cov_mat))\n\n[1] 24 24\n\n\n\n\n\nSimulación dada la media y la matriz de varianza\n\nmu  &lt;- rep(0, n_x * n_y) # Media del proceso\nsimu &lt;- rmvnorm(1,\n                mean = mu,\n                sigma = cov_mat)\nprint(simu[1:5])\n\n[1]  0.3720653  4.1971497  3.3336331  3.1950061 -0.7517423\n\n\n\n\n\nUnir las coordenadas con la columna de simulación\n\ndata &lt;- as.data.frame(cbind(coordenadas@coords,\n                            Simula = t(simu)))\nnames(data) &lt;- c(\"X\", \"Y\", \"Var\")\nprint(head(data))\n\n          X   Y        Var\n1 0.0000000 0.0  0.3720653\n2 0.3333333 0.0  4.1971497\n3 0.6666667 0.0  3.3336331\n4 1.0000000 0.0  3.1950061\n5 0.0000000 0.2 -0.7517423\n6 0.3333333 0.2  5.9296301\n\n\nReshape para matriz, esto transforma la tabla de datos en matriz\n\ntabla &lt;- reshape2::dcast(data,\n                         X ~ Y,\n                         value.var = \"Var\")\nrownames(tabla) &lt;- tabla[, 1]\ntabla &lt;- tabla[, c(-1)]\nprint(tabla)\n\n                          0        0.2       0.4       0.6       0.8          1\n0                 0.3720653 -0.7517423 0.2332209 -1.449911 -1.564889 -1.0484684\n0.333333333333333 4.1971497  5.9296301 2.9753045  8.577112  1.388929  0.6956084\n0.666666666666667 3.3336331  2.9183525 3.8052988  4.158139  6.448563  5.9056287\n1                 3.1950061  1.9372674 3.1493069  6.759089  1.524677  1.5311836\n\n\nPulimiento de medianas de la tabla\n\nmed &lt;- medpolish(tabla)\n\n1: 28.9252\n2: 26.10114\n3: 25.71408\nFinal: 25.7125\n\n\n\ngeo_data &lt;- reshape2::melt(med$residuals)\nprint(med)\n\n\nMedian Polish Results (Dataset: \"tabla\")\n\nOverall: 2.84403\n\nRow Effects:\n                0 0.333333333333333 0.666666666666667                 1 \n       -3.1148691         0.2208515         0.5177958        -0.2208515 \n\nColumn Effects:\n         0        0.2        0.4        0.6        0.8          1 \n 0.6073662 -0.4621881  0.4737667  2.4661122 -1.1962754 -0.9348120 \n\nResiduals:\n                          0       0.2       0.4     0.6       0.8        1\n0                  0.035538 -0.018715  0.030294 -3.6452 -0.097774  0.15718\n0.333333333333333  0.524902  3.326937 -0.563344  3.0461 -0.479677 -1.43446\n0.666666666666667 -0.635559  0.018715 -0.030294 -1.6698  4.283013  3.47862\n1                 -0.035538 -0.223723  0.052362  1.6698  0.097774 -0.15718\n\n\nReshape de los datos, con efecto de la fila y la columna\n\ntabla_residuales &lt;- as.data.frame(med$residuals)\nnames(tabla_residuales) &lt;- med$col\nrownames(tabla_residuales) &lt;- med$row\ngeo_data &lt;- reshape2::melt(as.matrix(tabla_residuales))\n\ngeo_data &lt;- cbind(data,\n                  geo_data,\n                  med$overall)\nnames(geo_data) &lt;- c(\"X\",\n                     \"Y\",\n                     \"Var\",\n                     \"Efecto fila\",\n                     \"Efecto columa\",\n                     \"Residual\",\n                     \"Efecto Global\")\nprint(geo_data)\n\n           X   Y        Var Efecto fila Efecto columa    Residual Efecto Global\n1  0.0000000 0.0  0.3720653  -3.1148691     0.6073662  0.03553839       2.84403\n2  0.3333333 0.0  4.1971497   0.2208515     0.6073662  0.52490213       2.84403\n3  0.6666667 0.0  3.3336331   0.5177958     0.6073662 -0.63555871       2.84403\n4  1.0000000 0.0  3.1950061  -0.2208515     0.6073662 -0.03553839       2.84403\n5  0.0000000 0.2 -0.7517423  -3.1148691    -0.4621881 -0.01871497       2.84403\n6  0.3333333 0.2  5.9296301   0.2208515    -0.4621881  3.32693684       2.84403\n7  0.6666667 0.2  2.9183525   0.5177958    -0.4621881  0.01871497       2.84403\n8  1.0000000 0.2  1.9372674  -0.2208515    -0.4621881 -0.22372281       2.84403\n9  0.0000000 0.4  0.2332209  -3.1148691     0.4737667  0.03029352       2.84403\n10 0.3333333 0.4  2.9753045   0.2208515     0.4737667 -0.56334354       2.84403\n11 0.6666667 0.4  3.8052988   0.5177958     0.4737667 -0.03029352       2.84403\n12 1.0000000 0.4  3.1493069  -0.2208515     0.4737667  0.05236182       2.84403\n13 0.0000000 0.6 -1.4499113  -3.1148691     2.4661122 -3.64518426       2.84403\n14 0.3333333 0.6  8.5771124   0.2208515     2.4661122  3.04611888       2.84403\n15 0.6666667 0.6  4.1581392   0.5177958     2.4661122 -1.66979863       2.84403\n16 1.0000000 0.6  6.7590892  -0.2208515     2.4661122  1.66979863       2.84403\n17 0.0000000 0.8 -1.5648888  -3.1148691    -1.1962754 -0.09777411       2.84403\n18 0.3333333 0.8  1.3889292   0.2208515    -1.1962754 -0.47967672       2.84403\n19 0.6666667 0.8  6.4485628   0.5177958    -1.1962754  4.28301258       2.84403\n20 1.0000000 0.8  1.5246770  -0.2208515    -1.1962754  0.09777411       2.84403\n21 0.0000000 1.0 -1.0484684  -3.1148691    -0.9348120  0.15718281       2.84403\n22 0.3333333 1.0  0.6956084   0.2208515    -0.9348120 -1.43446102       2.84403\n23 0.6666667 1.0  5.9056287   0.5177958    -0.9348120  3.47861503       2.84403\n24 1.0000000 1.0  1.5311836  -0.2208515    -0.9348120 -0.15718281       2.84403\n\n\nValidación de la descomposición\n\nvalida &lt;- cbind(geo_data$Var,\n                geo_data[[\"Efecto fila\"]] +\n                geo_data[[\"Efecto columa\"]] +\n                geo_data[[\"Residual\"]] +\n                geo_data[[\"Efecto Global\"]])\nvalida &lt;- as.data.frame(valida)\nnames(valida) &lt;- c(\"datos\", \"suma\")\nprint(valida)\n\n        datos       suma\n1   0.3720653  0.3720653\n2   4.1971497  4.1971497\n3   3.3336331  3.3336331\n4   3.1950061  3.1950061\n5  -0.7517423 -0.7517423\n6   5.9296301  5.9296301\n7   2.9183525  2.9183525\n8   1.9372674  1.9372674\n9   0.2332209  0.2332209\n10  2.9753045  2.9753045\n11  3.8052988  3.8052988\n12  3.1493069  3.1493069\n13 -1.4499113 -1.4499113\n14  8.5771124  8.5771124\n15  4.1581392  4.1581392\n16  6.7590892  6.7590892\n17 -1.5648888 -1.5648888\n18  1.3889292  1.3889292\n19  6.4485628  6.4485628\n20  1.5246770  1.5246770\n21 -1.0484684 -1.0484684\n22  0.6956084  0.6956084\n23  5.9056287  5.9056287\n24  1.5311836  1.5311836"
  },
  {
    "objectID": "cokriging.html",
    "href": "cokriging.html",
    "title": "Cokriging",
    "section": "",
    "text": "El cokriging es una extensión del kriging que permite predecir una variable en una ubicación no muestreada utilizando no solo datos de esa misma variable, sino también información de otras variables relacionadas o covariables. Este método aprovecha la correlación espacial entre varias variables para mejorar la precisión de las predicciones.\nSupongamos que queremos hacer la predicción tomando en cuenta \\(p\\) variables de forma simultánea. Considerando \\(Z(s_i) = (Z_1(s_i),Z_2(s_i),\\cdots,Z_p(s_i))'\\) , el predictor para \\(Z_l(s_0), 1\\leq l\\leq p\\) basado en p, basado en las \\(p\\) variables tiene la forma\n\\[\nZ^*_l(s_0) = \\sum_{i=1}^n \\sum_{q=1}^p \\lambda_{qi}Z_q(s_i)\n\\]\nEl mejor predictor lineal insesgado de una variable en la ubicación \\(s_0\\) está dado por la minimización de\n\\[\nmax_{1\\leq l \\leq n}\\{Var[Z_l(s_0)-Z^*_l(s_0)]\\}\n\\]\nPor eficiencia computacional, puede decidirse minimizar\n\\[\n\\sum_{i=1}^nVar[Z_l(s_0)-Z^*_l(s_0)]\n\\]\nEn el paquete SpatFD se realiza cokriging sobre los scores elegidos para todas las variables funcionales involucradas. Las predicciones de scores se utilizan para construir el predictor funcional del cokriging.\n\ndata(COKMexico)\n# Definimos nuestro objeto SpatFD\nSFD_PM10_NO2 &lt;- SpatFD(Mex_PM10, coords = coord_PM10, basis = \"Fourier\", \nnbasis = 21, lambda = 0.000001, nharm = 2)\n# Agregamos las observaciones de NO2 al objeto que creamos antes por medio del argumento add\nSFD_PM10_NO2 &lt;- SpatFD(NO2, coords = coord_NO2, basis = \"Fourier\", \nnbasis = 27, lambda = 0.000001, nharm = 2,\n                      add = SFD_PM10_NO2)\n# Definimos los modelos de varianza de cada una de las variables\nmodel1 &lt;- gstat::vgm(647677.1,\"Gau\",23317.05)\nmodel1 &lt;- gstat::vgm(127633,\"Wav\",9408.63, add.to = model1)\n\n# Especificamos la ubicación no muestreada\nnewcoords &lt;- data.frame(x = 509926, y = 2179149)\n\nLa función COKS_scores_lambdas nos permite hacer el cokriging funcional\n\ncokrig = COKS_scores_lambdas(SFD_PM10_NO2, newcoords, model1)\n\nUsing fill.all = TRUE by default\n\n\nUsing method = 'lambda' by default\n\n\n\n\n\n\n\n\n\nLinear Model of Coregionalization found. Good.\n[using ordinary cokriging]\n\n\n\ncokrig$modelfit\n\ndata:\nPC1.1 : formula = puntajes[[1]][[1]]`~`1 ; data dim = 13 x 2\nPC2.1 : formula = puntajes[[1]][[2]]`~`1 ; data dim = 13 x 2\nPC1.2 : formula = puntajes[[2]][[1]]`~`1 ; data dim = 18 x 2\nPC2.2 : formula = puntajes[[2]][[2]]`~`1 ; data dim = 18 x 2\nvariograms:\n               model      psill    range\nPC1.1[1]         Gau 356886.232 23317.05\nPC1.1[2]         Wav 251618.187  9408.63\nPC2.1[1]         Gau 157275.294 23317.05\nPC2.1[2]         Wav  66770.748  9408.63\nPC1.2[1]         Gau 509628.594 23317.05\nPC1.2[2]         Wav  86045.557  9408.63\nPC2.2[1]         Gau   9178.223 23317.05\nPC2.2[2]         Wav  77729.767  9408.63\nPC1.1.PC2.1[1]   Gau  96771.742 23317.05\nPC1.1.PC2.1[2]   Wav -11290.879  9408.63\nPC1.1.PC1.2[1]   Gau 358697.498 23317.05\nPC1.1.PC1.2[2]   Wav  84592.302  9408.63\nPC2.1.PC1.2[1]   Gau -36478.239 23317.05\nPC2.1.PC1.2[2]   Wav  57029.144  9408.63\nPC1.1.PC2.2[1]   Gau  11668.546 23317.05\nPC1.1.PC2.2[2]   Wav 137897.759  9408.63\nPC2.1.PC2.2[1]   Gau  -1677.278 23317.05\nPC2.1.PC2.2[2]   Wav -12680.551  9408.63\nPC1.2.PC2.2[1]   Gau  16583.870 23317.05\nPC1.2.PC2.2[2]   Wav  40857.282  9408.63\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "classification.html",
    "href": "classification.html",
    "title": "Clasificación",
    "section": "",
    "text": "Esta función clasifica nuevos datos funcionales basándose en los resultados del PCA de los datos de entrenamiento."
  },
  {
    "objectID": "classification.html#descripción",
    "href": "classification.html#descripción",
    "title": "Clasificación",
    "section": "",
    "text": "Esta función clasifica nuevos datos funcionales basándose en los resultados del PCA de los datos de entrenamiento."
  },
  {
    "objectID": "classification.html#uso",
    "href": "classification.html#uso",
    "title": "Clasificación",
    "section": "Uso",
    "text": "Uso\nclassification(data.train.pca, new.basis, k, distance, mcov = NULL)"
  },
  {
    "objectID": "classification.html#argumentos",
    "href": "classification.html#argumentos",
    "title": "Clasificación",
    "section": "Argumentos",
    "text": "Argumentos\n\ndata.train.pca: Una lista de resultados de PCA a partir de los datos de entrenamiento.\nnew.basis: Objeto de base a partir de los datos de prueba.\nk: Número de vecinos más cercanos a considerar para la clasificación.\ndistance: Tipo de distancia a utilizar (por ejemplo, “euclidiana”, “mahalanobis”).\nmcov: Matrices de covarianza opcionales para la distancia de Mahalanobis."
  },
  {
    "objectID": "classification.html#valor",
    "href": "classification.html#valor",
    "title": "Clasificación",
    "section": "Valor",
    "text": "Valor\nLa función devuelve la clase predicha para los nuevos datos."
  },
  {
    "objectID": "classification.html#detalles",
    "href": "classification.html#detalles",
    "title": "Clasificación",
    "section": "Detalles",
    "text": "Detalles\nEl proceso de clasificación utiliza los resultados del PCA sobre los datos de entrenamiento para clasificar nuevos puntos de datos. Emplea un algoritmo de k vecinos más cercanos, donde la métrica de distancia puede ser especificada por el usuario."
  },
  {
    "objectID": "classification.html#ejemplos",
    "href": "classification.html#ejemplos",
    "title": "Clasificación",
    "section": "Ejemplos",
    "text": "Ejemplos\ndata(vowels)\n#### Crear parámetros y nombres para los datos.\np = 228 ; nelec = 21 ; nvow = 5\nnames_vowels = c(\"a\",\"e\",\"i\",\"o\",\"u\")\nn.basis &lt;- c(14, 13, 12, 13, 11)\ns4.gfdata = gfdata(data = vowels, p = p, names = names_vowels, coords = vowels_coords, nbasis = n.basis)\n\n# Crear datos de entrenamiento y prueba\ns4.sep = gfd_clasif_data(s4.gfdata, 0.8, seed = 2910)\ns4.train = s4.sep$train\ns4.test = s4.sep$test\n\n# Clasificación\ncla &lt;- classification(data.train.pca = s4.train,\n                      new.basis = s4.test[[1]]$data_fd[[1]],\n                      k = 4,\n                      distance = 'euclidean',\n                      mcov = mcov)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "SpatFD es un paquete en R diseñado para facilitar el análisis de datos espaciales con componentes funcionales. Proporciona herramientas para manejar datos funcionales espaciales, permitiendo a investigadores y analistas explorar, modelar y visualizar de manera eficiente la variabilidad y dependencias espaciales en conjuntos de datos complejos.\nNuestro paquete está pensado para soportar una amplia gama de aplicaciones, desde estudios ambientales hasta econometría, ofreciendo métodos adaptables a diversos dominios. Ya sea que estés trabajando con tendencias geoespaciales, dinámicas temporales o relaciones funcionales, SpatFD te brinda la flexibilidad y las herramientas necesarias para extraer conclusiones significativas.\nSpatFD ha sido desarrollado con un enfoque en la usabilidad y el rendimiento, asegurando que tanto usuarios novatos como experimentados de R puedan aprovechar sus capacidades para realizar investigaciones avanzadas en estadística espacial. Únete a nuestra creciente comunidad de usuarios y explora el potencial de los datos funcionales espaciales con SpatFD."
  },
  {
    "objectID": "about.html#referencias",
    "href": "about.html#referencias",
    "title": "About",
    "section": "Referencias",
    "text": "Referencias\n\nBohorquez, M., Giraldo, R., & Mateu, J. (2016). Optimal sampling for spatial prediction of functional data. Statistical Methods & Applications, 25(1), 39-54.\nBohorquez, M., Giraldo, R., & Mateu, J. (2016). Multivariate functional random fields: prediction and optimal sampling. Stochastic Environmental Research and Risk Assessment, 31, pages53–70 (2017).\nBohorquez M., Giraldo R. and Mateu J. (2021). Spatial prediction and optimal sampling of functional data in Geostatistical Functional Data Analysis: Theory and Methods. John Wiley Sons, Chichester, UK. ISBN: 978-1-119-38784-8. https://www.wiley.com/en-us/Geostatistical+Functional+Data+Analysis-p-9781119387848."
  },
  {
    "objectID": "airqualitybogota.html",
    "href": "airqualitybogota.html",
    "title": "AirQualityBogota",
    "section": "",
    "text": "El conjunto de datos AirQualityBogota contiene información sobre la calidad del aire en Bogotá, Colombia. Específicamente, incluye mediciones de material particulado 10 (PM10) recolectadas en 10 estaciones de monitoreo distribuidas por la ciudad. Al cargar los datos encontrará en el ambiente\n\ncoord: Un DataFrame con los nombres y coordenadas de cada una de las estaciones de monitoreo.\nmap: Un objeto del tipo sf que contiene el mapa de Bogotá.\nPM10: Contiene las observaciones de PM10 de cada estación.\n\n\n\nEl PM10 se refiere a partículas de materia en el aire con un diámetro de 10 micrómetros o menos. Estas partículas son lo suficientemente pequeñas como para ser inhaladas y pueden tener efectos negativos en la salud humana, especialmente en los sistemas respiratorio y cardiovascular."
  },
  {
    "objectID": "airqualitybogota.html#descripción",
    "href": "airqualitybogota.html#descripción",
    "title": "AirQualityBogota",
    "section": "",
    "text": "El conjunto de datos AirQualityBogota contiene información sobre la calidad del aire en Bogotá, Colombia. Específicamente, incluye mediciones de material particulado 10 (PM10) recolectadas en 10 estaciones de monitoreo distribuidas por la ciudad. Al cargar los datos encontrará en el ambiente\n\ncoord: Un DataFrame con los nombres y coordenadas de cada una de las estaciones de monitoreo.\nmap: Un objeto del tipo sf que contiene el mapa de Bogotá.\nPM10: Contiene las observaciones de PM10 de cada estación.\n\n\n\nEl PM10 se refiere a partículas de materia en el aire con un diámetro de 10 micrómetros o menos. Estas partículas son lo suficientemente pequeñas como para ser inhaladas y pueden tener efectos negativos en la salud humana, especialmente en los sistemas respiratorio y cardiovascular."
  },
  {
    "objectID": "airqualitybogota.html#uso",
    "href": "airqualitybogota.html#uso",
    "title": "AirQualityBogota",
    "section": "Uso",
    "text": "Uso\nPara cargar los datos en R, usa el siguiente comando:\n\n\nLinking to GEOS 3.12.2, GDAL 3.9.3, PROJ 9.4.1; sf_use_s2() is TRUE\n\n\n\ndata(AirQualityBogota)\n\n\nstr(coord)\n\n'data.frame':   10 obs. of  3 variables:\n $ ESTACION: chr  \"Bsq\" \"IDRD\" \"Sony\" \"EscIng\" ...\n $ X       : num  105076 99661 92104 103675 98239 ...\n $ Y       : num  112526 106572 99968 120780 118365 ...\n\n\n\nstr(PM10)\n\n'data.frame':   8761 obs. of  10 variables:\n $ Bosque       : int  29 32 32 24 29 31 24 26 25 36 ...\n $ IDRD         : int  53 48 25 36 17 7 9 12 12 13 ...\n $ Carvajal_Sony: int  72 69 61 30 42 44 30 39 53 49 ...\n $ Guaymaral    : int  74 55 58 51 41 39 46 60 54 41 ...\n $ Suba_Corpas  : int  53 52 45 45 38 40 44 67 51 41 ...\n $ Fontibon     : int  65 49 35 40 26 23 21 29 32 30 ...\n $ PteAranda    : int  91 70 45 43 33 11 15 28 24 31 ...\n $ MAVDT        : int  31 32 32 29 21 21 25 29 26 32 ...\n $ Kennedy      : int  135 94 68 53 47 45 49 59 62 71 ...\n $ Tunal        : int  38 29 18 17 24 24 19 15 20 35 ...\n\n\n\nplot(map$geometry)"
  },
  {
    "objectID": "cokmexico.html",
    "href": "cokmexico.html",
    "title": "Mex PM10",
    "section": "",
    "text": "El conjunto de datos COKMexico contiene información sobre la calidad del aire en 13 ubicaciones de México. Específicamente, incluye mediciones de material particulado 10 (PM10) y N02 recolectadas en 13 estaciones de monitoreo distribuidas por el país. Al cargar los datos encontrará en el ambiente."
  },
  {
    "objectID": "cokmexico.html#uso",
    "href": "cokmexico.html#uso",
    "title": "Mex PM10",
    "section": "Uso",
    "text": "Uso\nPara cargar los datos en R, usa el siguiente comando:\n\n\nLinking to GEOS 3.12.2, GDAL 3.9.3, PROJ 9.4.1; sf_use_s2() is TRUE\n\n\n\ndata(COKMexico)\n\n\nstr(coord_NO2)\n\n'data.frame':   18 obs. of  2 variables:\n $ X: num  509226 473346 482180 469366 479189 ...\n $ Y: num  2171149 2164689 2152665 2141275 2180751 ...\n\n\n\nstr(coord_PM10)\n\n'data.frame':   13 obs. of  2 variables:\n $ X: num  509226 479189 474444 484020 487445 ...\n $ Y: num  2171149 2180751 2154232 2146380 2147815 ...\n\n\n\nstr(Mex_PM10)\n\n int [1:4344, 1:13] 84 110 140 131 151 181 147 139 118 74 ...\n - attr(*, \"dimnames\")=List of 2\n  ..$ : chr [1:4344] \"1\" \"2\" \"3\" \"4\" ...\n  ..$ : chr [1:13] \"ACO\" \"CUT\" \"FAC\" \"HGM\" ...\n\n\n\nstr(Mex_PM10)\n\n int [1:4344, 1:13] 84 110 140 131 151 181 147 139 118 74 ...\n - attr(*, \"dimnames\")=List of 2\n  ..$ : chr [1:4344] \"1\" \"2\" \"3\" \"4\" ...\n  ..$ : chr [1:13] \"ACO\" \"CUT\" \"FAC\" \"HGM\" ...\n\n\n\nstr(NO2)\n\n int [1:4292, 1:18] 21 21 21 18 16 12 12 10 9 10 ...\n - attr(*, \"dimnames\")=List of 2\n  ..$ : chr [1:4292] \"1\" \"2\" \"3\" \"4\" ...\n  ..$ : chr [1:18] \"ACO\" \"ATI\" \"CAM\" \"CUA\" ...\n\n\n\nplot(map_mex)"
  },
  {
    "objectID": "cross_validation.html",
    "href": "cross_validation.html",
    "title": "Validación Cruzada",
    "section": "",
    "text": "Esta función realiza la validación cruzada leave-one-out para kriging funcional y cokriging. Deja sistemáticamente una observación fuera del conjunto de datos, ajusta el modelo a los datos restantes y luego realiza una predicción para la observación que se ha dejado fuera. Se utiliza para evaluar el rendimiento predictivo del modelo de kriging funcional."
  },
  {
    "objectID": "cross_validation.html#descripción",
    "href": "cross_validation.html#descripción",
    "title": "Validación Cruzada",
    "section": "",
    "text": "Esta función realiza la validación cruzada leave-one-out para kriging funcional y cokriging. Deja sistemáticamente una observación fuera del conjunto de datos, ajusta el modelo a los datos restantes y luego realiza una predicción para la observación que se ha dejado fuera. Se utiliza para evaluar el rendimiento predictivo del modelo de kriging funcional."
  },
  {
    "objectID": "cross_validation.html#uso",
    "href": "cross_validation.html#uso",
    "title": "Validación Cruzada",
    "section": "Uso",
    "text": "Uso\ncrossval_loo(object, plot_show)"
  },
  {
    "objectID": "cross_validation.html#argumentos",
    "href": "cross_validation.html#argumentos",
    "title": "Validación Cruzada",
    "section": "Argumentos",
    "text": "Argumentos\n\nobject: Un objeto de clase KS_pred obtenido con la función KS_scores_lambdas.\nplot_show: Un valor lógico. Si es TRUE, la función generará y mostrará un gráfico de los resultados de la validación cruzada. Si es FALSE, no se mostrará ningún gráfico. El valor predeterminado es TRUE."
  },
  {
    "objectID": "cross_validation.html#valor",
    "href": "cross_validation.html#valor",
    "title": "Validación Cruzada",
    "section": "Valor",
    "text": "Valor\nLa función devuelve un objeto que contiene los resultados de la validación cruzada leave-one-out. Incluye:\n\nperformance_metrics: Estadísticas resumidas que describen el rendimiento predictivo general, como el error cuadrático medio.\nplots: Generación de gráficos que muestran los resultados de la validación cruzada, controlados por el parámetro plot_show. Si plot_show es TRUE, esto contendrá los gráficos; de lo contrario, estará vacío."
  },
  {
    "objectID": "cross_validation.html#ejemplos",
    "href": "cross_validation.html#ejemplos",
    "title": "Validación Cruzada",
    "section": "Ejemplos",
    "text": "Ejemplos\n# Código de ejemplo que demuestra cómo usar la función crossval_loo\nlibrary(SpatFD)\nlibrary(gstat)\n\n# Cargar datos y coordenadas\ndata(AirQualityBogota)\n\n# s_0 ubicación no muestreada. Puede ser un data.frame o matriz con una o más ubicaciones de interés\nnewcoorden = data.frame(X = seq(93000, 105000, len = 100), Y = seq(97000, 112000, len = 100))\n# newcoorden = data.frame(X=110000,Y=126000)\n# newcoorden = matrix(c(110000.23, 109000, 109500, 130000.81, 129000, 131000), nrow = 3, ncol = 2, byrow = TRUE)\n\n# Construir el objeto SpatFD\nSFD_PM10 &lt;- SpatFD(PM10, coords = coord[, -1], basis = \"Bsplines\", \n                   nbasis = 17, norder = 5, lambda = 0.00002, nharm = 3)\n\n# Modelos de semivariograma para cada campo aleatorio espacial de puntuaciones\nmodelos &lt;- list(vgm(psill = 2199288.58, \"Wav\", range = 1484.57, nugget = 0),\n                vgm(psill = 62640.74, \"Mat\", range = 1979.43, nugget = 0, kappa = 0.68),\n                vgm(psill = 37098.25, \"Exp\", range = 6433.16, nugget = 0))\n\n# Kriging funcional. Predicción espacial funcional en cada ubicación de interés\n# method = \"lambda\"\n# Cálculo de lambda_i\nKS_SFD_PM10_l &lt;- KS_scores_lambdas(SFD_PM10, newcoorden, method = \"lambda\", \n                                    model = modelos)\n# method = \"scores\"\n# Kriging simple de puntuaciones\nKS_SFD_PM10_sc &lt;- KS_scores_lambdas(SFD_PM10, newcoorden, method = \"scores\", model = modelos)\n# method = \"both\"\nKS_SFD_PM10_both &lt;- KS_scores_lambdas(SFD_PM10, newcoorden, method = \"both\", model = modelos)\n\n# Validación Cruzada \ncrossval_loo(KS_SFD_PM10_l)\ncrossval_loo(KS_SFD_PM10_sc)\ncrossval_loo(KS_SFD_PM10_both)"
  },
  {
    "objectID": "GeoestadísticaConSgeostat.html",
    "href": "GeoestadísticaConSgeostat.html",
    "title": "Geoestadística con sgeostat",
    "section": "",
    "text": "rm(list=ls())\naquifer=read.table(\"data/aquifer.txt\",head=T,dec=\",\")\nhead(aquifer)\n\n       Este     Norte Profundidad\n1  42.78275 127.62282        1464\n2 -27.39691  90.78732        2553\n3  -1.16289  84.89600        2158\n4 -18.61823  76.45199        2455\n5  96.46549  64.58058        1756\n6 108.56243  82.92325        1702"
  },
  {
    "objectID": "GeoestadísticaConSgeostat.html#data-load",
    "href": "GeoestadísticaConSgeostat.html#data-load",
    "title": "Geoestadística con sgeostat",
    "section": "",
    "text": "rm(list=ls())\naquifer=read.table(\"data/aquifer.txt\",head=T,dec=\",\")\nhead(aquifer)\n\n       Este     Norte Profundidad\n1  42.78275 127.62282        1464\n2 -27.39691  90.78732        2553\n3  -1.16289  84.89600        2158\n4 -18.61823  76.45199        2455\n5  96.46549  64.58058        1756\n6 108.56243  82.92325        1702"
  },
  {
    "objectID": "GeoestadísticaConSgeostat.html#libraries",
    "href": "GeoestadísticaConSgeostat.html#libraries",
    "title": "Geoestadística con sgeostat",
    "section": "Libraries",
    "text": "Libraries\n\nlibrary(scatterplot3d)\nlibrary(ggplot2)\nlibrary(cowplot)\nlibrary(sgeostat)"
  },
  {
    "objectID": "GeoestadísticaConSgeostat.html#including-plots",
    "href": "GeoestadísticaConSgeostat.html#including-plots",
    "title": "Geoestadística con sgeostat",
    "section": "Including Plots",
    "text": "Including Plots\n\ng1=ggplot(aquifer, aes(Profundidad, Este)) + \n  geom_point() + \n  geom_line() +\n  xlab(\"Este\") + \n  ylab(\"Profundidad\")\n\ng2=ggplot(aquifer, aes(Profundidad, Norte)) + \n  geom_point() + \n  geom_line() +\n  xlab(\"Norte\") + \n  ylab(\"Profundidad\")\n\ng3=ggplot(aquifer, aes(Profundidad, Este*Norte)) + \n  geom_point() + \n  geom_line() +\n  xlab(\"Interacción este,norte\") + \n  ylab(\"Profundidad\")\n\n\nplot_grid(g1,g2,g3)\n\n\n\n\n\n\n\n\n\ncor(aquifer)\n\n                  Este      Norte Profundidad\nEste         1.0000000  0.1147565  -0.7788885\nNorte        0.1147565  1.0000000  -0.6200923\nProfundidad -0.7788885 -0.6200923   1.0000000\n\n\n\nscatterplot3d(aquifer, highlight.3d=TRUE, col.axis=\"blue\",\ncol.grid=\"lightblue\", main=\"Tendencia de Profundidad\", pch=20)\n\n\n\n\n\n\n\n\n\nreg1 &lt;- lm(Profundidad ~ Este + Norte, data = aquifer)\nresiduales1  &lt;-  residuals(reg1)\nsummary(reg1)\n\n\nCall:\nlm(formula = Profundidad ~ Este + Norte, data = aquifer)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-366.96 -161.53  -30.71  148.15  651.20 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 2591.4302    38.9599   66.52   &lt;2e-16 ***\nEste          -6.7514     0.3438  -19.64   &lt;2e-16 ***\nNorte         -5.9872     0.4066  -14.73   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 203.3 on 82 degrees of freedom\nMultiple R-squared:  0.8921,    Adjusted R-squared:  0.8894 \nF-statistic: 338.9 on 2 and 82 DF,  p-value: &lt; 2.2e-16\n\n\n\nanova(reg1)\n\nAnalysis of Variance Table\n\nResponse: Profundidad\n          Df   Sum Sq  Mean Sq F value    Pr(&gt;F)    \nEste       1 19045642 19045642  460.95 &lt; 2.2e-16 ***\nNorte      1  8960172  8960172  216.86 &lt; 2.2e-16 ***\nResiduals 82  3388069    41318                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nreg2 &lt;- lm(Profundidad ~ Este*Norte, data = aquifer)\nresiduales2  &lt;-  residuals(reg2)\nsummary(reg2)\n\n\nCall:\nlm(formula = Profundidad ~ Este * Norte, data = aquifer)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-406.30 -138.88  -13.04  129.36  722.48 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  2.627e+03  3.833e+01  68.546  &lt; 2e-16 ***\nEste        -8.287e+00  5.658e-01 -14.646  &lt; 2e-16 ***\nNorte       -6.649e+00  4.327e-01 -15.366  &lt; 2e-16 ***\nEste:Norte   2.452e-02  7.401e-03   3.314  0.00138 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 191.9 on 81 degrees of freedom\nMultiple R-squared:  0.905, Adjusted R-squared:  0.9014 \nF-statistic: 257.1 on 3 and 81 DF,  p-value: &lt; 2.2e-16\n\n\n\nanova(reg2)\n\nAnalysis of Variance Table\n\nResponse: Profundidad\n           Df   Sum Sq  Mean Sq F value    Pr(&gt;F)    \nEste        1 19045642 19045642  517.06 &lt; 2.2e-16 ***\nNorte       1  8960172  8960172  243.25 &lt; 2.2e-16 ***\nEste:Norte  1   404448   404448   10.98  0.001379 ** \nResiduals  81  2983621    36835                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nreg3 &lt;- lm(Profundidad ~ Este*Norte+I(Este^2)*I(Norte^2), data = aquifer)\nresiduales3  &lt;-  residuals(reg3)\nsummary(reg3)\n\n\nCall:\nlm(formula = Profundidad ~ Este * Norte + I(Este^2) * I(Norte^2), \n    data = aquifer)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-372.7 -133.6  -20.3  129.9  505.1 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           2.538e+03  7.038e+01  36.055   &lt;2e-16 ***\nEste                 -7.728e+00  6.028e-01 -12.822   &lt;2e-16 ***\nNorte                -3.075e+00  1.770e+00  -1.737   0.0863 .  \nI(Este^2)            -6.792e-03  5.967e-03  -1.138   0.2585    \nI(Norte^2)           -2.372e-02  9.049e-03  -2.622   0.0105 *  \nEste:Norte            1.155e-02  9.680e-03   1.193   0.2365    \nI(Este^2):I(Norte^2)  2.251e-06  9.541e-07   2.360   0.0208 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 180.7 on 78 degrees of freedom\nMultiple R-squared:  0.9189,    Adjusted R-squared:  0.9126 \nF-statistic: 147.2 on 6 and 78 DF,  p-value: &lt; 2.2e-16\n\n\n\nanova(reg3)\n\nAnalysis of Variance Table\n\nResponse: Profundidad\n                     Df   Sum Sq  Mean Sq  F value    Pr(&gt;F)    \nEste                  1 19045642 19045642 583.2335 &lt; 2.2e-16 ***\nNorte                 1  8960172  8960172 274.3868 &lt; 2.2e-16 ***\nI(Este^2)             1    55368    55368   1.6955 0.1967061    \nI(Norte^2)            1   152170   152170   4.6599 0.0339500 *  \nEste:Norte            1   451567   451567  13.8283 0.0003755 ***\nI(Este^2):I(Norte^2)  1   181854   181854   5.5689 0.0207829 *  \nResiduals            78  2547110    32655                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\naquifer=data.frame(aquifer,resi=residuales2)\naquifer_points=point(aquifer, x=\"Este\", y=\"Norte\")\naquifer_pair=pair(aquifer_points,num.lags=10)\n\n....................................................................................\n\n\n\nstr(aquifer_pair)\n\nList of 5\n $ from: num [1:3570] 1 1 1 1 1 1 1 1 1 1 ...\n $ to  : num [1:3570] 2 3 4 5 6 7 8 9 10 11 ...\n $ lags: Factor w/ 10 levels \"1\",\"2\",\"3\",\"4\",..: 3 3 3 4 3 4 4 4 4 4 ...\n $ dist: num [1:3570] 79.3 61.3 79.9 82.8 79.5 ...\n $ bins: num [1:10] 13.6 40.7 67.8 94.9 122 ...\n - attr(*, \"type\")= chr \"isotropic\"\n - attr(*, \"class\")= chr \"pair\"\n\n\n\naquifer.v&lt;-est.variogram(aquifer_points,aquifer_pair,'resi')\n\n\ng4=ggplot(aquifer, aes(resi, Este)) + \n  geom_point() + \n  geom_line() +\n  xlab(\"Este\") + \n  ylab(\"residuales2\")\n\ng5=ggplot(aquifer, aes(resi, Norte)) + \n  geom_point() + \n  geom_line() +\n  xlab(\"Norte\") + \n  ylab(\"residuales2\")\n\nplot_grid(g4,g5)\n\n\n\n\n\n\n\n\n\naquifer_points=point(aquifer, x=\"Este\", y=\"Norte\")\nfit.trend(aquifer_points,at=\"Profundidad\", np=2, plot.it=TRUE)\n\n\n\n\n\n\n\n\n$beta\n      x^0 y^0       x^1 y^0       x^2 y^0       x^0 y^1       x^1 y^1 \n 2.481430e+03 -8.373708e+00  1.416675e-03 -2.043419e+00  2.680056e-02 \n      x^0 y^2 \n-2.464371e-02 \n\n$R\n       x^0 y^0   x^1 y^0    x^2 y^0    x^0 y^1    x^1 y^1   x^0 y^2\n[1,] -9.219544 -155.6739 -41051.636 -731.67314 -16082.944 -85540.31\n[2,]  0.000000  595.1832   3500.219   57.75539  38829.771  12491.66\n[3,]  0.000000    0.0000  39397.313 -117.36878   1909.315 -23722.80\n[4,]  0.000000    0.0000      0.000  485.98967  14332.040  91118.22\n[5,]  0.000000    0.0000      0.000    0.00000  25401.055   3240.90\n[6,]  0.000000    0.0000      0.000    0.00000      0.000  19989.20\n\n$np\n[1] 2\n\n$x\n [1]   42.78275  -27.39691   -1.16289  -18.61823   96.46549  108.56243\n [7]   88.36356   90.04213   93.17269   97.61099   90.62946   92.55262\n[13]   99.48996  -24.06744  -26.06285   56.27842   73.03881   80.26679\n[19]   80.23009   68.83845   76.39921   64.46148   43.39657   39.07769\n[25]  112.80450   54.25899    6.13202   -3.80469   -2.23054   -2.36177\n[31]   -2.18890   63.22428  -10.77860  -18.98889  -38.57884   83.14496\n[37]  -21.80248  -23.56457  -20.11299  -16.62654   29.90748  100.91568\n[43]  101.29544  103.26625  -14.31073  -18.13447  -18.12151   -9.88796\n[49]  -12.16336   11.65754   61.69122   69.57896   66.72205  -36.65446\n[55]  -19.55102  -21.29791  -22.36166   21.14719    7.68461   -8.33227\n[61]   56.70724   59.00052   68.96893   70.90225   73.00243   59.66237\n[67]   61.87249   63.70810    5.62706   18.24739   85.68824  105.07646\n[73] -101.64278 -145.23654  -73.99313  -94.48182  -88.84983 -120.25898\n[79]  -86.02454  -72.79097 -100.17372  -78.83539  -83.69063  -95.61661\n[85]  -87.55480\n\n$y\n [1] 127.62282  90.78732  84.89600  76.45199  64.58058  82.92325  56.45348\n [8]  39.25820  33.05852  56.27887  35.08169  41.75238  59.15785 184.76636\n[15] 114.07479  26.84826  18.88140  12.61593  14.61795 107.77423  95.99380\n[22] 110.39641  53.61499  61.99805  45.54766 147.81987  48.32772  40.40450\n[29]  29.91113  33.82002  33.68207  79.49924 175.11346 171.91695 158.52742\n[36] 159.11559  15.02551   9.41441  22.09269  17.25621 175.12875  22.97808\n[43]  22.96385  20.34239  31.26545  30.18118  29.53241  38.14483  39.11081\n[50]  18.73347  32.94906  33.80841  33.93264 150.91457 137.78404 131.82542\n[57] 137.13680 139.26199 126.83751 107.77691 171.26443 164.54863 177.24820\n[64] 161.38136 162.98959 170.10544 174.30177 173.91454  79.08730  77.39191\n[71] 139.81702 132.03181  10.65106  28.02333  87.97270  86.62606  76.70991\n[78]  80.76485  54.36334  43.09215  42.89881  40.82141  46.50482  35.82183\n[85]  29.39267\n\n$z\n [1] 1464 2553 2158 2455 1756 1702 1805 1797 1714 1466 1729 1638 1736 1476 2200\n[16] 1999 1680 1806 1682 1306 1722 1437 1828 2118 1725 1606 2648 2560 2544 2386\n[31] 2400 1757 1402 1364 1735 1376 2729 2766 2736 2432 1024 1611 1548 1591 2540\n[46] 2352 2528 2575 2468 2646 1739 1674 1868 1865 1777 1579 1771 1408 1527 2003\n[61] 1386 1089 1384 1030 1092 1161 1415 1231 2300 2238 1038 1332 3510 3490 2594\n[76] 2650 2533 3571 2811 2728 3136 2553 2798 2691 2946\n\n$residuals\n [1] -145.932017  296.391955   20.569629  155.586776  136.944207  210.578982\n [7]  112.643763   81.535500   12.407325 -165.733666   11.643984  -55.843867\n[13]  123.038140  130.250727  132.838620   16.473072 -186.973641   -9.864104\n[19] -133.020821 -298.072286   98.737035 -175.328351 -174.667016  118.113364\n[25]  176.632628  200.333264  366.232978  173.604750  128.842139  -15.778284\n[31]   -1.005758  -17.176812   -5.743382 -109.803640   35.578021  175.509274\n[37]  109.375693  113.827801  154.658230 -138.758151 -234.947039  -41.999962\n[43] -102.169175  -45.349545   38.415648 -182.959426   -9.456222  134.544149\n[49]   14.873572  303.070200 -191.631118 -197.446346  -23.989926   92.632496\n[55]  -47.092725 -308.538280  -72.511843 -213.402614 -260.643390  -17.741523\n[61]  187.380986 -159.999448  282.152142 -199.908135 -116.838018  -37.190026\n[67]  262.093246   81.109636  169.467368  176.796541 -289.932780   42.387375\n[73]  216.381585  -51.786437   30.159248  -53.946573 -219.188525  648.160187\n[79]  -92.004756 -152.583829   49.711612 -386.649271 -141.519561 -407.429504\n[85] -129.126052\n\nattr(,\"class\")\n[1] \"trend.surface\"\n\n\n\ng6=ggplot(aquifer.v, aes(resi, Norte)) + \n  geom_point() + \n  geom_line() +\n  xlab(\"Norte\") + \n  ylab(\"residuales2\")\n\ng6=ggplot(aquifer.v, aes(bins, classic)) + \n  geom_point() + \n  geom_line() +\n  xlab(\"Rezago espacial, h\") + \n  ylab(\"Estimador clásico del variograma\")\n\ng7=ggplot(aquifer.v, aes(bins, robust)) + \n  geom_point() + \n  geom_line() +\n  xlab(\"Rezago espacial, h\") + \n  ylab(\"Estimador robusto 1 del variograma\")\n\ng8=ggplot(aquifer.v, aes(bins, med)) + \n  geom_point() + \n  geom_line() +\n  xlab(\"Rezago espacial, h\") + \n  ylab(\"Estimador robusto 2 del variograma\")\n\nplot_grid(g6,g7,g8,nrow=1,ncol=3)\n\n\n\n\n\n\n\n\n\n#par(mfrow=c(1,3))\nprint(aquifer.v)\n\n   lags      bins   classic    robust       med   n\n1     1  13.55308  43779.20  44355.34  47948.45 285\n2     2  40.65923  71039.50  71176.29  73188.30 350\n3     3  67.76539  80041.91  85367.59  93223.52 492\n4     4  94.87154  67197.27  68067.40  73056.46 719\n5     5 121.97770  73572.25  68052.99  66133.91 612\n6     6 149.08385  57650.90  58608.95  58819.91 521\n7     7 176.19001  65498.82  62167.57  68112.31 356\n8     8 203.29616 130414.72 107613.55  77805.71 173\n9     9 230.40231 161738.13 134102.60 123952.77  43\n10   10 257.50847  35525.99  45217.14  58333.98  19\n\n\n\nplot(aquifer.v$robust)\n\n\n\n\n\n\n\n\n\nplot(aquifer.v$med,col='blue')\npoints(aquifer.v$robust,col=\"red\")\n\n\n\n\n\n\n\n\n\naquifer.vmodExp&lt;-fit.exponential(aquifer.v,c0=0,ce=40000,ae=20,plot.it=TRUE,iterations=30)\n\nInitial parameter estimates:  0 40000 20 \n\n\n\n\n\n\n\n\n\nIteration: 1 \nGradient vector:  -4432.441 977.0988 -8.943538 \nNew parameter estimates:  1e-06 40977.1 11.05646 \n\nrse.dif =  3232643827 (rse = 3232643827 )  ;  parm.dist =  977.1397 \n\n\n\n\n\n\n\n\n\nIteration: 2 \nGradient vector:  -26700.7 22493.46 -2.800242 \nNew parameter estimates:  1e-06 63470.56 8.256219 \n\nrse.dif =  -17644208 (rse = 3.215e+09 )  ;  parm.dist =  22493.46 \n\n\n\n\n\n\n\n\n\nIteration: 3 \nGradient vector:  -11057.27 -15597.73 2.315183 \nNew parameter estimates:  1e-06 47872.83 10.5714 \n\nrse.dif =  -3772568 (rse = 3211227051 )  ;  parm.dist =  15597.73 \n\n\n\n\n\n\n\n\n\nIteration: 4 \nGradient vector:  -27525.12 16431.58 -1.824505 \nNew parameter estimates:  1e-06 64304.41 8.746897 \n\nrse.dif =  3032851 (rse = 3214259902 )  ;  parm.dist =  16431.58 \n\n\n\n\n\n\n\n\n\nIteration: 5 \nGradient vector:  -20442.22 -7053.019 1.144197 \nNew parameter estimates:  1e-06 57251.39 9.891094 \n\nrse.dif =  -2468665 (rse = 3211791237 )  ;  parm.dist =  7053.019 \n\n\n\n\n\n\n\n\n\nIteration: 6 \nGradient vector:  -27557.41 7097.539 -0.7122805 \nNew parameter estimates:  1e-06 64348.93 9.178813 \n\nrse.dif =  1486180 (rse = 3213277417 )  ;  parm.dist =  7097.539 \n\n\n\n\n\n\n\n\n\nIteration: 7 \nGradient vector:  -24787.06 -2758.919 0.3605893 \nNew parameter estimates:  1e-06 61590.01 9.539403 \n\nrse.dif =  -951749.7 (rse = 3212325667 )  ;  parm.dist =  2758.919 \n\n\n\n\n\n\n\n\n\nIteration: 8 \nGradient vector:  -26691.4 1898.737 -0.1885371 \nNew parameter estimates:  1e-06 63488.75 9.350866 \n\nrse.dif =  471370.4 (rse = 3212797038 )  ;  parm.dist =  1898.737 \n\n\n\n\n\n\n\n\n\nIteration: 9 \nGradient vector:  -25850.35 -838.0686 0.09276125 \nNew parameter estimates:  1e-06 62650.68 9.443627 \n\nrse.dif =  -249219.6 (rse = 3212547818 )  ;  parm.dist =  838.0686 \n\n\n\n\n\n\n\n\n\nIteration: 10 \nGradient vector:  -26302.53 450.7265 -0.04631475 \nNew parameter estimates:  1e-06 63101.41 9.397312 \n\nrse.dif =  121873.4 (rse = 3212669692 )  ;  parm.dist =  450.7265 \n\n\n\n\n\n\n\n\n\nIteration: 11 \nGradient vector:  -26086.54 -215.2624 0.02285916 \nNew parameter estimates:  1e-06 62886.14 9.420171 \n\nrse.dif =  -61031.79 (rse = 3212608660 )  ;  parm.dist =  215.2624 \n\n\n\n\n\n\n\n\n\nIteration: 12 \nGradient vector:  -26195.52 108.6221 -0.01133309 \nNew parameter estimates:  1e-06 62994.77 9.408838 \n\nrse.dif =  30077.83 (rse = 3212638738 )  ;  parm.dist =  108.6221 \n\n\n\n\n\n\n\n\n\nIteration: 13 \nGradient vector:  -26142.08 -53.26613 0.005604603 \nNew parameter estimates:  1e-06 62941.5 9.414443 \n\nrse.dif =  -14922.96 (rse = 3212623815 )  ;  parm.dist =  53.26613 \n\n\n\n\n\n\n\n\n\nIteration: 14 \nGradient vector:  -26168.65 26.48517 -0.002774911 \nNew parameter estimates:  1e-06 62967.99 9.411668 \n\nrse.dif =  7377.216 (rse = 3212631192 )  ;  parm.dist =  26.48517 \n\n\n\n\n\n\n\n\n\nIteration: 15 \nGradient vector:  -26155.53 -13.07801 0.001373075 \nNew parameter estimates:  1e-06 62954.91 9.413041 \n\nrse.dif =  -3653.216 (rse = 3212627539 )  ;  parm.dist =  13.07801 \n\n\n\n\n\n\n\n\n\nIteration: 16 \nGradient vector:  -26162.03 6.479831 -0.0006796194 \nNew parameter estimates:  1e-06 62961.39 9.412361 \n\nrse.dif =  1807.514 (rse = 3212629346 )  ;  parm.dist =  6.479831 \n\n\n\n\n\n\n\n\n\nIteration: 17 \nGradient vector:  -26158.82 -3.20516 0.0003363367 \nNew parameter estimates:  1e-06 62958.18 9.412698 \n\nrse.dif =  -894.6895 (rse = 3212628451 )  ;  parm.dist =  3.20516 \n\n\n\n\n\n\n\n\n\nIteration: 18 \nGradient vector:  -26160.41 1.586717 -0.0001664615 \nNew parameter estimates:  1e-06 62959.77 9.412531 \n\nrse.dif =  442.763 (rse = 3212628894 )  ;  parm.dist =  1.586717 \n\n\n\n\n\n\n\n\n\nIteration: 19 \nGradient vector:  -26159.62 -0.7851797 8.238305e-05 \nNew parameter estimates:  1e-06 62958.98 9.412613 \n\nrse.dif =  -219.1369 (rse = 3212628675 )  ;  parm.dist =  0.7851797 \n\n\n\n\n\n\n\n\n\nIteration: 20 \nGradient vector:  -26160.01 0.3886224 -4.077271e-05 \nNew parameter estimates:  1e-06 62959.37 9.412573 \n\nrse.dif =  108.4519 (rse = 3212628784 )  ;  parm.dist =  0.3886224 \n\n\n\n\n\n\n\n\n\nIteration: 21 \nGradient vector:  -26159.82 -0.192328 2.01789e-05 \nNew parameter estimates:  1e-06 62959.18 9.412593 \n\nrse.dif =  -53.67477 (rse = 3212628730 )  ;  parm.dist =  0.192328 \n\n\n\n\n\n\n\n\n\nIteration: 22 \nGradient vector:  -26159.91 0.09518727 -9.986825e-06 \nNew parameter estimates:  1e-06 62959.28 9.412583 \n\nrse.dif =  26.56425 (rse = 3212628756 )  ;  parm.dist =  0.09518727 \n\n\n\n\n\n\n\n\n\nIteration: 23 \nGradient vector:  -26159.86 -0.04710907 4.94261e-06 \nNew parameter estimates:  1e-06 62959.23 9.412588 \n\nrse.dif =  -13.14703 (rse = 3212628743 )  ;  parm.dist =  0.04710907 \n\n\n\n\n\n\n\n\n\nIteration: 24 \nGradient vector:  -26159.89 0.023315 -2.446165e-06 \nNew parameter estimates:  1e-06 62959.25 9.412585 \n\nrse.dif =  6.506634 (rse = 3212628750 )  ;  parm.dist =  0.023315 \n\n\n\n\n\n\n\n\n\nIteration: 25 \nGradient vector:  -26159.88 -0.01153889 1.21064e-06 \nNew parameter estimates:  1e-06 62959.24 9.412587 \n\nrse.dif =  -3.220222 (rse = 3212628747 )  ;  parm.dist =  0.01153889 \n\n\n\n\n\n\n\n\n\nIteration: 26 \nGradient vector:  -26159.88 0.005710764 -5.991627e-07 \nNew parameter estimates:  1e-06 62959.25 9.412586 \n\nrse.dif =  1.593734 (rse = 3212628748 )  ;  parm.dist =  0.005710764 \n\n\n\n\n\n\n\n\n\nIteration: 27 \nGradient vector:  -26159.88 -0.002826342 2.965346e-07 \nNew parameter estimates:  1e-06 62959.24 9.412586 \n\nrse.dif =  -0.7887611 (rse = 3212628747 )  ;  parm.dist =  0.002826342 \n\n\n\n\n\n\n\n\n\nIteration: 28 \nGradient vector:  -26159.88 0.001398795 -1.467591e-07 \nNew parameter estimates:  1e-06 62959.24 9.412586 \n\nrse.dif =  0.3903689 (rse = 3212628748 )  ;  parm.dist =  0.001398795 \n\n\n\n\n\n\n\n\n\nIteration: 29 \nGradient vector:  -26159.88 -0.0006922812 7.263288e-08 \nNew parameter estimates:  1e-06 62959.24 9.412586 \n\nrse.dif =  -0.1932006 (rse = 3212628748 )  ;  parm.dist =  0.0006922812 \n\n\n\n\n\n\n\n\n\nIteration: 30 \nGradient vector:  -26159.88 0.000342624 -3.594748e-08 \nNew parameter estimates:  1e-06 62959.24 9.412586 \n\nrse.dif =  0.09561825 (rse = 3212628748 )  ;  parm.dist =  0.000342624 \n\n\n\n\n\n\n\n\n\nConvergence not achieved!\n\n\n\naquifer.vmodGau&lt;-fit.gaussian(aquifer.v,c0=0,cg=50000,ag=50,plot.it=TRUE,iterations=30)\n\nInitial parameter estimates:  0 50000 50 \n\n\n\n\n\n\n\n\n\nIteration: 1 \nGradient vector:  19162.34 -33401.14 -11.41191 \nNew parameter estimates:  19162.34 16598.86 38.58809 \n\nrse.dif =  3299750048 (rse = 3299750048 )  ;  parm.dist =  38507.55 \n\n\n\n\n\n\n\n\n\nIteration: 2 \nGradient vector:  -1294.927 2010.017 -18.77473 \nNew parameter estimates:  17867.41 18608.87 19.81336 \n\nrse.dif =  -66430135 (rse = 3233319913 )  ;  parm.dist =  2391.1 \n\n\n\n\n\n\n\n\n\nIteration: 3 \nGradient vector:  3201.043 -2835.169 9.216254 \nNew parameter estimates:  21068.46 15773.71 29.02961 \n\nrse.dif =  -24694350 (rse = 3208625564 )  ;  parm.dist =  4276.09 \n\n\n\n\n\n\n\n\n\nIteration: 4 \nGradient vector:  -4345.272 4292.413 -6.361973 \nNew parameter estimates:  16723.18 20066.12 22.66764 \n\nrse.dif =  4004881 (rse = 3212630445 )  ;  parm.dist =  6107.884 \n\n\n\n\n\n\n\n\n\nIteration: 5 \nGradient vector:  53.88685 -4.270081 2.074271 \nNew parameter estimates:  16777.07 20061.85 24.74191 \n\nrse.dif =  -3703977 (rse = 3208926468 )  ;  parm.dist =  54.09555 \n\n\n\n\n\n\n\n\n\nIteration: 6 \nGradient vector:  -391.4471 384.4526 -0.5571294 \nNew parameter estimates:  16385.62 20446.3 24.18478 \n\nrse.dif =  588163 (rse = 3209514631 )  ;  parm.dist =  548.6666 \n\n\n\n\n\n\n\n\n\nIteration: 7 \nGradient vector:  29.55911 -27.0943 0.07968918 \nNew parameter estimates:  16415.18 20419.21 24.26447 \n\nrse.dif =  -201438.9 (rse = 3209313192 )  ;  parm.dist =  40.09799 \n\n\n\n\n\n\n\n\n\nIteration: 8 \nGradient vector:  -6.581211 6.259206 -0.01207028 \nNew parameter estimates:  16408.6 20425.47 24.2524 \n\nrse.dif =  26607.8 (rse = 3209339800 )  ;  parm.dist =  9.082408 \n\n\n\n\n\n\n\n\n\nIteration: 9 \nGradient vector:  0.9423146 -0.8928955 0.001794561 \nNew parameter estimates:  16409.54 20424.57 24.25419 \n\nrse.dif =  -4077.43 (rse = 3209335722 )  ;  parm.dist =  1.298161 \n\n\n\n\n\n\n\n\n\nIteration: 10 \nGradient vector:  -0.1413215 0.1339887 -0.0002673761 \nNew parameter estimates:  16409.4 20424.71 24.25393 \n\nrse.dif =  605.1536 (rse = 3209336327 )  ;  parm.dist =  0.194743 \n\n\n\n\n\n\n\n\n\nIteration: 11 \nGradient vector:  0.02102884 -0.01993597 3.982407e-05 \nNew parameter estimates:  16409.42 20424.69 24.25397 \n\nrse.dif =  -90.18701 (rse = 3209336237 )  ;  parm.dist =  0.02897682 \n\n\n\n\n\n\n\n\n\nIteration: 12 \nGradient vector:  -0.003132718 0.00296995 -5.931842e-06 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  13.43229 (rse = 3209336251 )  ;  parm.dist =  0.004316777 \n\n\n\n\n\n\n\n\n\nIteration: 13 \nGradient vector:  0.0004666088 -0.0004423641 8.835486e-07 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  -2.000767 (rse = 3209336249 )  ;  parm.dist =  0.0006429701 \n\n\n\n\n\n\n\n\n\nIteration: 14 \nGradient vector:  -6.950171e-05 6.589045e-05 -1.316048e-07 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  0.2980142 (rse = 3209336249 )  ;  parm.dist =  9.577086e-05 \n\n\n\n\n\n\n\n\n\nIteration: 15 \nGradient vector:  1.035229e-05 -9.814388e-06 1.960254e-08 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  -0.04438925 (rse = 3209336249 )  ;  parm.dist =  1.426508e-05 \n\n\n\n\n\n\n\n\n\nIteration: 16 \nGradient vector:  -1.542e-06 1.46188e-06 -2.919839e-09 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  0.006612301 (rse = 3209336249 )  ;  parm.dist =  2.124821e-06 \n\n\n\n\n\n\n\n\n\nIteration: 17 \nGradient vector:  2.296994e-07 -2.177628e-07 4.349363e-10 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  -0.0009851456 (rse = 3209336249 )  ;  parm.dist =  3.165152e-07 \n\n\n\n\n\n\n\n\n\nIteration: 18 \nGradient vector:  -3.420782e-08 3.242781e-08 -6.477718e-11 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  0.0001473427 (rse = 3209336249 )  ;  parm.dist =  4.713621e-08 \n\n\n\n\n\n\n\n\n\nIteration: 19 \nGradient vector:  5.086605e-09 -4.821087e-09 9.637383e-12 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  -2.193451e-05 (rse = 3209336249 )  ;  parm.dist =  7.007276e-09 \n\n\n\n\n\n\n\n\n\nIteration: 20 \nGradient vector:  -7.583935e-10 7.161523e-10 -1.439258e-12 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  2.861023e-06 (rse = 3209336249 )  ;  parm.dist =  1.042223e-09 \n\n\n\n\n\n\n\n\n\nIteration: 21 \nGradient vector:  1.019258e-10 -9.775917e-11 1.99309e-13 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  -4.768372e-07 (rse = 3209336249 )  ;  parm.dist =  1.415077e-10 \n\nConvergence achieved by sums of squares.\n\n\n\n\n\n\n\n\n\nFinal parameter estimates:  16409.42 20424.69 24.25396 \n\n\n\naquifer.vmodWave&lt;-fit.wave(aquifer.v,c0=0,cw=40000,aw=10,plot.it=TRUE,iterations=30,weighted=T)\n\nInitial parameter estimates:  0 40000 10 \n\n\n\n\n\n\n\n\n\nIteration: 1 \nGradient vector:  18650.32 -21981.27 -0.7942028 \nNew parameter estimates:  18650.32 18018.73 9.205797 \n\nrse.dif =  3409704989 (rse = 3409704989 )  ;  parm.dist =  28827.26 \n\n\n\n\n\n\n\n\n\nIteration: 2 \nGradient vector:  812.9227 -1109.399 -1.187299 \nNew parameter estimates:  19463.25 16909.33 8.018498 \n\nrse.dif =  -289093760 (rse = 3120611230 )  ;  parm.dist =  1375.358 \n\n\n\n\n\n\n\n\n\nIteration: 3 \nGradient vector:  -6990.158 6973.566 0.9858099 \nNew parameter estimates:  12473.09 23882.9 9.004308 \n\nrse.dif =  24044562 (rse = 3144655792 )  ;  parm.dist =  9873.851 \n\n\n\n\n\n\n\n\n\nIteration: 4 \nGradient vector:  7025.438 -6960.473 -1.260353 \nNew parameter estimates:  19498.53 16922.43 7.743955 \n\nrse.dif =  -56767551 (rse = 3087888241 )  ;  parm.dist =  9889.639 \n\n\n\n\n\n\n\n\n\nIteration: 5 \nGradient vector:  -9210.154 9213.61 1.066674 \nNew parameter estimates:  10288.37 26136.04 8.810629 \n\nrse.dif =  175986924 (rse = 3263875165 )  ;  parm.dist =  13027.57 \n\n\n\n\n\n\n\n\n\nIteration: 6 \nGradient vector:  11994.7 -11983.26 -2.255679 \nNew parameter estimates:  22283.07 14152.77 6.55495 \n\nrse.dif =  -196728543 (rse = 3067146622 )  ;  parm.dist =  16954.98 \n\n\n\n\n\n\n\n\n\nIteration: 7 \nGradient vector:  -14060.45 14195.04 -1.578095 \nNew parameter estimates:  8222.625 28347.81 4.976855 \n\nrse.dif =  147278852 (rse = 3214425474 )  ;  parm.dist =  19979.87 \n\n\n\n\n\n\n\n\n\nIteration: 8 \nGradient vector:  -15826.64 16212.91 0.3854677 \nNew parameter estimates:  1e-06 44560.72 5.362323 \n\nrse.dif =  -46983778 (rse = 3167441696 )  ;  parm.dist =  18178.84 \n\n\n\n\n\n\n\n\n\nIteration: 9 \nGradient vector:  13145.08 -21444.98 -0.8756698 \nNew parameter estimates:  13145.08 23115.75 4.486653 \n\nrse.dif =  -757940879 (rse = 2409500817 )  ;  parm.dist =  25153.13 \n\n\n\n\n\n\n\n\n\nIteration: 10 \nGradient vector:  -9434763 9682459 25.73116 \nNew parameter estimates:  1e-06 9705575 30.21781 \n\nrse.dif =  1636307005 (rse = 4045807822 )  ;  parm.dist =  9682468 \n\n\n\n\n\n\n\n\n\nIteration: 11 \nGradient vector:  20962.2 -9688482 0.02156687 \nNew parameter estimates:  20962.2 17093.21 30.23938 \n\nrse.dif =  83628062 (rse = 4129435883 )  ;  parm.dist =  9688504 \n\n\n\n\n\n\n\n\n\nIteration: 12 \nGradient vector:  7173.136 -8587.116 1.22582 \nNew parameter estimates:  28135.34 8506.099 31.4652 \n\nrse.dif =  -628497356 (rse = 3500938527 )  ;  parm.dist =  11188.94 \n\n\n\n\n\n\n\n\n\nIteration: 13 \nGradient vector:  2974.651 -2890.861 -4.19572 \nNew parameter estimates:  31109.99 5615.237 27.26947 \n\nrse.dif =  -192443200 (rse = 3308495327 )  ;  parm.dist =  4147.969 \n\n\n\n\n\n\n\n\n\nIteration: 14 \nGradient vector:  -2399.351 1443.698 15.69929 \nNew parameter estimates:  28710.64 7058.936 42.96876 \n\nrse.dif =  147479203 (rse = 3455974530 )  ;  parm.dist =  2800.25 \n\n\n\n\n\n\n\n\n\nIteration: 15 \nGradient vector:  4786.661 2165.107 -43.14322 \nNew parameter estimates:  33497.3 9224.042 1e-06 \n\nrse.dif =  -686128323 (rse = 2769846206 )  ;  parm.dist =  5253.728 \n\n\n\n\n\n\n\n\n\nIteration: 16 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\nGradient vector:  -7188.309 -5.926894e-07 0 \nNew parameter estimates:  26308.99 9224.042 1e-06 \n\nrse.dif =  686457465 (rse = 3456303671 )  ;  parm.dist =  7188.309 \n\n\n\n\n\n\n\n\n\nIteration: 17 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\nGradient vector:  -5.339328e-06 -5.926894e-07 0 \nNew parameter estimates:  26308.99 9224.042 1e-06 \n\nrse.dif =  0.4889331 (rse = 3456303672 )  ;  parm.dist =  5.372122e-06 \n\n\n\n\n\n\n\n\n\nIteration: 18 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\nGradient vector:  5.926852e-07 -5.926894e-07 0 \nNew parameter estimates:  26308.99 9224.042 1e-06 \n\nrse.dif =  1.907349e-06 (rse = 3456303672 )  ;  parm.dist =  8.381857e-07 \n\n\n\n\n\n\n\n\n\nIteration: 19 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\nGradient vector:  5.926931e-07 -5.926894e-07 0 \nNew parameter estimates:  26308.99 9224.042 1e-06 \n\nrse.dif =  -9.536743e-07 (rse = 3456303672 )  ;  parm.dist =  8.381908e-07 \n\nConvergence achieved by sums of squares.\n\n\n\n\n\n\n\n\n\nFinal parameter estimates:  26308.99 9224.042 1e-06 \n\n\n\ncurve(65000*(1-(14/x)*sin(x/14)),0,300,ylim=c(0,200000))\npoints(aquifer.v$bins,aquifer.v$classic,col=3)\ntext(aquifer.v$bins,aquifer.v$classic,aquifer.v$n,col=2)\n\n\n\n\n\n\n\n\n\ncurve(200000*(1-exp(-x/170)),0,300)\npoints(aquifer.v$bins,aquifer.v$classic,col=2)\n\n\n\n\n\n\n\n\n\ncurve(65000*(1-(14/x)*sin(x/14)),0,300,ylim=c(0,200000))\npoints(aquifer.v$bins,aquifer.v$classic,col=3)\ntext(aquifer.v$bins,aquifer.v$classic,aquifer.v$n,col=2)\n\n\n\n\n\n\n\n\n\naquifer.vmodExp&lt;-fit.exponential(aquifer.v,c0=0,ce=200000,ae=170,plot.it=TRUE,iterations=30,weighted=T)\n\nInitial parameter estimates:  0 2e+05 170 \n\n\n\n\n\n\n\n\n\nIteration: 1 \nGradient vector:  16365.66 -238859.4 -103.7436 \nNew parameter estimates:  16365.66 1e-06 66.25643 \n\nrse.dif =  3826411368 (rse = 3826411368 )  ;  parm.dist =  200668.5 \n\n\n\n\n\n\n\n\n\nIteration: 2 \nGradient vector:  7737.246 16547.95 166070861252 \nNew parameter estimates:  24102.91 16547.95 166070861318 \n\nrse.dif =  -767474321 (rse = 3058937047 )  ;  parm.dist =  166070861252 \n\n\n\n\n\n\n\n\n\nIteration: 3 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\nGradient vector:  3355.03 1.242479e+13 0 \nNew parameter estimates:  27457.94 1.242479e+13 166070861318 \n\nrse.dif =  -120011141 (rse = 2938925906 )  ;  parm.dist =  1.242479e+13 \n\n\n\n\n\n\n\n\n\nIteration: 4 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\nGradient vector:  423.3165 -663474885968 0 \nNew parameter estimates:  27881.25 1.176131e+13 166070861318 \n\nrse.dif =  11801483 (rse = 2950727388 )  ;  parm.dist =  663474885968 \n\n\n\n\n\n\n\n\n\nIteration: 5 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\nGradient vector:  3.873181 -6320523090 0 \nNew parameter estimates:  27885.12 1.175499e+13 166070861318 \n\nrse.dif =  128956.4 (rse = 2950856345 )  ;  parm.dist =  6320523090 \n\n\n\n\n\n\n\n\n\nIteration: 6 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\nGradient vector:  0.02266712 -36921321 0 \nNew parameter estimates:  27885.15 1.175495e+13 166070861318 \n\nrse.dif =  752.3639 (rse = 2950857097 )  ;  parm.dist =  36921321 \n\n\n\n\n\n\n\n\n\nIteration: 7 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\nGradient vector:  0.0001316946 -214507.3 0 \nNew parameter estimates:  27885.15 1.175495e+13 166070861318 \n\nrse.dif =  4.371067 (rse = 2950857102 )  ;  parm.dist =  214507.3 \n\n\n\n\n\n\n\n\n\nIteration: 8 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\nGradient vector:  7.650992e-07 -1246.212 0 \nNew parameter estimates:  27885.15 1.175495e+13 166070861318 \n\nrse.dif =  0.02539396 (rse = 2950857102 )  ;  parm.dist =  1246.213 \n\n\n\n\n\n\n\n\n\nIteration: 9 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\nGradient vector:  4.447233e-09 -7.24441 0 \nNew parameter estimates:  27885.15 1.175495e+13 166070861318 \n\nrse.dif =  0.0001473427 (rse = 2950857102 )  ;  parm.dist =  7.244141 \n\n\n\n\n\n\n\n\n\nIteration: 10 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\nGradient vector:  2.31966e-11 -0.03646515 0 \nNew parameter estimates:  27885.15 1.175495e+13 166070861318 \n\nrse.dif =  9.536743e-07 (rse = 2950857102 )  ;  parm.dist =  0.03710938 \n\nConvergence achieved by sums of squares.\n\n\n\n\n\n\n\n\n\nFinal parameter estimates:  27885.15 1.175495e+13 166070861318 \n\n\n\naquifer.vmodwave&lt;-fit.wave(aquifer.v,c0=4000,cw=30000,aw=15,plot.it=TRUE,iterations=0,weighted=T)\n\n\n\n\n\n\n\n\nConvergence not achieved!\n\n\n\naquifer.vmodExp_0&lt;-fit.exponential(aquifer.v,c0=0,ce=200000,ae=170,plot.it=TRUE,iterations=0,weighted=T)\n\n\n\n\n\n\n\n\nConvergence not achieved!\n\n\n\naquifer.vmodwave_0&lt;-fit.wave(aquifer.v,c0=4000,cw=30000,aw=15,plot.it=TRUE,iterations=0,weighted=T)\n\n\n\n\n\n\n\n\nConvergence not achieved!\n\n\n\naquifer.spherical&lt;-fit.spherical(aquifer.v,c0=0,cs=35000,as=70,plot.it=TRUE,iterations=0,weighted=T)\n\n\n\n\n\n\n\n\nConvergence not achieved!\n\n\n\nggplot(aquifer.v, aes(bins, classic)) + \n  geom_point() + \n  geom_line() +\n  xlab(\"Rezago espacial, h\") + \n  ylab(\"Estimador clásico del variograma\")+\n  xlim(0, 300) +\n  geom_function(aes(color = \"Exponencial\"),\n    fun =~4000+150000*(1-exp(-.x/100)) \n    ) +\n  geom_function(aes(color = \"Seno cardinal\"),\n    fun =~4000+30000*(1-((15/.x)*sin(.x/15)))             \n    ) + xlab(\"Rezago espacial\") + ylab(\"Modelos teóricos de  semivariogramas\") \n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_function()`).\n\n\n\n\n\n\n\n\n\n\nKriging_aquifer &lt;- point(data.frame(list(x=10,y=80)))\nKriging_aquifer &lt;- krige(Kriging_aquifer, aquifer_points, 'resi', aquifer.vmodExp_0)\n\n\nUsing all points.\n  Preparing the kriging system matrix...\n  Inverting the matrix...\n  Predicting.\n\n\n\nKriging_aquifer\n\n\nPoint object: x \n\n   Locations: 1\n\n   Attributes:\n      x\n      y\n      do\n      zhat\n      sigma2hat\n\n\n\nKriging_aquifer$sigma2hat\n\n[1] 7010.452\n\n\n\nKriging_aquifer &lt;- point(data.frame(list(x=10,y=80)))\nKriging_aquifer &lt;- krige(Kriging_aquifer, aquifer_points, 'resi', aquifer.vmodwave_0)\n\n\nUsing all points.\n  Preparing the kriging system matrix...\n  Inverting the matrix...\n  Predicting.\n\n\n\nKriging_aquifer\n\n\nPoint object: x \n\n   Locations: 1\n\n   Attributes:\n      x\n      y\n      do\n      zhat\n      sigma2hat\n\n\n\nKriging_aquifer$zhat\n\n[1] 196.2781\n\n\n\nKriging_aquifer$sigma2hat\n\n[1] 5169.927\n\n\n\ngrid &lt;- list(x=seq(min(aquifer$Este),max(aquifer$Este),by=20),y=seq(min(aquifer$Norte),max(aquifer$Norte),by=10))\ngrid$xr &lt;- range(grid$x)\ngrid$xs &lt;- grid$xr[2] - grid$xr[1]\ngrid$yr &lt;- range(grid$y)\ngrid$ys &lt;- grid$yr[2] - grid$yr[1]\ngrid$max &lt;- max(grid$xs, grid$ys)\ngrid$xy &lt;- data.frame(cbind(c(matrix(grid$x, length(grid$x), length(grid$y))),\nc(matrix(grid$y, length(grid$x), length(grid$y), byrow=TRUE))))\ncolnames(grid$xy) &lt;- c(\"x\", \"y\")\ngrid$point &lt;- point(grid$xy)\ngrid$krige &lt;- krige(grid$point,aquifer_points,'resi',aquifer.vmodwave_0,maxdist=180,extrap=FALSE)\n\n\nUsing points within 180 units of prediction points.\n  Predicting..........................................................................................................................................................................................................................................\n\n\n\nop &lt;- par(no.readonly = TRUE)\npar(pty=\"s\")\nplot(grid$xy, type=\"n\", xlim=c(grid$xr[1], grid$xr[1]+grid$max),ylim=c(grid$yr[1], grid$yr[1]+grid$max))\nimage(grid$x,grid$y,matrix(grid$krige$zhat,length(grid$x),length(grid$y)),add=TRUE)\ncontour(grid$x,grid$y,matrix(grid$krige$zhat,length(grid$x),length(grid$y)),add=TRUE)\n\n\n\n\n\n\n\n\n\nx11()\nop &lt;- par(no.readonly = TRUE)\npar(pty=\"s\")\nplot(grid$xy, type=\"n\", xlim=c(grid$xr[1], grid$xr[1]+grid$max),ylim=c(grid$yr[1], grid$yr[1]+grid$max))\nimage(grid$x,grid$y,matrix(grid$krige$sigma2hat,length(grid$x),length(grid$y)), add=TRUE)\ncontour(grid$x,grid$y,matrix(grid$krige$sigma2hat,length(grid$x),length(grid$y)),add=TRUE)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SpatFD",
    "section": "",
    "text": "La geoestadística funcional es una extensión del marco teórico de la geoestadística tradicional, que permite el análisis y modelado de datos funcionales correlacionados espacialmente, tanto univariados como multivariados. Este enfoque incluye herramientas exploratorias, predicción espacial mediante kriging y cokriging, muestreo óptimo, clasificación supervisada y simulación. A través de este enfoque, se modela la estructura de dependencia espacial entre curvas, lo que permite realizar predicciones en ubicaciones no muestreadas utilizando predictores funcionales que minimizan las varianzas del error de predicción. Además, se ofrece la optimización de la configuración de las ubicaciones de muestreo para mejorar la predicción espacial funcional.\nLas herramientas disponibles también permiten la representación gráfica de las curvas predichas en cada ubicación y el mapeo de las superficies en cada punto temporal. La clasificación supervisada integra la correlación espacial, y se extiende a escenarios con medidas funcionales repetidas en cada localización. Finalmente, la simulación de datos funcionales correlacionados espacialmente puede ser tanto condicional como incondicional, y se fundamenta en el supuesto de espacios de Hilbert conjuntos gaussianos."
  },
  {
    "objectID": "index.html#datos-funcionales",
    "href": "index.html#datos-funcionales",
    "title": "SpatFD",
    "section": "Datos Funcionales",
    "text": "Datos Funcionales\nImaginemos que estamos interesados en estudiar cómo varía la temperatura en diferentes ciudades del mundo durante un año completo. Para hacerlo, en lugar de tomar una sola medida de la temperatura, registramos el promedio mensual de la termperatura durante todo un año.\nEn lugar de analizar cada punto de temperatura de manera independiente, podemos ver la temperatura a lo largo del añi como una función continua del tiempo. Esta función nos describe cómo la temperatura cambia en cada instante del día, lo cual permite realizar análisis mucho más precisos.\n\n\n\nPZmaps, CC BY-SA 3.0, via Wikimedia Commons\n\n\nLos datos funcionales son los que en lugar de contemplar cada dato como una observación puntual, se consideran como funciones continuas observadas en un conjunto de puntos. Los datos funcionales permiten capturar mejor la complejidad de fenómenos que además de variar en el espacio, varían en dominios continuos como el tiempo o la altitud, además de facilitar la detección de tendencias o anomalías teniendo en cuenta múltiples dimensiones de variación."
  },
  {
    "objectID": "kriging.html",
    "href": "kriging.html",
    "title": "Kriging",
    "section": "",
    "text": "El Kriging es un método de interpolación basado en la teoría de procesos estocástocos que permite estimar los valores que toma una variable en lugares no muestreados a partir de la suposición de que las ubicaciones están correlacionadas espacialmente."
  },
  {
    "objectID": "kriging.html#kriging-ordinario",
    "href": "kriging.html#kriging-ordinario",
    "title": "Kriging",
    "section": "Kriging Ordinario",
    "text": "Kriging Ordinario\nDado un conjunto de observaciones en diferentes localizaciones \\(s_1,s_2,\\cdots,s_n\\) busca predecir el valor de la variable de interés en una nueva ubicación \\(s_0\\)​ como una combinación ponderada de las observaciones:\n\\[\n\\hat{Z}(s_0) = \\sum_{i=1}^n \\lambda_iZ(s_i)\n\\]\nDonde \\(\\lambda_i\\) son los pesos asignados a cada observación, determinados en función de la covarianza espacial entre \\(s_0\\) y \\(s_i\\) determinado por un variograma."
  },
  {
    "objectID": "kriging.html#kriging-funcional",
    "href": "kriging.html#kriging-funcional",
    "title": "Kriging",
    "section": "Kriging Funcional",
    "text": "Kriging Funcional\nEn el contexto funcional, las observaciones en cada ubicación espacial no son valores discretos sino funciones completas. Supongamos que tenemos un conjunto de funciones \\(X(s_1,t),X(s_2,t),\\cdots,X(s_n,t)\\) donde cada \\(X(s_i,t)\\) es una función que describe el comportamiento de la variable de interés a lo largo de un dominio continuo \\(t\\) (como el tiempo).\nEl kriging funcional extiende la idea del kriging clásico al predecir una función en una nueva ubicación \\(s_0\\) utilizando una combinación ponderada de las funciones observadas en las localizaciones \\(s_1,\\cdots,s_n\\). En ese orden de ideas, podemos formular el kriging funcional de la siguiente manera\n\\[\n\\hat{X}(s_0,t)=\\sum_{i=1}^n \\lambda_i(t)X(s_i,t)\n\\]\ndonde \\(\\lambda_i(t)\\) son las funciones de peso que dependen de la localización y del dominio funcional \\(t\\). Estas funciones de peso se determinan resolviendo un sistema de ecuaciones basado en la covariancia entre las funciones observadas y la función a predecir.\nCon el paquete SpatFD podemos crear un objeto SpatFD y definir los modelos de semivariogramas que vamos a emplear en el kriging. En este caso usaremos los datos AirQualityBogota y ajustaremos tres semivariogramas, uno wave, uno Mattern y por último un exponencial, la ubicación que queremos predecir se define en la variable newcoorden.\n\n# Load data and coordinates\ndata(AirQualityBogota)\n\n#s_0 nonsampled location. It could be data.frame or matrix and one or more locations of interest\nnewcoorden=data.frame(X=seq(93000,105000,len=100),Y=seq(97000,112000,len=100))\n\n# Building the SpatFD object\nSFD_PM10 &lt;- SpatFD(PM10, coords = coord[, -1], basis = \"Bsplines\", nbasis = 17,norder=5, lambda = 0.00002, nharm=3)\n\n\n# Semivariogram models for each spatial random field of scores\nmodelos &lt;- list(vgm(psill = 2199288.58, \"Wav\", range = 1484.57, nugget =  0),\n                vgm(psill = 62640.74, \"Mat\", range = 1979.43, nugget = 0,kappa=0.68),\n                vgm(psill =37098.25, \"Exp\", range = 6433.16, nugget =  0))\n\nExisten dos enfoques diferentes para realizar el kriging funcional, el método de scores y el método lambda.\n\nMétodo de Scores\nEn el método de scores, el análisis funcional se basa en una descomposición de las funciones observadas en un conjunto de componentes principales, generalmente a través de una descomposición en funciones base (como la descomposición en funciones ortogonales o en series de Fourier). Este método se descompone en dos etapas:\n\nDescomposición funcional: Se aplica una descomposición funcional de las observaciones para representar cada función como una combinación de componentes principales (bases funcionales) y sus correspondientes coeficientes o “scores”. Si las funciones \\(X(s_i,t)\\) observadas se pueden representar como:\n\n\\[\nX(s_i,t) = \\sum_{k=1}^K \\alpha_{ik}\\phi_k(t)\n\\]\ndonde \\(\\phi_k(t)\\) son las bases funcionales y \\(\\alpha_{ik}\\) son los scores de las componentes principales para cada localización \\(s_i\\). En lugar de predecir la función completa, este método se centra en predecir los scores en la ubicación no observada \\(s_0\\).\nPredicción de una nueva ubicación: El kriging se aplica sobre los scores obtenidos. Se predicen los scores de la nueva ubicación \\(s_0\\) para construir la función predicha \\(\\hat{X}(s_0,t)\\) como una combinación de las bases funcionales ponderadas por los scores predichos:\n\\[\n\\hat{X}(s_0,t) = \\sum_{k=1}^K \\alpha_{0k}\\phi_k(t)\n\\]\nLa función KS_scores_lambdas permite realizar el kriging usando este método al usar “scores” en la opción method\n\nKS_SFD_PM10_sc &lt;- KS_scores_lambdas(SFD_PM10, newcoorden, method = \"scores\", model = modelos)\n\nUsing first variable by default\n\n\nUsing fill.all = TRUE by default\n\n\n[using simple kriging]\n[using simple kriging]\n[using simple kriging]\n\n\nMétodo Lambda\nEste método utiliza una combinación de las funciones observadas, ponderadas por ciertos coeficientes o pesos, para estimar la función en la nueva ubicación, es decir, el kriging se lleva a cabo directamente sobre las funciones. El predictor \\(\\breve{\\chi}_{ s_0}(t)\\)\nestá dado por\n\\[\\breve{\\chi}_{s_0}(t)=\\sum\\limits_{i=1}^{n}\\lambda_i\\chi_{s_i}(t)\\]\nDeben encontrarse los pesos \\(\\lambda_i\\) que minimicen la diferencia entre la verdadera función en la ubicación no observada \\(s_0\\) y el predictor. Eso se expresa matemáticamente como:\n\\[\nmin||\\chi_{s_0}(t)-\\breve{\\chi}_{s_0}(t)||^2\n\\]\ndonde \\(\\chi_{s_0}(t)\\) es la verdadera función en la ubicación \\(s_0\\). La minimización de esta expresión se realiza en el sentido de la norma \\(L^2\\).\nLa función KS_scores_lambdas permite realizar el kriging usando este método al usar “lambda” en la opción method\n\nKS_SFD_PM10_l &lt;- KS_scores_lambdas(SFD_PM10, newcoorden ,method = \"lambda\", model = modelos)\n\nUsing first variable by default\n\n\nUsing fill.all = TRUE by default\n\n\n\nFinalmente, ambos métodos pueden ser aplicados usanto “both” como argumento en method.\n\nKS_SFD_PM10_both &lt;- KS_scores_lambdas(SFD_PM10, newcoorden, method = \"both\", model = modelos)\n\nUsing first variable by default\n\n\nUsing fill.all = TRUE by default\n\n\n[using simple kriging]\n[using simple kriging]\n[using simple kriging]"
  },
  {
    "objectID": "kriging.html#gráficamente",
    "href": "kriging.html#gráficamente",
    "title": "Kriging",
    "section": "Gráficamente",
    "text": "Gráficamente\nPodemos graficar las predicciones usando la función ggplot_KS\n\nggplot_KS(KS_SFD_PM10_both,show.varpred = FALSE,\n         main = \"Plot 1 - Using Scores\",\n          main2 = \"Plot 2 - Using Lambda\",\n           ylab = \"PM10\")\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\nAsí mismo, podemos graficar las predicciones suavizadas en tiempos específicos.\n\nggmap_KS(KS_SFD_PM10_both,\n         map_path = map,\n         window_time = c(2108),\n         method = \"lambda\",\n         zmin = 50)\n\nUsing fill.all = TRUE by default\n\n\n[[1]]"
  },
  {
    "objectID": "optimal_design.html",
    "href": "optimal_design.html",
    "title": "Diseño Óptimo",
    "section": "",
    "text": "La función FD_optimal_design permite determinar el diseño espacial óptimo para la recolección de datos funcionales o escalares, basado en un modelo de variograma y un conjunto de puntos donde se desea realizar predicciones. Este diseño es crucial para optimizar la información obtenida en estudios espaciales."
  },
  {
    "objectID": "optimal_design.html#introducción",
    "href": "optimal_design.html#introducción",
    "title": "Diseño Óptimo",
    "section": "",
    "text": "La función FD_optimal_design permite determinar el diseño espacial óptimo para la recolección de datos funcionales o escalares, basado en un modelo de variograma y un conjunto de puntos donde se desea realizar predicciones. Este diseño es crucial para optimizar la información obtenida en estudios espaciales."
  },
  {
    "objectID": "optimal_design.html#uso",
    "href": "optimal_design.html#uso",
    "title": "Diseño Óptimo",
    "section": "Uso",
    "text": "Uso\nFD_optimal_design(k, s0, model, fixed_stations = NULL,\n                   scalar = FALSE, nharm = NULL,\n                   method = \"lambda\", grid = NULL,\n                   map = NULL, plt = FALSE)"
  },
  {
    "objectID": "optimal_design.html#argumentos",
    "href": "optimal_design.html#argumentos",
    "title": "Diseño Óptimo",
    "section": "Argumentos",
    "text": "Argumentos\n\nk: Número de nuevas estaciones a ubicar.\ns0: Un objeto de tipo matrix, array, data.frame o SpatialPoints que contiene las coordenadas de los puntos donde se desea realizar la predicción óptima.\nmodel: Un objeto VariogramModel del paquete gstat o una lista de modelos si se utilizarán diferentes modelos para cada armónico.\nfixed_stations: Coordenadas de estaciones ya existentes que no se eliminarán. Puede ser de clase matrix, array, data.frame, SpatialPoints o NULL si no hay estaciones fijas.\nscalar: Booleano que indica si la optimización es para datos funcionales (FALSE) o escalares (TRUE). Si es TRUE, nharm se establece en 1.\nnharm: Número de armónicos de los componentes principales funcionales a utilizar en la predicción.\nmethod: Método de kriging funcional que se utilizará, disponible “lambda” y “scores”.\ngrid: Coordenadas donde se pueden ubicar las nuevas estaciones, debe ser de tipo matrix, array, data.frame, SpatialPoints.\nmap: Objeto espacial del paquete sp donde se ubicarán las nuevas estaciones. También se usará para crear la gráfica.\nplt: Booleano que indica si se debe generar una gráfica con ggplot2."
  },
  {
    "objectID": "optimal_design.html#detalles",
    "href": "optimal_design.html#detalles",
    "title": "Diseño Óptimo",
    "section": "Detalles",
    "text": "Detalles\nLa función utiliza métodos presentados por Bohorquez et al. (2016) para encontrar la mejor combinación de diseño según la varianza del error de predicción de kriging funcional. Se implementan dos métodos de kriging funcional:\n\nMétodo “lambda”: Utiliza FPCA y kriging simple.\nMétodo “scores”: Aplica kriging simple a cada armónico y minimiza la varianza total de las predicciones."
  },
  {
    "objectID": "optimal_design.html#valor-de-retorno",
    "href": "optimal_design.html#valor-de-retorno",
    "title": "Diseño Óptimo",
    "section": "Valor de Retorno",
    "text": "Valor de Retorno\nLa función devuelve un objeto de clase OptimalSpatialDesign que incluye:\n\nnew_stations: Coordenadas de las nuevas estaciones.\nfixed_stations: Coordenadas de las estaciones fijas.\nplot: Gráfica generada con ggplot2."
  },
  {
    "objectID": "optimal_design.html#ejemplo",
    "href": "optimal_design.html#ejemplo",
    "title": "Diseño Óptimo",
    "section": "Ejemplo",
    "text": "Ejemplo\nlibrary(gstat)\ns0 &lt;- cbind(2 * runif(100), runif(100))  # coordenadas aleatorias\nfixed_stations &lt;- cbind(2 * runif(4), runif(4))\nx_grid &lt;- seq(0, 2, length = 30)\ny_grid &lt;- seq(0, 1, length = 30)\ngrid &lt;- cbind(rep(x_grid, each = 30), rep(y_grid, 30))\nmodel &lt;- vgm(psill = 5.665312,\n              model = \"Exc\",\n              range = 8000,\n              kappa = 1.62,\n              add.to = vgm(psill = 0.893,\n                           model = \"Nug\",\n                           range = 0,\n                           kappa = 0))\n\nOSD &lt;- FD_optimal_design(k = 10, s0 = s0, model = model,\n                         grid = grid, nharm = 2, plt = TRUE,\n                         fixed_stations = fixed_stations)\n\n# Resultados\nOSD$new_stations\nOSD$fixed_stations\nOSD$plot\nclass(OSD)\n\n\n\n\n\n\nNote\n\n\n\nEl método ‘lambda’ tiende a ser más rápido que el método ‘scores’.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nCuando el método es ‘lambda’, el valor minimizado no es la varianza, sino el negativo de una expresión específica en la referencia mencionada"
  },
  {
    "objectID": "spatfd_object.html",
    "href": "spatfd_object.html",
    "title": "Objetos SpatFD",
    "section": "",
    "text": "El objeto SpatFD crea objetos univariados y multivariados de clase SpatFD a partir de coordenadas espaciales, funciones o series temporales observadas en cada ubicación espacial. El término “series temporales” es genérico, ya que las observaciones pueden estar relacionadas con la frecuencia u otra dimensión espacial, como la profundidad, en lugar del tiempo."
  },
  {
    "objectID": "spatfd_object.html#argumentos",
    "href": "spatfd_object.html#argumentos",
    "title": "Objetos SpatFD",
    "section": "Argumentos",
    "text": "Argumentos\n\ndata: Los datos deben ser proporcionados en un data-frame o una matriz donde cada columna corresponde a una ubicación, y las filas son una secuencia de puntos de datos, ordenados según el tiempo, frecuencia, profundidad, etc. También puede ser un objeto fd del paquete fda.\ncoords: Un data-frame o matriz con coordenadas espaciales (x, y). El número de columnas en data debe coincidir con el número de filas en coords para cada variable.\nbasis: Funciones base. Puede ser “Fourier” o “Bsplines” (predeterminado: “Bsplines”).\nnbasis: El número de funciones base.\nlambda: Valor del parámetro de suavizado.\nnharm: Número de armónicos o funciones propias reportados en los resultados de Componentes Principales Funcionales.\nname: Se puede asignar un nuevo nombre a los datos.\nadd: Se pueden agregar otras variables para la predicción funcional multivariada espacial (cokriging funcional). No es necesario que todas las variables estén observadas en las mismas ubicaciones espaciales.\n…: Argumentos adicionales de fda como create.bspline.basis o create.fourier.basis."
  },
  {
    "objectID": "spatfd_object.html#detalles",
    "href": "spatfd_object.html#detalles",
    "title": "Objetos SpatFD",
    "section": "Detalles",
    "text": "Detalles\nLos objetos SpatFD almacenan los datos funcionales, sus parámetros, los resultados de análisis de componentes principales funcionales, y las coordenadas espaciales para cada variable. Cada variable tiene su propio conjunto de datos funcionales, data-frame o matriz, y archivo de coordenadas espaciales."
  },
  {
    "objectID": "spatfd_object.html#valor",
    "href": "spatfd_object.html#valor",
    "title": "Objetos SpatFD",
    "section": "Valor",
    "text": "Valor\nPara cada variable: Se proporcionan los datos funcionales y los componentes principales funcionales vinculados con las coordenadas espaciales."
  },
  {
    "objectID": "spatfd_object.html#notas",
    "href": "spatfd_object.html#notas",
    "title": "Objetos SpatFD",
    "section": "Notas",
    "text": "Notas\n\nAunque no hay un límite para el número de variables en el cokriging funcional, la verdadera limitación está en los requisitos para encontrar un modelo de covarianza multivariada válido. Se recomienda aplicar el principio de parsimonia.\nLas ubicaciones deben estar en la misma región de interés para que tenga sentido incluirlas en el mismo modelo de predicción. Sin embargo, cada variable puede estar observada en diferentes ubicaciones espaciales y tener un número diferente de observaciones.\n\n\nForma de uso\n\n# Cargar datos\ndata(AirQualityBogota)\n\n# Crear un objeto univariado usando 2 nharm\nSFD_PM10 &lt;- SpatFD(PM10, coords = coord[,2:3], basis = \"Bsplines\", nbasis = 91,\nlambda = 0.00002, nharm = 2)\n\n\nstr(SFD_PM10)\n\nList of 1\n $ PM10:List of 7\n  ..$ data         :'data.frame':   8761 obs. of  10 variables:\n  .. ..$ Bosque       : int [1:8761] 29 32 32 24 29 31 24 26 25 36 ...\n  .. ..$ IDRD         : int [1:8761] 53 48 25 36 17 7 9 12 12 13 ...\n  .. ..$ Carvajal_Sony: int [1:8761] 72 69 61 30 42 44 30 39 53 49 ...\n  .. ..$ Guaymaral    : int [1:8761] 74 55 58 51 41 39 46 60 54 41 ...\n  .. ..$ Suba_Corpas  : int [1:8761] 53 52 45 45 38 40 44 67 51 41 ...\n  .. ..$ Fontibon     : int [1:8761] 65 49 35 40 26 23 21 29 32 30 ...\n  .. ..$ PteAranda    : int [1:8761] 91 70 45 43 33 11 15 28 24 31 ...\n  .. ..$ MAVDT        : int [1:8761] 31 32 32 29 21 21 25 29 26 32 ...\n  .. ..$ Kennedy      : int [1:8761] 135 94 68 53 47 45 49 59 62 71 ...\n  .. ..$ Tunal        : int [1:8761] 38 29 18 17 24 24 19 15 20 35 ...\n  ..$ coords       :'data.frame':   10 obs. of  2 variables:\n  .. ..$ X: num [1:10] 105076 99661 92104 103675 98239 ...\n  .. ..$ Y: num [1:10] 112526 106572 99968 120780 118365 ...\n  ..$ coordsnames  : chr [1:10] \"Bosque\" \"IDRD\" \"Carvajal_Sony\" \"Guaymaral\" ...\n  ..$ data_fd      :List of 3\n  .. ..$ coefs  : num [1:91, 1:10] 22.6 37.3 13.3 40.6 26.2 ...\n  .. .. ..- attr(*, \"dimnames\")=List of 2\n  .. .. .. ..$ : chr [1:91] \"bspl4.1\" \"bspl4.2\" \"bspl4.3\" \"bspl4.4\" ...\n  .. .. .. ..$ : chr [1:10] \"Bosque\" \"IDRD\" \"Carvajal_Sony\" \"Guaymaral\" ...\n  .. ..$ basis  :List of 10\n  .. .. ..$ call       : language basisfd(type = type, rangeval = rangeval, nbasis = nbasis, params = params,      dropind = dropind, quadvals = qu| __truncated__\n  .. .. ..$ type       : chr \"bspline\"\n  .. .. ..$ rangeval   : num [1:2] 1 8761\n  .. .. ..$ nbasis     : num 91\n  .. .. ..$ params     : num [1:87] 101 200 300 399 499 ...\n  .. .. ..$ dropind    : NULL\n  .. .. ..$ quadvals   : NULL\n  .. .. ..$ values     : list()\n  .. .. ..$ basisvalues: list()\n  .. .. ..$ names      : chr [1:91] \"bspl4.1\" \"bspl4.2\" \"bspl4.3\" \"bspl4.4\" ...\n  .. .. ..- attr(*, \"class\")= chr \"basisfd\"\n  .. ..$ fdnames:List of 3\n  .. .. ..$ time  : chr [1:8761] \"1\" \"2\" \"3\" \"4\" ...\n  .. .. ..$ reps  : chr [1:10] \"Bosque\" \"IDRD\" \"Carvajal_Sony\" \"Guaymaral\" ...\n  .. .. ..$ values: chr \"value\"\n  .. ..- attr(*, \"class\")= chr \"fd\"\n  ..$ fpca         :List of 5\n  .. ..$ harmonics:List of 3\n  .. .. ..$ coefs  : num [1:91, 1:2] 0.006843 0.006646 0.013123 0.000889 0.005331 ...\n  .. .. .. ..- attr(*, \"dimnames\")=List of 2\n  .. .. .. .. ..$ : chr [1:91] \"bspl4.1\" \"bspl4.2\" \"bspl4.3\" \"bspl4.4\" ...\n  .. .. .. .. ..$ : chr [1:2] \"PC1\" \"PC2\"\n  .. .. ..$ basis  :List of 10\n  .. .. .. ..$ call       : language basisfd(type = type, rangeval = rangeval, nbasis = nbasis, params = params,      dropind = dropind, quadvals = qu| __truncated__\n  .. .. .. ..$ type       : chr \"bspline\"\n  .. .. .. ..$ rangeval   : num [1:2] 1 8761\n  .. .. .. ..$ nbasis     : num 91\n  .. .. .. ..$ params     : num [1:87] 101 200 300 399 499 ...\n  .. .. .. ..$ dropind    : NULL\n  .. .. .. ..$ quadvals   : NULL\n  .. .. .. ..$ values     : list()\n  .. .. .. ..$ basisvalues: list()\n  .. .. .. ..$ names      : chr [1:91] \"bspl4.1\" \"bspl4.2\" \"bspl4.3\" \"bspl4.4\" ...\n  .. .. .. ..- attr(*, \"class\")= chr \"basisfd\"\n  .. .. ..$ fdnames:List of 3\n  .. .. .. ..$ : chr [1:91] \"bspl4.1\" \"bspl4.2\" \"bspl4.3\" \"bspl4.4\" ...\n  .. .. .. ..$ : chr [1:2] \"PC1\" \"PC2\"\n  .. .. .. ..$ : chr \"values\"\n  .. .. ..- attr(*, \"class\")= chr \"fd\"\n  .. ..$ values   : num [1:91] 2634394 107330 53673 42406 38477 ...\n  .. ..$ scores   : num [1:10, 1:2] -1448 -1888 3430 112 515 ...\n  .. ..$ varprop  : num [1:2] 0.9006 0.0367\n  .. ..$ meanfd   :List of 3\n  .. .. ..$ coefs  : num [1:91, 1] 28.1 47 43.8 40.4 34.9 ...\n  .. .. .. ..- attr(*, \"dimnames\")=List of 2\n  .. .. .. .. ..$ : NULL\n  .. .. .. .. ..$ : chr \"mean\"\n  .. .. ..$ basis  :List of 10\n  .. .. .. ..$ call       : language basisfd(type = type, rangeval = rangeval, nbasis = nbasis, params = params,      dropind = dropind, quadvals = qu| __truncated__\n  .. .. .. ..$ type       : chr \"bspline\"\n  .. .. .. ..$ rangeval   : num [1:2] 1 8761\n  .. .. .. ..$ nbasis     : num 91\n  .. .. .. ..$ params     : num [1:87] 101 200 300 399 499 ...\n  .. .. .. ..$ dropind    : NULL\n  .. .. .. ..$ quadvals   : NULL\n  .. .. .. ..$ values     : list()\n  .. .. .. ..$ basisvalues: list()\n  .. .. .. ..$ names      : chr [1:91] \"bspl4.1\" \"bspl4.2\" \"bspl4.3\" \"bspl4.4\" ...\n  .. .. .. ..- attr(*, \"class\")= chr \"basisfd\"\n  .. .. ..$ fdnames:List of 3\n  .. .. .. ..$ time  : chr [1:8761] \"1\" \"2\" \"3\" \"4\" ...\n  .. .. .. ..$ reps  : chr \"mean\"\n  .. .. .. ..$ values: chr \"mean value\"\n  .. .. ..- attr(*, \"class\")= chr \"fd\"\n  .. ..- attr(*, \"class\")= chr \"pca.fd\"\n  ..$ variable_name: chr \"PM10\"\n  ..$ call_args    :List of 9\n  .. ..$ data   :'data.frame':  8761 obs. of  10 variables:\n  .. .. ..$ Bosque       : int [1:8761] 29 32 32 24 29 31 24 26 25 36 ...\n  .. .. ..$ IDRD         : int [1:8761] 53 48 25 36 17 7 9 12 12 13 ...\n  .. .. ..$ Carvajal_Sony: int [1:8761] 72 69 61 30 42 44 30 39 53 49 ...\n  .. .. ..$ Guaymaral    : int [1:8761] 74 55 58 51 41 39 46 60 54 41 ...\n  .. .. ..$ Suba_Corpas  : int [1:8761] 53 52 45 45 38 40 44 67 51 41 ...\n  .. .. ..$ Fontibon     : int [1:8761] 65 49 35 40 26 23 21 29 32 30 ...\n  .. .. ..$ PteAranda    : int [1:8761] 91 70 45 43 33 11 15 28 24 31 ...\n  .. .. ..$ MAVDT        : int [1:8761] 31 32 32 29 21 21 25 29 26 32 ...\n  .. .. ..$ Kennedy      : int [1:8761] 135 94 68 53 47 45 49 59 62 71 ...\n  .. .. ..$ Tunal        : int [1:8761] 38 29 18 17 24 24 19 15 20 35 ...\n  .. ..$ coords :'data.frame':  10 obs. of  2 variables:\n  .. .. ..$ X: num [1:10] 105076 99661 92104 103675 98239 ...\n  .. .. ..$ Y: num [1:10] 112526 106572 99968 120780 118365 ...\n  .. ..$ basis  : chr \"Bsplines\"\n  .. ..$ nbasis : num 91\n  .. ..$ lambda : num 2e-05\n  .. ..$ nharm  : num 2\n  .. ..$ name   : NULL\n  .. ..$ add    : NULL\n  .. ..$ basisfd:List of 10\n  .. .. ..$ call       : language basisfd(type = type, rangeval = rangeval, nbasis = nbasis, params = params,      dropind = dropind, quadvals = qu| __truncated__\n  .. .. ..$ type       : chr \"bspline\"\n  .. .. ..$ rangeval   : num [1:2] 1 8761\n  .. .. ..$ nbasis     : num 91\n  .. .. ..$ params     : num [1:87] 101 200 300 399 499 ...\n  .. .. ..$ dropind    : NULL\n  .. .. ..$ quadvals   : NULL\n  .. .. ..$ values     : list()\n  .. .. ..$ basisvalues: list()\n  .. .. ..$ names      : chr [1:91] \"bspl4.1\" \"bspl4.2\" \"bspl4.3\" \"bspl4.4\" ...\n  .. .. ..- attr(*, \"class\")= chr \"basisfd\"\n - attr(*, \"class\")= chr \"SpatFD\"\n\n\nPara cada variable incluida en el objeto SpatFD, la función summary retorna:\n\nHead of data: Primeras filas de los datos asociados.\nCoordinates: Coordenadas espaciales correspondientes a cada ubicación.\nEigenvalues: Valores propios de la descomposición en componentes principales.\nMean coefficients: Coeficientes medios de la representación funcional.\nProportion of explained variance by each component: Proporción de varianza explicada por cada componente principal.\n\n\nsummary(SFD_PM10)\n\n#  PM10 \n## Data \n     Bosque IDRD Carvajal_Sony Guaymaral Suba_Corpas Fontibon PteAranda MAVDT\n1        29   53            72        74          53       65        91    31\n2        32   48            69        55          52       49        70    32\n3        32   25            61        58          45       35        45    32\n4        24   36            30        51          45       40        43    29\n5       ...  ...           ...       ...         ...      ...       ...   ...\n8758     50   88            99        27          41       66        56    61\n8759     40   73            99        27          43       36        71    43\n8760     52   37            84        92          57       39        58    44\n8761     46   45            87        65          60       49        38    40\n     Kennedy Tunal\n1        135    38\n2         94    29\n3         68    18\n4         53    17\n5        ...   ...\n8758      64    39\n8759      76    32\n8760      75    48\n8761      79    17\n\n ## Coordinates \n           X          Y\n1 105075.655 112526.216\n2 99661.2289 106572.463\n3 92103.6962 99967.8739\n4 103675.229 120779.813\n5        ...        ...\n\n ## Eigenvalues \n                ev\n1 2634394.04728212\n2 107329.989552922\n3 53673.3376594282\n4 42406.3364006517\n5              ...\n\n ## Mean coefficients \n               mean\n1  28.1142060830838\n2  46.9632482975211\n3  43.8359915678551\n4  40.4199430064293\n5               ...\n88 68.0581607089687\n89 65.8120473593034\n90 20.2318977856245\n91 74.2871948785061\n\n ## Proportion of explained variance by component \n     varprop\n1 0.90063221\n2 0.03669339"
  }
]